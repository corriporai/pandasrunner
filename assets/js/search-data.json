{
  
    
        "post0": {
            "title": "Release 0.4.0 with new running metrics and examples package!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . It has beeen a while since our last release, this is because we are working hard in new features in our new release of RunPandas 0.4. Let&#39;s highlight them: . The Activity now provides extra running statistics such as Vertical Altitude Speed (VAM), mean speed, mean pace, gradient, and mean heart rate. | Now we provide in our runpandas.MeasureSeries the capability of conversions such as distance conversion (km - miles), latitudes and longitudes (degrees - radians) and pace conversion (min/km and min/mile). | There is an auxiliar package for loading activity examples for testing and demo purposes: runpandas.datasets . The goal is to enrich with several real examples in FIT, GPX and TCX format files. | Finally, there is a CI workflow for uploading automatically a package to Pypi after release. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to some new running metrics such as mean pace and mean speed. . First let&#39;s explain the differences between mean pace and mean speed. Although both values express similar information, they are the reverse of each other. The Pace is how much time you need to cover a particular distance, while speed is an indicator of the number of meters you are able to cover within one second. These values can be presented different, depending on the measure units used to express these metrics. Pace is given in unit of time per unit of distance, whereas speed is distance over time. . The formulas are: . Speed (m/s) = distance (m) / time (s) . Pace (s/m) = time (sec) / distance (m) . We provide in runpandas new acessors (runpandas.acessors) for computing those metrics: . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . #compute the distance using haversine formula between two consecutive latitude, longitudes observations. activity[&#39;distpos&#39;] = activity.compute.distance() #compute the speed normalized per interval. activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;speed&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 0.335758 00:00:12 1.939984 00:00:16 2.295962 Name: speed, dtype: float64 . print(&#39;Mean speed m/s:&#39;, activity.mean_speed()) print(&#39;Mean pace s/m:&#39;, activity.mean_pace()) . Mean speed m/s: 2.3545989706029533 Mean pace s/m: 0 days 00:00:00.424701 . Generally this is shown in different units like speed (km/h) and pace (min/km): . #convert m/s to km/h by multiplying the factor of 3.6 print(&#39;Mean speed km/h:&#39;, activity.mean_speed() * 3.6) #We define a auxiliar function to convert the pace from sec/m to min/km: def convert_pace_secmeters2minkms(seconds): from pandas import Timedelta pace_min = int((seconds * 1000) / 60) pace_sec = int(seconds * 1000 - (pace_min * 60)) total_seconds = (pace_min * 60) + pace_sec return Timedelta(seconds=total_seconds) pace_min_km = convert_pace_secmeters2minkms(activity.mean_pace().total_seconds()) print(&#39;Mean pace min/km:&#39;, pace_min_km) . Mean speed km/h: 8.476556294170631 Mean pace min/km: 0 days 00:07:04 . Support to gradient and vertical speed. . Gradient is a measure of the route steepness-the magnitude of its incline or slope as compared to the horizontal. Most often presented as a percentage, the gradient of a climb will normally fall somewhere between 3-15 percent. For practical use, it is usually used for estimating the difficulty of the climb during the route. . #Gradient computed through the distance points activity[&#39;grad&#39;] = activity.compute.gradient() activity[&#39;grad&#39;] . time 00:00:00 NaN 00:00:01 NaN 00:00:06 0.000000 00:00:12 -0.121218 00:00:16 0.000000 ... 00:32:51 0.028739 00:32:56 -0.028715 00:33:02 -0.042557 00:33:07 -0.051672 00:33:11 -0.097842 Name: grad, Length: 383, dtype: float64 . VAM (Vertical Altitude Speed) similar to speed except it tracks how fast you go up vertically rather than horizontally between two points. While speed is measured in miles or kilometers per hour, VAM is measured in vertical meters per hour (vmh). It tells you how many meters you would climb if you went up a moderate grade for an hour. . #Vertical Altitude Speed (VAM) in m/s activity[&#39;vam&#39;] = activity.compute.vertical_speed() activity[&#39;vam&#39;] . time 00:00:00 NaN 00:00:01 0.000000 00:00:06 0.000000 00:00:12 -0.240336 00:00:16 0.000000 ... 00:32:51 0.096118 00:32:56 -0.096118 00:33:02 -0.160217 00:33:07 -0.192285 00:33:11 -0.360504 Name: vam, Length: 383, dtype: float64 . Support to other metrics such as mean heart_pace . #Meart heart rate through the activity &#39;bpm&#39;, int(activity.mean_heart_rate()) . (&#39;bpm&#39;, 156) . Some conversion functions available for measure metrics . #convert the speed m/s to km/h activity[&#39;speed&#39;].kph . time 00:00:00 NaN 00:00:01 1.199325 00:00:06 1.208731 00:00:12 6.983941 00:00:16 8.265462 ... 00:32:51 11.864734 00:32:56 12.001946 00:33:02 13.600020 00:33:07 13.428554 00:33:11 13.155589 Name: speed, Length: 383, dtype: float64 . #gradient converted from degrees to percent activity[&#39;grad&#39;].pct . time 00:00:00 NaN 00:00:01 NaN 00:00:06 0.000000 00:00:12 -12.121772 00:00:16 0.000000 ... 00:32:51 2.873890 00:32:56 -2.871543 00:33:02 -4.255745 00:33:07 -5.167165 00:33:11 -9.784157 Name: grad, Length: 383, dtype: float64 . #Total Altitude descent and ascent print(&#39;Ascent&#39;, sum(activity[&#39;alt&#39;].ascent)) print(&#39;Descent&#39;, sum(activity[&#39;alt&#39;].descent)) . Ascent 153.80981445000006 Descent -166.30712890300006 . #distance from meters to kms activity[&#39;dist&#39;].km . time 00:00:00 0.000000 00:00:01 0.000000 00:00:06 0.001107 00:00:12 0.013003 00:00:16 0.022405 ... 00:32:51 4.613642 00:32:56 4.630378 00:33:02 4.652966 00:33:07 4.671573 00:33:11 4.686311 Name: dist, Length: 383, dtype: float64 . An example activities package including several real word activities from different formats. . The runpandas package also comes with extra batteries, such as our runpandas.datasets package, which includes a range of example data for testing purposes. There is a dedicated repository with all the data available. An index of the data is kept here. . example_fit = rpd.activity_examples(path=&#39;Garmin_Fenix_6S_Pro-Running.fit&#39;) print(example_fit.summary) print(&#39;Included metrics:&#39;, example_fit.included_data) . Synced from watch Garmin Fenix 6S Included metrics: [&lt;MetricsEnum.latitude: &#39;latitude&#39;&gt;, &lt;MetricsEnum.longitude: &#39;longitude&#39;&gt;, &lt;MetricsEnum.elevation: &#39;elevation&#39;&gt;, &lt;MetricsEnum.heartrate: &#39;heartrate&#39;&gt;, &lt;MetricsEnum.cadence: &#39;cadence&#39;&gt;, &lt;MetricsEnum.distance: &#39;distance&#39;&gt;, &lt;MetricsEnum.temperature: &#39;temperature&#39;&gt;] . rpd.read_file(example_fit.path).head() . enhanced_speed enhanced_altitude unknown_87 fractional_cadence lap session unknown_108 dist cad hr lon lat temp . time . 00:00:00 0.000 | 254.0 | 0 | 0.0 | 0 | 0 | NaN | 0.00 | 0 | 101 | 13.843376 | 51.066280 | 8 | . 00:00:01 0.000 | 254.0 | 0 | 0.0 | 0 | 0 | NaN | 0.00 | 0 | 101 | 13.843374 | 51.066274 | 8 | . 00:00:10 1.698 | 254.0 | 0 | 0.0 | 0 | 1 | 2362.0 | 0.00 | 83 | 97 | 13.843176 | 51.066249 | 8 | . 00:00:12 2.267 | 254.0 | 0 | 0.0 | 0 | 1 | 2362.0 | 3.95 | 84 | 99 | 13.843118 | 51.066250 | 8 | . 00:00:21 2.127 | 254.6 | 0 | 0.5 | 0 | 1 | 2552.0 | 16.67 | 87 | 100 | 13.842940 | 51.066231 | 8 | . In case of you just only want to see all the activities in a specific file type , you can filter the runpandas.activities_examples, which returns a filter iterable that you can iterate over: . fit_examples = rpd.activity_examples(file_type=rpd.FileTypeEnum.FIT) for example in fit_examples: #Download and play with the filtered examples print(example.path) . https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Fenix_6S_Pro-Running.fit https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Fenix2_running_with_hrm.fit https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Forerunner_910XT-Running.fit . What is coming next ? . Working hard in advanced running metrics such as power , heart rate zones and the feature of printing the summary of the activity with the main statistics. . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/04/24/release-v04.html",
            "relUrl": "/general/jupyter/releases/2021/04/24/release-v04.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Release 0.3.0 with moving metrics!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We are very excited to announce RunPandas 0.3. This release comes with new features and fixes, let&#39;s highlight them: . Support to moving metrics, with the capability of detecting periods of inactivity. | Support to compute some running general statistics such as total time elapsed and moving time elapsed. | Support to imputated statistics: speed in m/s and total distance and distance per position. | Added Zenodo DOI badge | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to calculated running metrics: total elapsed time, speed and total distance . The Activity dataframe now contains special properties that presents some statistics from the workout such as elapsed time, speed and the distance of workout in meters. . #Disable INFO Logging for a better visualization import logging logging.getLogger().setLevel(logging.CRITICAL) . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . The total ellapsed time is the duration from the moment you hit start on your device until the moment you finish the activity. The total distance is the total of meters ran by the athetle in the activity. The speed is measured in meters per second, and returns a runpandas.MeasureSeries.Speed series with the ratio of the distance traveled per record and the number of seconds to run it. . Occasionally, some observations such as speed, distance and others must be calculated based on available data in the given activity. In runpandas there are special accessors (runpandas.acessors) that computes some of these metrics. We will compute the speed and the distance per position observations using the latitude and longitude for each record and calculate the haversine distance in meters and the speed in meters per second. . #total time elapsed for the activity print(activity.ellapsed_time) #distance of workout in meters print(activity.distance) . 0 days 00:33:11 4686.31103516 . #compute the distance using haversine formula between two consecutive latitude, longitudes observations. activity[&#39;distpos&#39;] = activity.compute.distance() activity[&#39;distpos&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 1.678792 00:00:12 11.639901 00:00:16 9.183847 Name: distpos, dtype: float64 . #compute the speed using the distance per position and the time recorded in seconds to run it. activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;speed&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 0.335758 00:00:12 1.939984 00:00:16 2.295962 Name: speed, dtype: float64 . In runpandas we will also have special atributes at the runpandas.MeasureSeries that can compute transformations such as speed conversion from m/s to km/h. . #kph property that converts m/s to km/h. activity[&#39;speed&#39;].kph . time 00:00:00 NaN 00:00:01 1.199325 00:00:06 1.208731 00:00:12 6.983941 00:00:16 8.265462 ... 00:32:51 11.864734 00:32:56 12.001946 00:33:02 13.600020 00:33:07 13.428554 00:33:11 13.155589 Name: speed, Length: 383, dtype: float64 . Support to detection of periods of inactivity (Moving time) . With the advent of the advanced tracking devices, they are capable of estimating the time that the runner was active. Then new devices can now calculate the moving time based on the GPS locations, distance, and speed of the activity. There are cases that the athlete can also use the pause button to deliberately pause the activity for any reason (stoplights, active rests, bathroom stops or even stopping for photos). . Runpandas will attempt to calculate based on the metrics available in the activity the moving time by detecting all the periods of inactivity. The formula is based on the speed per record (distance recorded) below a specified threshold. It is a powerful metric that the runner can now know to see his real performance, removing any bias related to stopped periods. This metric is quite popular also in several tracking platforms such as Garmin and Strava. . With the new dataframe auxiliar method Activity.only_moving, runpandas detects the periods of inactivity and returns the moving series containing all the observations considered to be stopped. It returns a runpandas.Activity dataframe with a special column named moving indexed by the Activity&#39;s TimeIndex. It is pandas.Series containing a vector of booleans which indicates the stopped periods. Boolean indexing it will help build quick filters to ignore any observations considered by the algorithm as a inactivity. . activity_only_moving = activity.only_moving() print(activity_only_moving[&#39;moving&#39;].head()) . time 00:00:00 False 00:00:01 False 00:00:06 False 00:00:12 True 00:00:16 True Name: moving, dtype: bool . Now we can compute the stopped time and the moving time. . print(&#39;The stopped period:&#39;, activity_only_moving[activity_only_moving[&#39;moving&#39;] == False].index.sum()) . The stopped period: 0 days 00:00:07 . print(&#39;The moving time:&#39;, activity_only_moving.moving_time) . The moving time: 0 days 00:33:05 . What is coming next ? . We will load several running metrics and statistics to our activities and measure series in order to provide the user deeper details about their running activities. It will includes heart time zones, average speed, personal best records per distance, and more! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/03/17/release-v03.html",
            "relUrl": "/general/jupyter/releases/2021/03/17/release-v03.html",
            "date": " • Mar 17, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Understanding moving time vs ellapsed time, distance and speed/pace calculations",
            "content": "Sport tracking applications and the social networks are quite popular among the runners nowadays. Everyone wants to perform the best run looking for a better pace, distance or time. But have you wondered how these metrics are calculated ? . In this post we’ll use gpx-file downloaded from Strava social application, extract, and analyse the gpx data of one single route. We’ll start with extracting the data from the gpx-file into a convenient runpandas.Activity dataframe. From there we’ll explore the data and try to replicate the stats and graphs that the interface of one most popular running application provides us with. . Getting the data . Most of the popular tracking apps allow you to download your activity as a gpx or tcx file. In this post, we will analyse a 12km run from Strava. The gpx-file, short for GPS Exchange Format, can usually be obtained by clicking on export. The screenshot below shows you where you can download your gpx-file in Strava. You can download the file used in this article here. . . Now, we want to load our gpx data into a runpandas.Activity. Take a look at your start point and end point and make sure everything makes sense (i.e. start time &lt; end time). If not, there might be something wrong with your data, or you might have forgotten about some tracks or segments. . import runpandas activity = runpandas.read_file(&#39;./data/post-metrics.gpx&#39;) print(&#39;Start&#39;, activity.index[0],&#39;End:&#39;, activity.index[-1]) print(activity.iloc[0][&#39;lat&#39;], activity.iloc[-1][&#39;lat&#39;]) . Start 0 days 00:00:00 End: 0 days 01:25:27 -8.045075 -8.036119 . The head of the activity (frame) should look like this: . activity.head(8) . cad alt hr lon lat . time . 00:00:00 84.0 | 12.7 | 174.0 | -34.893787 | -8.045075 | . 00:00:04 84.0 | 12.7 | 174.0 | -34.893787 | -8.045075 | . 00:00:06 84.0 | 12.7 | 174.0 | -34.893810 | -8.045115 | . 00:00:08 84.0 | 12.7 | 174.0 | -34.893852 | -8.045168 | . 00:00:10 84.0 | 12.7 | 174.0 | -34.893890 | -8.045216 | . 00:00:13 84.0 | 12.7 | 174.0 | -34.893898 | -8.045266 | . 00:00:16 85.0 | 12.7 | 174.0 | -34.893898 | -8.045282 | . 00:00:19 86.0 | 12.7 | 174.0 | -34.893906 | -8.045329 | . It is important to notice that the time interval between two data points isn&#39;t constant. This happens because the device which records the data can&#39;t always provide the GPS-data due to connectivity problems or even to hardware limitation. In case of such a failure/limitation the data point is skipped (without an error) and the app will collect the data at the next time interval. So keep in mind that for further analysis we can&#39;t assume that the interval between all points is the same. . Plotting the data . Now with the data loaded, we can explore it with some basic plots. Strava provides some interesting graphs to the runner such as the 2D map (longitude vs latitude) and elevation gain during the activity (altitude vs time). Using native plotting tools we can come to quite similar results. . import matplotlib.pyplot as plt plt.plot(activity[&#39;lon&#39;], activity[&#39;lat&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fa8cb4f0790&gt;] . . axis = activity.plot.area(y=&#39;alt&#39;) axis.set_ylim(0,100) . (0.0, 100.0) . . Calculating the total distance . Now let&#39;s going through the key metrics of the activity such as distance and speed. A quick look can misguide you into incorrect calculations. The first one is the distance between two LL-points (latitude, longitude) which it isn&#39;t a straight line, but spherical. . . There are two main approaches to calculate the distance between two points on a spherical surface: the Haversine distance and the Vincenty distance. The two formulas take a different approach on calculating the distance, but this is outside the scoop of this post. The maths behind both approaches can be found here. . Another issue about the distance calculation is if the data have been calculated solely based on latitude and longitude, without taking into consideration the elevation gain or loss, then the distance covered can be underestimated. The easiest way to do this, is to compute the spherical 2d distance and then use the Euclidean formula to add the altitude measurements. The formula below shows this last step. . If the uncorrected distance covered at time point $t_{i}$ is $d_{2,i}$, to correct the distance covered between time point $t_{i-1}$ and time point $t_{i}$ to begin{equation} d_{i} - d_{i-1} = sqrt{ left(d_{2,i} - d_{2,i-1} right)^{ ! !2} + left(a_{i} - a_{i-1} right)^{ ! !2}} end{equation} , where $d_{i}$ and $a_{i}$ are the corrected cumulative distance and the altitude at time $t_{i}$, respectively. . Now with the theoretical background presented, we can start implementing these formulas in our code. We will apply in all data points all possible implementations of our distance formula (Haversine or Vicenty and 2d or 3d) and compute the total distance for every data point by using the dataframe function cumsum. . There are geodesic python libraries already available with Vicenty and Haversine formulas, so we will import them here for our distance calculations. . #pip install haversine &amp; pip install vincenty from vincenty import vincenty as vn from haversine import haversine as hv from haversine import Unit import numpy as np . activity[&#39;shift_lon&#39;] = activity.shift(1)[&#39;lon&#39;] activity[&#39;shift_lat&#39;] = activity.shift(1)[&#39;lat&#39;] #compute the vincenty 2d distance activity[&#39;distance_vin_2d&#39;] = activity[[&#39;lat&#39;, &#39;lon&#39;, &#39;shift_lat&#39;, &#39;shift_lon&#39;]].apply(lambda x: vn( (x[0], x[1]),(x[2], x[3])), axis=1) #transform the value in meters activity[&#39;distance_vin_2d&#39;] = activity[&#39;distance_vin_2d&#39;] * 1000 #compute the haversine 2d distance activity[&#39;distance_hav_2d&#39;] = activity[[&#39;lat&#39;, &#39;lon&#39;, &#39;shift_lat&#39;, &#39;shift_lon&#39;]].apply(lambda x: hv((x[0], x[1]),(x[2], x[3]), unit=Unit.METERS), axis=1) #compute the total distance activity[&#39;distance_vin_no_alt&#39;] = activity[&#39;distance_vin_2d&#39;].cumsum() activity[&#39;distance_hav_no_alt&#39;] = activity[&#39;distance_hav_2d&#39;].cumsum() #compute the vincenty and haversine 3d activity[&#39;shift_alt&#39;] = activity.shift(1)[&#39;alt&#39;] activity[&#39;alt_dif&#39;] = activity[[&#39;alt&#39;, &#39;shift_alt&#39;]].apply(lambda x: x[1] - x[0], axis=1) activity[&#39;distance_vin_3d&#39;] = activity[[&#39;distance_vin_2d&#39;, &#39;alt_dif&#39;]].apply(lambda x: np.sqrt(x[0]**2 + (x[1])**2), axis=1) activity[&#39;distance_hav_3d&#39;] = activity[[&#39;distance_hav_2d&#39;, &#39;alt_dif&#39;]].apply(lambda x: np.sqrt(x[0]**2 + (x[1])**2), axis=1) #compute the total distances for vincenty and haversined 3D activity[&#39;distance_vin&#39;] = activity[&#39;distance_vin_3d&#39;].cumsum() activity[&#39;distance_hav&#39;] = activity[&#39;distance_hav_3d&#39;].cumsum() activity.drop([&#39;shift_lon&#39;, &#39;shift_lat&#39;, &#39;shift_alt&#39;], axis=1) #present the results activity[[&#39;distance_vin&#39;, &#39;distance_hav&#39;, &#39;distance_hav_3d&#39;, &#39;distance_vin_3d&#39;]] . distance_vin distance_hav distance_hav_3d distance_vin_3d . time . 00:00:00 NaN | NaN | NaN | NaN | . 00:00:04 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 00:00:06 5.099000 | 5.118162 | 5.118162 | 5.099000 | . 00:00:08 12.568000 | 12.609153 | 7.490991 | 7.469000 | . 00:00:10 19.330000 | 19.390883 | 6.781730 | 6.762000 | . ... ... | ... | ... | ... | . 01:25:17 12544.272150 | 12564.172393 | 6.437592 | 6.421000 | . 01:25:21 12559.222485 | 12579.203834 | 15.031441 | 14.950334 | . 01:25:23 12564.868485 | 12584.874982 | 5.671148 | 5.646000 | . 01:25:25 12570.232485 | 12590.267705 | 5.392723 | 5.364000 | . 01:25:27 12575.313485 | 12595.361143 | 5.093437 | 5.081000 | . 1697 rows × 4 columns . For futher convenice, we can extract the data in our previously created activity. Let&#39;s check the results with the following print comand. . print(&#39;Vicenty 2D: &#39;, activity[&#39;distance_vin_no_alt&#39;].max()) print(&#39;Haversine 2D: &#39;, activity[&#39;distance_hav_no_alt&#39;].max()) print(&#39;Vincenty 3D: &#39;, activity[&#39;distance_vin&#39;].max()) print(&#39;Haversine 3D: &#39;, activity[&#39;distance_hav&#39;].max()) . Vicenty 2D: 12574.600999999993 Haversine 2D: 12594.649752172338 Vincenty 3D: 12575.313484827602 Haversine 3D: 12595.361142855156 . If we compare the distance calculations between the app and ours, we will see they are almost similar. . . But why do we have 50m of difference between our internal calculations and the distance showed in the app ? It is explained in an article from Strava&#39;s support team. . A flat surface is assumed, and vertical speed from topography is not accounted for. — Strava In this scenario our 2d calculations are right and the we might conclude the app doesn’t take elevation into account. The difference between the distance proposed by the app and our estimate is about 50m (0.03%). Note that this difference will increase if you undertake more altitude-intense activities (mountain biking or hiking). . Now let&#39;s going forward to our next metric, the total activity time ellapsed x moving time. . Calculating the time ellapsed x moving time . def strfdelta(tdelta, fmt): d = {&quot;days&quot;: tdelta.days} d[&quot;hours&quot;], rem = divmod(tdelta.seconds, 3600) d[&quot;minutes&quot;], d[&quot;seconds&quot;] = divmod(rem, 60) return fmt.format(**d) print(&#39;Total time: &#39; , strfdelta(activity.index[-1], &quot;{hours} hour {minutes} min {seconds} sec&quot;)) . Total time: 1 hour 25 min 27 sec . The total time elapsed totally agrees with our calculations, but the moving time seems to be diferent. Let us explain the basic concepts: Elapsed time is the duration from the moment you hit start on your device or phone to the moment you finish the activity. It includes stoplights, coffee breaks, bathroom stops and stopping for photos. Moving time, on the other hand, is a measure of how long you were active, this can be realistic when we have to slow down and stop for a traffic light, for example. . Let’s see if we can figure out which threshold Strava uses to stop the timer (and therefore boost our average speed). To do so, we need to create a new variable that calculates our movement in meters per second (and not just movement per data point, hence why we created the time difference variable). Let’s do this for our haversine 2d distance, since that’s the closest approximation of the distance proposed by the app. . import pandas as pd import numpy as np activity[&#39;time&#39;] = activity.index activity[&#39;time_dif&#39;] = (activity.time - activity.time.shift(1).fillna(activity.time.iloc[0]))/np.timedelta64(1,&#39;s&#39;) activity[&#39;distance_dif_per_sec&#39;] = activity[&#39;distance_hav_2d&#39;] / activity[&#39;time_dif&#39;] activity[&#39;distance_dif_per_sec&#39;] . time 00:00:00 NaN 00:00:04 0.000000 00:00:06 2.559081 00:00:08 3.745496 00:00:10 3.390865 ... 01:25:17 3.218796 01:25:21 3.757777 01:25:23 2.835574 01:25:25 2.696362 01:25:27 2.546719 Name: distance_dif_per_sec, Length: 1697, dtype: float64 . With this new variable we can iterate through a list of thresholds. Let&#39;s assume values between 50 cm and 1 meter, and try to evaluate which one adds up to a timer time-out closest to 640 seconds (~=10 minutes). . for treshold in [0.5, 0.6, 0.7, 0.8, 0.9, 1]: print(treshold, &#39;m&#39;, &#39; : Time:&#39;, sum(activity[activity[&#39;distance_dif_per_sec&#39;] &lt; treshold][&#39;time_dif&#39;]), &#39; seconds&#39;) . 0.5 m : Time: 574.0 seconds 0.6 m : Time: 577.0 seconds 0.7 m : Time: 640.0 seconds 0.8 m : Time: 640.0 seconds 0.9 m : Time: 640.0 seconds 1 m : Time: 640.0 seconds . As we can see at the table above, the movement per second was less than 80-70 centimeters, the application didn&#39;t consider it as movement and discard those intervals (it&#39;s about 2.9 km/h , a speed far below that most people do in their walking pace). Since we don&#39;t have the algorithm used for the real calculation in the app, we can get to an approximate moving time. . total_time = activity[&#39;time_dif&#39;].sum() stopped_time = sum(activity[activity[&#39;distance_dif_per_sec&#39;] &lt; 0.8][&#39;time_dif&#39;]) pd.Timedelta(seconds=total_time - stopped_time) . Timedelta(&#39;0 days 01:14:47&#39;) . Calculating the speed and pace . With the moving time and distance calculated, we can now calculate the pace and speed. Speed is calculated by dividing the distance traveled in meters by the time it took in seconds, and then converted to km/h. . activity[&#39;speed&#39;] = (activity[&#39;distance_hav_2d&#39;] / activity [&#39;time_dif&#39;]) * 3.6 . Next we will filter out all the data where the movement per second is larger than 80 centimeters, based on the threshold we evaluated above. . activity_with_timeout = activity[activity[&#39;distance_dif_per_sec&#39;] &gt; 0.8] . Finally, we compute the weighted average speed and convert it to minutes and seconds per kilometers to get the Pace metric. . def pace(speed, fmt): d = {&quot;hours&quot;: 0} d[&quot;minutes&quot;] = np.floor(60 / speed) d[&quot;seconds&quot;] = round(((60 / speed - np.floor(60 / speed))*60), 0) return fmt.format(**d) avg_km_h = (sum((activity_with_timeout[&#39;speed&#39;] * activity_with_timeout[&#39;time_dif&#39;])) / sum(activity_with_timeout[&#39;time_dif&#39;])) print(&#39;Speed:&#39;, avg_km_h , &#39;km/h&#39;) print(&#39;Cadence:&#39; , pace(avg_km_h, &quot;{hours} hour {minutes} min {seconds} sec&quot;)) . Speed: 10.065838469772745 km/h Cadence: 0 hour 5.0 min 58.0 sec . The results compared to the proposed by our app show similar values, with average speed of 5 minutes and 58 seconds per kilometer, a difference of only just 2 secs. . Let&#39;s plot our average speed for every 10 seconds to see our speed floats during the run. For this plot we will need the cumulative sum of our time differente to 10 seconds and plot the aggregated speed against it. . activity[&#39;time_10s&#39;] = list(map(lambda x: round(x, -1), np.cumsum(activity[&#39;time_dif&#39;]))) plt.plot(activity.groupby([&#39;time_10s&#39;]).mean()[&#39;speed&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fa8c893f550&gt;] . The result shown is a smooth line plot where we check the speed (km/h) vs the time in seconds. . Calculating the elevation gain . The last metric we will explore is the elevation gain. According to the apps documentation, the cumulative elevation gain refers to the sum of every gain elevation throughout an entire Activity. . Based on that, we can compute the elevation gain by mapping over our altitude difference column of our dataframe. . activity_with_timeout.loc[activity_with_timeout[&#39;alt_dif&#39;] &gt; 0][&#39;alt_dif&#39;].sum() . 38.0 . The elevation calculated is far away from what the app showed (about 25m). Checking the altitude difference column values we can see that there are measures down to 10 centimeters. After reading the docummentation, we found out that the elevation data go through a noise correction algorithm. It is based on the a threshold where climbing needs to occur consistently for more than 10 meters for activities without strong barometric or two meters for an activity with the barometric data before it&#39;s added to the total elevation gain. . elevations = zip(list(activity_with_timeout[&#39;alt&#39;]), list(activity_with_timeout[&#39;distance_hav_2d&#39;])) THRESHOLD_METERS = 10 def calculate_elevation_gain(elevations): elevations = list(elevations) thresholdStartingPoint = elevations[0][0] diff_distance = 0 count_diff = 0 gain = 0 valueAgainstThreshold = 0 for elevation, distance in elevations: diff = elevation - thresholdStartingPoint diff_distance+=distance if diff &gt; 0: valueAgainstThreshold += diff if abs(diff_distance) &gt;= THRESHOLD_METERS: gain += valueAgainstThreshold diff_distance = 0 valueAgainstThreshold = 0 else: diff_distance = 0 valueAgainstThreshold = 0 thresholdStartingPoint = elevation return gain #plt.plot(activity[&#39;alt_dif&#39;]) print(calculate_elevation_gain(elevations)) . 25.30000000000002 . The new result is 25.2m, very close to the elevation propose by the app. Based on that, we could recalculate the 3rd distances to get these new elevation values into account to get the distance closest to the 2d distance. . What&#39;s next ? . In this article we presented some popular metrics in runner&#39;s world such as moving time, cadence, pace and elevation gain. The calculations behind the metrics were also detailed and we gave a possible approximation of some of the algorithms used by a famous tracking running application, since we don&#39;t have access, of course,how they implemented it. . The next steps will be implement these metrics as properties, methods of the runpandas.Activity dataframe. We will release it soon with examples detailed at one of our future posts. Keep following here! . — Please feel free to bring any inconsistencies or mistakes by leaving a comment below.- .",
            "url": "https://corriporai.github.io/pandasrunner/calculation/gps/metrics/jupyter/features/tracking/2021/01/29/metrics.html",
            "relUrl": "/calculation/gps/metrics/jupyter/features/tracking/2021/01/29/metrics.html",
            "date": " • Jan 29, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Release 0.2.0 and support to Strava!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We are very excited to announce RunPandas 0.2. This release comes with new features and fixes, let&#39;s highlight them: . Improved docummentation with new sections such as User Guide, Install Guide, API Reference and Changelog. | Support to new code and docummentation third-party plugins like CodeFactor, Pepy, Zenodo and Binder. | Support to read multiple tracking files from a single directory | Added the feature of fetching activity data from social network Strava. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Read multiple tracking files from a single directory . With the new module function runpandas.read_dir , you can reall all the files in a directory and iterate over them. It uses runpandas.read_file and returns a generator. It is important to notice that read_dir expects all the files to be of a supported file format in the directory. . from pathlib import Path import runpandas directory = Path(&quot;path/to/some/dir/&quot;) for activity in runpandas.read_dir(directory): # Do things with the activities . Support to fetch activity stream data from Strava . We addded the support to fetch a single activity stream from the social sports app Strava. The function runpandas.read_strava assumes that you have an API access token and already performed an API authentication. You can use a support script available at our repository strava_auth_handler.py that we developed using the library stravalib. The basic usage is simple and it saves the API token into a file. . It is required to have a client_id and and a client_secret, for that you must have a developer account at strava and create an application. See further at strava: (https://developers.strava.com/) . Here a simple example about how to call : . $ python scripts/strava_auth_handler.py --client_id YOUCLIENTID --client_secret YOURCLIENTSECRET $ more access_token.json &quot;{ &quot;access_token &quot;: &quot;YOURACCESSTOKEN &quot;, &quot;refresh_token &quot;: &quot;YOURREFRESHTOKEN &quot;, &quot;expires_at &quot;: 1607634877}&quot; . read_strava() returns a runpandas.Activity with column runpandas.MeasureSeries matching Runpandas nomenclature. . #Disable INFO Logging for a better visualization import logging logging.getLogger().setLevel(logging.CRITICAL) . import runpandas activity = runpandas.read_strava(activity_id=4437021783, access_token=&quot;c1370af8341f5c5696988d54a1560130737f5954&quot;) activity.head(5) . 2020-12-06 06:36:27 . moving velocity_smooth grade_smooth alt cad dist hr lon lat . time . 00:00:00 False | 0.0 | 1.1 | 6.4 | 79 | 0.0 | 111 | -34.847439 | -8.016994 | . 00:00:04 True | 1.4 | 1.2 | 6.4 | 79 | 5.6 | 111 | -34.847324 | -8.016978 | . 00:00:06 True | 1.6 | 0.9 | 6.5 | 79 | 9.5 | 111 | -34.847252 | -8.016969 | . 00:00:09 True | 2.3 | 1.2 | 6.6 | 79 | 16.9 | 111 | -34.847221 | -8.016894 | . 00:00:12 True | 2.3 | 1.1 | 6.6 | 79 | 23.2 | 111 | -34.847176 | -8.016860 | . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/01/13/release-v02.html",
            "relUrl": "/general/jupyter/releases/2021/01/13/release-v02.html",
            "date": " • Jan 13, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "The first runpandas release is alive! Welcome to the release 0.1.0!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . Today we are happy to announce the initial release of runpandas, which makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to make the pandas data analysis package support reading, transforming and enable running metrics analytics. . How to use runpandas . Require the runpandas module in you Python Code and use our tracking file reader in case of reading local files in tcx, gpx or fit format. . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . The data file is loaded into a runpandas.Activity , which is a subclass of the pandas.DataFrame and provides some additional features. The library also provides for certain columns specific methods that extends the pandas.Series subclasses. In this example below, we get time, altitude, distance, heart rate and geo position (lat/long). . activity.head(5) . alt dist hr lon lat . time . 00:00:00 178.942627 | 0.000000 | 62.0 | -79.093187 | 35.951880 | . 00:00:01 178.942627 | 0.000000 | 62.0 | -79.093184 | 35.951880 | . 00:00:06 178.942627 | 1.106947 | 62.0 | -79.093172 | 35.951868 | . 00:00:12 177.500610 | 13.003035 | 62.0 | -79.093228 | 35.951774 | . 00:00:16 177.500610 | 22.405027 | 60.0 | -79.093141 | 35.951732 | . For instance, if you want to get the base unit for the altitude alt data or the distance dist data: . activity.alt.base_unit . &#39;m&#39; . activity.alt.sum() . 65883.68151855901 . activity.dist.base_unit . &#39;m&#39; . activity.dist[-1] . 4686.31103516 . Since the Activity is a DataFrame, we can play with data and create some visualizations. In this example we use the built in matplotlib based plot function to present the distance x time. . activity[[&#39;dist&#39;]].plot() . &lt;AxesSubplot:xlabel=&#39;time&#39;&gt; . Finally, let&#39;s watch a glimpse of the map route by plotting a 2d map using logintude vs latitude. . activity.plot(x=&#39;lon&#39;, y=&#39;lat&#39;) . &lt;AxesSubplot:xlabel=&#39;lon&#39;&gt; . That&#39;s some of features available! Please check out the runpandas docummentation link for the package&#39;s full API. . How to install runpandas . The release version of runpandas (0.1.0) is available on PyPI, the Python Package Index repository as runpandas link. . If you haven&#39;t already installed, start by downloading and installing with pip: . $ pip install runpandas --upgrade . Please note that we currently only support Python 3.6+. You are now ready to start using the runpandas. . Roadmap . We have big plans for runpandas, including not limited to: . Adding suport reading running tracking sessions from social application Strava; | Adding support reading track files giving a directory as parameter; | Better docummentation with user guide and install guidelines; | Support to session of activities | Support to special plots such as routes, average heart zones, personal bests for specific distances. | . You can see the live roadmap of features at our issues repository. . Thanks . It is our first release after two months of planning and coding. We hope that you find runpandas helpful - it is still very young, and result of some of my ideas and needs to perform personal running analysis. So don&#39;t be afraid to get in touch and let us know what features you would like to add next, Feel free to raise an issue if you spot any bugs! .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/01/07/release-v01.html",
            "relUrl": "/general/jupyter/releases/2021/01/07/release-v01.html",
            "date": " • Jan 7, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Welcome to runpandas",
            "content": "What is runpandas ? . Welcome to the runpandas library. The framework was developed by me, Marcel Caraciolo targeted at getting the most from your running data. . Recent technological advances to GPS-enabled tracking devices is transforming the aspects of training and competition in fitness activities such as running, cycling and swimming. Those devices produces detailed tracking data among several sports data available for anyone interested at its analysis. This enables a descriptive analysis associated with the related data, such as performance, impact of volume of training or just reviewing the historical activities. There are several devices or applications for sports tracking offered by manufacturers of the tracking devices, such as Garmin, Polar, and through a wide range of applications for devices such as smartphones and smartwatches, e.g., Strava, Endomondo, and Runtastic Running GPS Tracker. . Limiting to range of data science open-source packages available, there is only a handful of packages specific to sport data and their analysis. Within Python ecosystem, one of the most popular programming languages for data science, there is a gap to fill between the collection of tracking data and the analysis of such data. Pandas is a popular package for data analysis, and several specific domain libraries as built on top of it. At my research at time, I didn’t find many sports data analysis package within the Python + Pandas ecosystem. . As a possible alternative, runpandas package comes as a set of utilities to import sports data from GPS-enabled devices or even track activities applications, and, after careful processing, organises them in data frames which can provide information about the units of measurement (e.g. distance and speed units) as well of any data operations that have been carried out (e.g., personal best records, heart efforts, elevation gain). Runpandas extends the datatypes used by pandas, so it can benefit its core operations for the handling of measurement units and for summarising and visualising tracking data. . . Real motivation behind runpandas . Many runners use Strava, Garmin , Nike plus , Runstatic App (iOS and Android) to track running activities. The APP and its companion website jointly provide many visual charts with analytical metrics to help runners review their running performances to set up new training plans or make adjustments. To a data scientist runner like me, it would be ideal that our data be downloaded and analyzed locally in my own way to have more fun or get different analysis. . Don’t get me wrong, I am huge fan and user of several running apps, but sometimes I get frustrated with the data processing and visualization that major providers offer, or sometimes I want just to play around with my tracking data and plot my running routes using Maps libraries or to calculate my personal best times for specific distances. Runpandas is an ellegible solution for data science runners like me, fans of digging sports data combined with all possibilities of rich analysis matching against weather, temperature, marathons, routes datasets. So, welcome to the world of running analytics, where data science meets the running. . How can I get started ? . . If you read until here, it is probably because you are interested at runpandas or the possibilities of performing your own analysis. I will give you some options: . If you want to check the documentation for more details on using runpandas: Read the Docs | If you already know the library, and want to contribute: Github | You are just a curious or a runner, and wants to see the some examples: | Another introduction to runpandas is my undergoing book Analysing your own running data with Python on Jupyter notebooks: | . . Marcel Caraciolo, Computer Engineer and Bioinformatics Specialist at Genomika Einstein laboratory. Currently responsible for lab systems product management. Interested at data science, productivity techiques and product management. Amateur runner and lego architecture sets lover. @marcelcaraciolo corriporai.github.io/pandasrunner . .",
            "url": "https://corriporai.github.io/pandasrunner/general/2020/08/01/welcome-to-runpandas.html",
            "relUrl": "/general/2020/08/01/welcome-to-runpandas.html",
            "date": " • Aug 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". My name is Marcel Caraciolo, creator of runpandas. When I am not running or coding, I manage the bioinformatics team at the Genomika Einstein, a genetics molecular laboratory, and product manager for some laboratory management systems. Amateur runner, lover of Lego Architecture sets and passioned about productivity and agile techniques. .",
          "url": "https://corriporai.github.io/pandasrunner/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://corriporai.github.io/pandasrunner/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}