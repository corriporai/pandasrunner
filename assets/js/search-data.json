{
  
    
        "post0": {
            "title": "Release 0.5.1 support to Nike Run Club app tracking files",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We published this minor release with one more social tracking app reading data support: Nike Run Club. In this release of RunPandas 0.5.1, we include: . Reader module support to Nike Run Club app runpandas.read_nikerun. Reading and handling the JSON tracking file from the Nike Run API into a runpandas.Activity` Reader module support to Nike Run Club app. Reading and handling the JSON tracking file from the Nike Run API into arunpandas.Activity` | Read and traverse a directory of Nike Run JSON activities by combining them into a single Activity by the function runpandas.read_dir_nikerun. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . What is Nike Run App? . Nike Run Club is one of the most popular free fitness apps that tracks users&#39; runs, capturing time, distance, pace, heart rate (with a fitness tracker), and route with an impressively precise GPS. It is available on Android and IOS platforms. . . Main Features . Nike Run Club doesn&#39;t offer a official method to export your historical fitness data, unfortunately. However there are several third-party tools available to overcome this issue. One of them is use the open-source tool NRC-Exporter, written in Python, that makes possible by commandline to export all your runs which have associated GPS data and converts them into the GPX format. . . Screenshot from the NRC-Exporter Official Repository Website . The NRC exporter makes available the activity JSON files, which after are converted to GPX format. You can work with both of these formats: GPX or JSON. In this post we will show how to load the JSON files. After running the extractor you will have a directory of all JSON files. It should look something like this: . $ tree activities activities ├── 0019f189-d32f-437f-a4d4-ef4f15304324.json ├── 0069911c-2cc8-489b-8335-8e613a81124s.json ├── 01a09869-0a95-49f2-bd84-75065b701c33.json └── 07e1fa42-a9a9-4626-bbef-60269dc4a111.json . Now you can load these JSON files into our runpandas reading package. . Reading a single workout . Let&#39;s load an exported run from Nike Run using the method runpandas.read_nikerun. This method was specially built for loading the exported JSON Nike Run activities, with all the handling data included. . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . #!pip install runpandas import runpandas as rpd activity = rpd.read_nikerun(&#39;./data/nikerun-sample.json&#39;) . activity . calories nikefuel steps alt hr lon lat . time . 00:00:00 NaN | NaN | NaN | 9.340020 | NaN | -34.894413 | -8.046077 | . 00:00:02.900000 NaN | NaN | NaN | 9.315611 | NaN | -34.894470 | -8.046149 | . 00:00:05.748000 0.447 | NaN | 7.0 | 9.323614 | NaN | -34.894564 | -8.046194 | . 00:00:10.586000 0.729 | 4.327005 | 14.0 | 9.260836 | 138.0 | -34.894624 | -8.046292 | . 00:00:15.585000 0.728 | NaN | 14.0 | 9.334247 | 139.0 | -34.894678 | -8.046401 | . ... ... | ... | ... | ... | ... | ... | ... | . 00:52:39.582000 0.826 | 7.061214 | 13.0 | 9.331132 | 189.0 | -34.894534 | -8.046602 | . 00:52:43.582000 0.411 | NaN | 8.0 | 9.316407 | NaN | -34.894465 | -8.046533 | . 00:52:44.582000 NaN | NaN | 7.0 | 9.512563 | NaN | -34.894443 | -8.046515 | . 00:52:45.582000 NaN | NaN | NaN | 9.324933 | NaN | -34.894429 | -8.046494 | . 00:52:49.582000 NaN | 7.064754 | 7.0 | NaN | 190.0 | -34.894395 | -8.046398 | . 727 rows × 7 columns . As shown above, the activity now after loaded can be analysed as any other activity in runpandas! . #compute the common metrics for the running activity such as distance per position, speed, pace, etc. activity[&#39;distpos&#39;] = activity.compute.distance() activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity_only_moving = activity.only_moving() . activity_only_moving.summary() . Session Running: 04-07-2021 11:23:19 Total distance (meters) 8248.08 Total ellapsed time 0 days 00:52:49.582000 Total moving time 0 days 00:47:47.583000 Average speed (km/h) 9.36815 Average moving speed (km/h) 10.2845 Average pace (per 1 km) 0 days 00:06:24 Average pace moving (per 1 km) 0 days 00:05:50 Average cadence NaN Average moving cadence NaN Average heart rate 177.822 Average moving heart rate 177.957 Average temperature NaN dtype: object . Reading multiple workouts . We also provides the method runpandas.read_dir_nikerun, which allows the user to read all the tracking files in JSON format in a directory and combined them into a runpandas.Actvity split by sessions based on the timestamp of each activity. Does it sound familiar to you? Exactly, it works as same as the runpandas.read_directory_aggregate, but it is specific for the Nike Run JSON output files. . To illustrate this in action, let&#39;s load a session of 6 activities of a single runner exported from he Nike Run account: . #!pip install runpandas import runpandas as rpd session = rpd.read_dir_nikerun(&#39;./data/nikerun_session&#39;) . session . calories nikefuel steps alt hr lon lat . start time . 2021-01-31 09:18:46.676000+00:00 00:00:00 NaN | NaN | NaN | 7.308532 | NaN | -34.891723 | -8.046471 | . 00:00:03 0.873 | NaN | 7.0 | 7.328482 | NaN | -34.891698 | -8.046576 | . 00:00:06 0.862 | NaN | 8.0 | 7.314730 | NaN | -34.891674 | -8.046687 | . 00:00:08.999000 0.150 | 2.056452 | 7.0 | 7.311658 | NaN | -34.891632 | -8.046807 | . 00:00:12.999000 0.509 | NaN | 14.0 | 7.334774 | NaN | -34.891624 | -8.046902 | . ... ... ... | ... | ... | ... | ... | ... | ... | . 2020-09-18 09:23:20.620000+00:00 00:25:38.379000 0.737 | NaN | 12.0 | 1.117384 | 176.0 | -34.897463 | -8.126419 | . 00:25:42.379000 0.362 | 5.205709 | 7.0 | 0.950017 | 176.0 | -34.897494 | -8.126517 | . 00:25:46.378000 0.725 | NaN | 14.0 | 0.950000 | NaN | -34.897489 | -8.126607 | . 00:25:52.378000 NaN | 5.242402 | 11.0 | 0.950000 | 175.0 | -34.897485 | -8.126700 | . 00:25:56.378000 NaN | NaN | NaN | NaN | NaN | -34.897540 | -8.126788 | . 3742 rows × 7 columns . print(&#39;There are &#39;, session.session.count(), &#39;activities&#39;) . There are 6 activities . #In this example we compute the distance and the distance per position across all workouts session = session.session.distance() #comput the speed for each activity session = session.session.speed(from_distances=True) #compute the pace for each activity session = session.session.pace() #compute the inactivity periods for each activity session = session.session.only_moving() . summary = session.session.summarize() summary . moving_time mean_speed max_speed mean_pace max_pace mean_moving_speed mean_moving_pace mean_cadence max_cadence mean_moving_cadence mean_heart_rate max_heart_rate mean_moving_heart_rate mean_temperature min_temperature max_temperature total_distance ellapsed_time . start . 2020-08-16 10:06:00.150000+00:00 00:17:51.850000 | 2.190390 | 15.123177 | 00:07:36 | 00:01:06 | 2.237329 | 00:07:26 | NaN | NaN | NaN | 160.772152 | 179.0 | 160.788462 | NaN | NaN | NaN | 2420.052106 | 00:18:24.850000 | . 2020-09-18 09:23:20.620000+00:00 00:25:49.378000 | 2.697902 | 13.684714 | 00:06:10 | 00:01:13 | 2.707618 | 00:06:09 | NaN | NaN | NaN | 171.626415 | 183.0 | 171.623574 | NaN | NaN | NaN | 4198.955573 | 00:25:56.378000 | . 2021-01-31 09:18:46.676000+00:00 00:53:54.324000 | 2.452860 | 13.833715 | 00:06:47 | 00:01:12 | 2.615802 | 00:06:22 | NaN | NaN | NaN | 168.152542 | 186.0 | 168.320683 | NaN | NaN | NaN | 8502.408803 | 00:57:46.325000 | . 2021-04-02 09:39:34+00:00 00:30:31 | 2.779288 | 10.529306 | 00:05:59 | 00:01:34 | 2.800375 | 00:05:57 | NaN | NaN | NaN | 178.212625 | 189.0 | 178.203333 | NaN | NaN | NaN | 5138.905933 | 00:30:49.001000 | . 2021-06-11 09:30:44+00:00 00:25:50 | 2.630604 | 6.038798 | 00:06:20 | 00:02:45 | 2.693010 | 00:06:11 | NaN | NaN | NaN | 167.064516 | 180.0 | 167.285714 | NaN | NaN | NaN | 4206.337676 | 00:26:39.001000 | . 2021-07-04 11:23:19.418000+00:00 00:47:47.583000 | 2.602263 | 4.212320 | 00:06:24 | 00:03:57 | 2.856801 | 00:05:50 | NaN | NaN | NaN | 177.821862 | 192.0 | 177.956967 | NaN | NaN | NaN | 8248.084577 | 00:52:49.582000 | . print(&#39;Session Interval:&#39;, (summary.index.to_series().max() - summary.index.to_series().min()).days, &#39;days&#39;) print(&#39;Total Workouts:&#39;, len(summary), &#39;runnings&#39;) print(&#39;Tota KM Distance:&#39;, summary[&#39;total_distance&#39;].sum() / 1000) print(&#39;Average Pace (all runs):&#39;, summary.mean_pace.mean()) print(&#39;Average Moving Pace (all runs):&#39;, summary.mean_moving_pace.mean()) print(&#39;Average KM Distance (all runs):&#39;, round(summary.total_distance.mean()/ 1000,2)) . Session Interval: 322 days Total Workouts: 6 runnings Tota KM Distance: 32.714744667475955 Average Pace (all runs): 0 days 00:06:32.666666 Average Moving Pace (all runs): 0 days 00:06:19.166666 Average KM Distance (all runs): 5.45 . As we illustrated above, we can extract several statistics from the session workouts using the same methods and acessors available from runpandas. . What is coming next ? . The next releases will focus on supporting marathon results. It will be awesome, keep tunned! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/07/21/release-051.html",
            "relUrl": "/general/jupyter/releases/2021/07/21/release-051.html",
            "date": " • Jul 21, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Release 0.5.0 with summary statistics and aggregation of multiple activities!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We published this major release with summary statistics for a single activity and the possibility of combining multiple workouts into a one multi-dimensional dataframe (season) , enabling other types of analysis, including historical performance over a period of time. In this release of RunPandas 0.5.0, we include: . Now the Activity can be summarised through common summary statistics using the runpandas.types.summary method. | We enable now the analysis over multiple activities by combining them into a single Activity. This results into new possibilities of aggregated analysis over a group of workouts. | There is a new acessor runpandas.acessors.season , that computes the running metrics through the combined activities. | Finally, there is a runpandas.types.session_summary method that includes summary statistics over the season (group) of activities. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Summary statistics for a single workout . The runpandas provides for the data runners the runpandas.types.summary method for the Activity dataframe. This methods computes the estimates of the total distance covered, the total duration, the time spent moving, and several averages metrics such as speed, pace, cadence, and heart rate, calculated based on total duration ot the time spent moving. . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . #!pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . activity . alt dist hr lon lat . time . 00:00:00 178.942627 | 0.000000 | 62 | -79.093187 | 35.951880 | . 00:00:01 178.942627 | 0.000000 | 62 | -79.093184 | 35.951880 | . 00:00:06 178.942627 | 1.106947 | 62 | -79.093172 | 35.951868 | . 00:00:12 177.500610 | 13.003035 | 62 | -79.093228 | 35.951774 | . 00:00:16 177.500610 | 22.405027 | 60 | -79.093141 | 35.951732 | . ... ... | ... | ... | ... | ... | . 00:32:51 170.290649 | 4613.641602 | 178 | -79.093241 | 35.951341 | . 00:32:56 169.810059 | 4630.377930 | 178 | -79.093192 | 35.951486 | . 00:33:02 168.848755 | 4652.966309 | 179 | -79.093086 | 35.951671 | . 00:33:07 167.887329 | 4671.572754 | 179 | -79.093000 | 35.951824 | . 00:33:11 166.445312 | 4686.311035 | 180 | -79.093014 | 35.951954 | . 383 rows × 5 columns . #compute the common metrics for the running activity such as distance per position, speed, pace, etc. activity[&#39;distpos&#39;] = activity.compute.distance() activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;vam&#39;] = activity.compute.vertical_speed() activity_only_moving = activity.only_moving() . activity_only_moving.summary() . Session Running: 26-12-2012 21:29:53 Total distance (meters) 4686.31 Total ellapsed time 0 days 00:33:11 Total moving time 0 days 00:33:05 Average speed (km/h) 8.47656 Average moving speed (km/h) 8.49853 Average pace (per 1 km) 0 days 00:07:04 Average pace moving (per 1 km) 0 days 00:07:03 Average cadence NaN Average moving cadence NaN Average heart rate 156.653 Average moving heart rate 157.4 Average temperature NaN dtype: object . The result above is an object of pandas.Series including the main running statistics from the workout. . Combining multiple activities into a Grouped Activity Dataframe . Runpandas powered by pandas libraries comes with the pandas.MultiIndex, which allows the dataframe have multiple columns as a row identifier, while having each index column related to another through a parent/child relationship. In our scenario we have the start time from each activity as the first index level and the timestamps from the activity as the second index level. This enables advanced statistical analysis acrosss one period of training sessions or over a period time. . The code chunk below loads the data using the method runpandas.read_directory_aggregate, which allows the user to read all the tracking files of a support format in a directory and combine them in a data frame split by sessions based on the timestamps of each activity. It means that for each workout file will be stored in separate lines in the dataframe. . import runpandas session = runpandas.read_dir_aggregate(dirname=&#39;./data/session/&#39;) . session . alt hr lon lat . start time . 2020-08-30 09:08:51.012 00:00:00 NaN | NaN | -34.893609 | -8.045055 | . 00:00:01.091000 NaN | NaN | -34.893624 | -8.045054 | . 00:00:02.091000 NaN | NaN | -34.893641 | -8.045061 | . 00:00:03.098000 NaN | NaN | -34.893655 | -8.045063 | . 00:00:04.098000 NaN | NaN | -34.893655 | -8.045065 | . ... ... ... | ... | ... | ... | . 2021-07-04 11:23:19.418 00:52:39.582000 0.050001 | 189.0 | -34.894534 | -8.046602 | . 00:52:43.582000 NaN | NaN | -34.894465 | -8.046533 | . 00:52:44.582000 NaN | NaN | -34.894443 | -8.046515 | . 00:52:45.582000 NaN | NaN | -34.894429 | -8.046494 | . 00:52:49.582000 NaN | 190.0 | -34.894395 | -8.046398 | . 48794 rows × 4 columns . session.index #MultiIndex (start, timestamp) . MultiIndex([(&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:00&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:01.091000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:02.091000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:03.098000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:04.098000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:05.096000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:06.096000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:07.097000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:08.097000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:09.102000&#39;), ... (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:18.584000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:22.584000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:26.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:30.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:35.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:39.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:43.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:44.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:45.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:49.582000&#39;)], names=[&#39;start&#39;, &#39;time&#39;], length=48794) . Session compute metrics methods . The package comes now with an acessor runpandas.types.acessors.session._SessionAcessor that holds special methods for computing the running metrics across all the activities. The calls delegate to the single activity metrics acessors. . #In this example we compute the distance and the distance per position across all workouts session = session.session.distance() session . alt hr lon lat distpos dist . start time . 2020-08-30 09:08:51.012 00:00:00 NaN | NaN | -34.893609 | -8.045055 | NaN | NaN | . 00:00:01.091000 NaN | NaN | -34.893624 | -8.045054 | 1.690587 | 1.690587 | . 00:00:02.091000 NaN | NaN | -34.893641 | -8.045061 | 2.095596 | 3.786183 | . 00:00:03.098000 NaN | NaN | -34.893655 | -8.045063 | 1.594298 | 5.380481 | . 00:00:04.098000 NaN | NaN | -34.893655 | -8.045065 | 0.163334 | 5.543815 | . ... ... ... | ... | ... | ... | ... | ... | . 2021-07-04 11:23:19.418 00:52:39.582000 0.050001 | 189.0 | -34.894534 | -8.046602 | 12.015437 | 8220.018885 | . 00:52:43.582000 NaN | NaN | -34.894465 | -8.046533 | 10.749779 | 8230.768664 | . 00:52:44.582000 NaN | NaN | -34.894443 | -8.046515 | 3.163638 | 8233.932302 | . 00:52:45.582000 NaN | NaN | -34.894429 | -8.046494 | 2.851535 | 8236.783837 | . 00:52:49.582000 NaN | 190.0 | -34.894395 | -8.046398 | 11.300740 | 8248.084577 | . 48794 rows × 6 columns . #comput the speed for each activity session = session.session.speed(from_distances=True) #compute the pace for each activity session = session.session.pace() #compute the inactivity periods for each activity session = session.session.only_moving() . How many activities are there in the activity ? There is a custom method count that returns the total number of activities in the season frame. . print (session.session.count(), &#39;activities&#39;) . 68 activities . Session summary statistics . After the loading and metrics computation for all the activities, we now can load the basic summaries about the training sessions: time spent, total distance, mean speed and other insightful statistics for each running activity. For this task, we may accomplish it by calling the method runpandas.types.session._SessionAcessor.summarize . It will return a basic Dataframe including all the aggregated statistics per activity from the season frame. . summary = session.session.summarize() summary . moving_time mean_speed max_speed mean_pace max_pace mean_moving_speed mean_moving_pace mean_cadence max_cadence mean_moving_cadence mean_heart_rate max_heart_rate mean_moving_heart_rate mean_temperature min_temperature max_temperature total_distance ellapsed_time . start . 2020-07-03 09:50:53.162 00:25:29.838000 | 2.642051 | 4.879655 | 00:06:18 | 00:03:24 | 2.665008 | 00:06:15 | NaN | NaN | NaN | 178.819923 | 188.0 | 178.872587 | NaN | NaN | NaN | 4089.467333 | 00:25:47.838000 | . 2020-07-05 09:33:20.999 00:05:04.999000 | 2.227637 | 6.998021 | 00:07:28 | 00:02:22 | 3.072098 | 00:05:25 | NaN | NaN | NaN | 168.345455 | 176.0 | 168.900000 | NaN | NaN | NaN | 980.162640 | 00:07:20.001000 | . 2020-07-05 09:41:59.999 00:18:19 | 1.918949 | 6.563570 | 00:08:41 | 00:02:32 | 2.729788 | 00:06:06 | NaN | NaN | NaN | 173.894180 | 185.0 | 174.577143 | NaN | NaN | NaN | 3139.401118 | 00:27:16 | . 2020-07-13 09:13:58.718 00:40:21.281000 | 2.509703 | 8.520387 | 00:06:38 | 00:01:57 | 2.573151 | 00:06:28 | NaN | NaN | NaN | 170.808176 | 185.0 | 170.795527 | NaN | NaN | NaN | 6282.491059 | 00:41:43.281000 | . 2020-07-17 09:33:02.308 00:32:07.691000 | 2.643278 | 8.365431 | 00:06:18 | 00:01:59 | 2.643278 | 00:06:18 | NaN | NaN | NaN | 176.436242 | 186.0 | 176.436242 | NaN | NaN | NaN | 5095.423045 | 00:32:07.691000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-06-13 09:22:30.985 01:32:33.018000 | 2.612872 | 23.583956 | 00:06:22 | 00:00:42 | 2.810855 | 00:05:55 | NaN | NaN | NaN | 169.340812 | 183.0 | 169.655879 | NaN | NaN | NaN | 15706.017295 | 01:40:11.016000 | . 2021-06-20 09:16:55.163 00:59:44.512000 | 2.492640 | 6.065895 | 00:06:41 | 00:02:44 | 2.749453 | 00:06:03 | NaN | NaN | NaN | 170.539809 | 190.0 | 171.231392 | NaN | NaN | NaN | 9965.168311 | 01:06:37.837000 | . 2021-06-23 09:37:44.000 00:26:49.001000 | 2.501796 | 5.641343 | 00:06:39 | 00:02:57 | 2.568947 | 00:06:29 | NaN | NaN | NaN | 156.864865 | 171.0 | 156.957031 | NaN | NaN | NaN | 4165.492241 | 00:27:45.001000 | . 2021-06-27 09:50:08.664 00:31:42.336000 | 2.646493 | 32.734124 | 00:06:17 | 00:00:30 | 2.661853 | 00:06:15 | NaN | NaN | NaN | 166.642857 | 176.0 | 166.721116 | NaN | NaN | NaN | 5074.217061 | 00:31:57.336000 | . 2021-07-04 11:23:19.418 00:47:47.583000 | 2.602263 | 4.212320 | 00:06:24 | 00:03:57 | 2.856801 | 00:05:50 | NaN | NaN | NaN | 177.821862 | 192.0 | 177.956967 | NaN | NaN | NaN | 8248.084577 | 00:52:49.582000 | . 68 rows × 18 columns . print(&#39;Session Interval:&#39;, (summary.index.to_series().max() - summary.index.to_series().min()).days, &#39;days&#39;) print(&#39;Total Workouts:&#39;, len(summary), &#39;runnings&#39;) print(&#39;Tota KM Distance:&#39;, summary[&#39;total_distance&#39;].sum() / 1000) print(&#39;Average Pace (all runs):&#39;, summary.mean_pace.mean()) print(&#39;Average Moving Pace (all runs):&#39;, summary.mean_moving_pace.mean()) print(&#39;Average KM Distance (all runs):&#39;, round(summary.total_distance.mean()/ 1000,2)) . Session Interval: 366 days Total Workouts: 68 runnings Tota KM Distance: 491.77377537338896 Average Pace (all runs): 0 days 00:07:18.411764 Average Moving Pace (all runs): 0 days 00:06:02.147058 Average KM Distance (all runs): 7.23 . As we can see above, we analyzed the period of 366 days (one year) of running workouts. In this period, she ran 68 times which achieved the total distance of 491 km! The average moving pace is 06&#39;02&quot; per km and average distance of 7.23km! Great numbers for a starter runner! . What is coming next ? . The next releases will focus on reading of Nike Run app workouts and support plugin for marathon results. It will be awesome, keep tunned! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/07/16/release050.html",
            "relUrl": "/general/jupyter/releases/2021/07/16/release050.html",
            "date": " • Jul 16, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Release 0.4.1 powered by heart zone metrics!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We published this minor release with some new metrics and changes to better improve our build process. In this release of RunPandas 0.4.1, we include: . The Activity now provides some special methods in runpandas.acessors that computes the heart training zones for each record and the time spent for each training zone. | We published for the first time our package to the Anaconda scientific package repository. | Finally, we have changed our CI build implementation from Travis CI to Github actions. Unfortunately, the Travis CI became highly limited to open-source projects, which resulted into several builds to not run anymore due to lack of credits. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to heart training zones metrics . Now runpandas comes with useful methods to data runners who desires to explore their heart rate data and check the heart rate range variation and the respective training zones or the time ellapsed through each training zone during the workout. . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . import runpandas activity = runpandas.read_file(&#39;./data/11km.tcx&#39;) print(&#39;Start&#39;, activity.index[0],&#39;End:&#39;, activity.index[-1]) print(activity.iloc[0][&#39;lat&#39;], activity.iloc[-1][&#39;lat&#39;]) . Start 0 days 00:00:00 End: 0 days 01:16:06 -8.364486 -8.364462 . First, let&#39;s perform a QC evaluation on the data, to check if there&#39;s any invalid or missing data required for the analysis. As you can see in the cell below, there are 5 records with heart rate data missing. We will replace all these with the first HR sensor data available. . import numpy as np group_hr = activity[&#39;hr&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_hr) #There is 5 missing values in HR. Let&#39;s see the positions where they are placed in the frame. print(activity[activity[&#39;hr&#39;].isnull()]) #We will replace all NaN values with the first HR sensor data available activity[&#39;hr&#39;].fillna(activity.iloc[5][&#39;hr&#39;], inplace=True) print(&#39;Total nan after fill:&#39;, activity[&#39;hr&#39;].isnull().sum()) . There are nan records: 5 run_cadence alt dist hr lon lat time 00:00:00 NaN 668.801819 0.000000 NaN -36.577568 -8.364486 00:00:07 NaN 668.714722 5.749573 NaN -36.577465 -8.364492 00:00:10 NaN 668.680603 11.615299 NaN -36.577423 -8.364470 00:00:12 83.0 668.639099 17.306795 NaN -36.577366 -8.364449 00:00:15 82.0 668.600464 22.672394 NaN -36.577312 -8.364429 speed time 00:00:00 0.000000 00:00:07 0.000000 00:00:10 0.000000 00:00:12 2.262762 00:00:15 2.317986 Total nan after fill: 0 . Let&#39;s see how to add a column with the heart rate zone label to the data frame. For this task, we will use the special method runpandas.compute.heart_zone . The parameters are the bins argument which contains the left and right bounds for each training zone and the labels argument corresponding to the zone labels . activity[&#39;heartrate_zone&#39;] = activity.compute.heart_zone( labels=[&quot;Rest&quot;, &quot;Z1&quot;, &quot;Z2&quot;, &quot;Z3&quot;, &quot;Z4&quot;, &quot;Z5&quot;], bins=[0, 92, 110, 129, 147, 166, 184]) activity[&quot;heartrate_zone&quot;].tail() . time 01:15:54 Z4 01:15:56 Z4 01:16:00 Z4 01:16:02 Z4 01:16:06 Z4 Name: heartrate_zone, dtype: category Categories (6, object): [Rest &lt; Z1 &lt; Z2 &lt; Z3 &lt; Z4 &lt; Z5] . To calculate the time in zone, there is also a special method runpandas.compute.time_in_zone which computes the time spent for each training zone. . time_in_zone = activity.compute.time_in_zone( labels=[&quot;Rest&quot;, &quot;Z1&quot;, &quot;Z2&quot;, &quot;Z3&quot;, &quot;Z4&quot;, &quot;Z5&quot;], bins=[0, 92, 110, 129, 147, 166, 184]) time_in_zone . hr_zone Rest 00:00:00 Z1 00:04:10 Z2 00:07:05 Z3 00:31:45 Z4 00:33:06 Z5 00:00:00 Name: time_diff, dtype: timedelta64[ns] . Anaconda Package . We decided to publish our runpandas packages at one of the most popular pythonic scientific package repositories : Anaconda . There are more millions data science packages published focusing on scientific areas. In this release we published at the owner&#39;s package repository (https://anaconda.org/marcelcaraciolo/runpandas), but the goal is to publish it at the conda-forge main repository. We will work on this task to submit our package as a release candidate. . Changing the Build script to suppor the Github Actions . Since last year the CI/CD provider TravisCI started to put several limitations to their free tier quotes , specially to open-source projects with had a specific ammount of time-credits for builds. We understood that for them it was a big decision , because building open source products and maintain them is extremely difficult. Since runpandas is a fully open source package, I decided to find other CI provider. . Github Actions came to the rescue, since it remains free for any open-source project hosted in Github. Finally, I moved in this release all the build scripts to the Github actions. . . For further information about the Github Actions and see how it works, please check this article and this post. . What is coming next ? . The next releases will come with power metrics and support to the workout summary visualization. So stay tunned! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/05/28/release-v041.html",
            "relUrl": "/general/jupyter/releases/2021/05/28/release-v041.html",
            "date": " • May 28, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Running powered by heart training zones.",
            "content": "Many runners use the heart rate (HR) data to plan their training strategies. Heart rate is an individual metric and differs between athletes running the same pace, therefore, it can help them to pace themselves properly and can be a useful metric to gauge fatigue and fitness level. One of the most popular systems used by marathon trainers including the heart rate are the ones introduced by Daniels Running Formula and those adopted by Garmin services; in both they define zones taking account the maximum heart rate and resting heart rate. These zones are broad for the convenience of the athlete when performing workouts at a given intensity. This intensity should vary depending on the purpose of the workout (recovery, threshold, VO2 max intervals , etc.). . Below, we present the zones using percentage of maximum heart rate (HRmax) as cuttofs. . Table 1. Training Modes for Different Heart Rate Zones (Daniels vs Garmin Cutoffs) . But why heart rate is an important marker of running effort ? Studies suggest that the human running is an energy transfer process. Running economy can be measured by how fast one can run, given a level of oxygen consumption (VO2). VO2 level is almost linearly correlated with running pace (effort) and high correlated with heart rate. The new devices provide HR recordings and it is easier to measure the HR instead of other markers. . Figure 2. Relationship between HR, VO2, Lactate, and Running Pace. Photo taken from the Website Mcmillanrunning . For many experienced runners, it would be important to analyze your historical workouts, explore your heart rate range variation and check the ellapsed time through each training zone in order to ensure that you are running at the right effort level to maximize your workout. In this post we will present how we can explore our heart rate (HR) records and the respective training zones based on the data provided from the smartwatches or tracking running apps. . Analyzing the heart data and building the respective training zones . Finding my maximum HR . The easiest way resorts to a empirical equation, HRmax = 220 - Age. It is drawn from some epidemiological studies; thus, may not personalized. A better way is to monitor HR while running uphill intervals or use your historical data to compute your HRmax. In this scenario let&#39;s use the empirical HRmax. My current age is 36, so my max heart rate would be 184 (HRmax = 220-36). . Computing the training zones . As we explained above, the heart rate is grouped by zones: active recovery (easy running), general aerobic (marathon pace), basic endurance or the lactate threshold zone (tempo run) and the anaerobic or the VO2 max work(interval). For my maximum heart rate of 184, based on the Garmin&#39;s thresholds, the zones can be calculated as: . Zone heart_rate . Z1 (Active recovery) | | 110 | . Z2 (Endurance) | | 129 | . Z3 (Tempo) | | 147 | . Z4 (Threshold) | | 166 | . Z5 (VO2 Max) | | 184 | . Using the Heart Rate Zones to Review a Workout . Now that we have the training zones, by using runpandas we could play with our workouts and evaluate the quality of the workouts based on its training zones. . In this example, I selected one of my workouts to further explore these zones and how they correlate with the sensors data available recorded. . import runpandas activity = runpandas.read_file(&#39;./data/11km.tcx&#39;) print(&#39;Start&#39;, activity.index[0],&#39;End:&#39;, activity.index[-1]) print(activity.iloc[0][&#39;lat&#39;], activity.iloc[-1][&#39;lat&#39;]) . Start 0 days 00:00:00 End: 0 days 01:16:06 -8.364486 -8.364462 . First, let&#39;s perform a QC evaluation on the data, to check if there&#39;s any invalid or missing data required for the analysis. As you can see in the cell below, there are 5 records with heart rate data missing. We will replace all these with the first HR sensor data available. . import numpy as np group_hr = activity[&#39;hr&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_hr) #There is 5 missing values in HR. Let&#39;s see the positions where they are placed in the frame. print(activity[activity[&#39;hr&#39;].isnull()]) #We will replace all NaN values with the first HR sensor data available activity[&#39;hr&#39;].fillna(activity.iloc[5][&#39;hr&#39;], inplace=True) print(&#39;Total nan after fill:&#39;, activity[&#39;hr&#39;].isnull().sum()) . There are nan records: 5 run_cadence alt dist hr lon lat time 00:00:00 NaN 668.801819 0.000000 NaN -36.577568 -8.364486 00:00:07 NaN 668.714722 5.749573 NaN -36.577465 -8.364492 00:00:10 NaN 668.680603 11.615299 NaN -36.577423 -8.364470 00:00:12 83.0 668.639099 17.306795 NaN -36.577366 -8.364449 00:00:15 82.0 668.600464 22.672394 NaN -36.577312 -8.364429 speed time 00:00:00 0.000000 00:00:07 0.000000 00:00:10 0.000000 00:00:12 2.262762 00:00:15 2.317986 Total nan after fill: 0 . The same QC method will be applied on the elevation , speed and distance sensor data. However, to fill the missing data we will apply a special method in pandas.DataFrame.fillna with the method=&#39;ffill&#39; option. &#39;ffill&#39; stands for &#39;forward fill&#39; and will propagate last valid observation forward. . group_alt = activity[&#39;alt&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_alt) #There is 16 missing values in HR. Let&#39;s see the positions where they are placed in the frame. print(activity[activity[&#39;alt&#39;].isnull()]) #We will replace all NaN values with the last valid alt sensor data available activity[&#39;alt&#39;].fillna(method=&#39;ffill&#39;, inplace=True) print(&#39;Total nan after fill:&#39;, activity[&#39;alt&#39;].isnull().sum()) . There are nan records: 16 run_cadence alt dist hr lon lat speed time 00:17:28 NaN NaN 2423.089355 105.0 NaN NaN 0.000000 00:17:31 NaN NaN 2430.292969 105.0 NaN NaN 0.830682 00:33:40 86.0 NaN 4918.916016 156.0 NaN NaN 2.692340 00:34:14 84.0 NaN 4985.800293 148.0 NaN NaN 2.390405 00:34:25 84.0 NaN 4998.516602 144.0 NaN NaN 2.554120 00:36:11 NaN NaN 5001.374512 101.0 NaN NaN 0.000000 00:46:43 86.0 NaN 6641.856445 138.0 NaN NaN 2.226430 00:46:44 86.0 NaN 6645.643555 138.0 NaN NaN 2.167022 00:46:49 57.0 NaN 6652.708008 136.0 NaN NaN 1.493457 00:48:43 57.0 NaN 6944.145996 147.0 NaN NaN 1.513124 00:52:55 87.0 NaN 7601.044434 158.0 NaN NaN 2.645489 00:52:58 87.0 NaN 7607.790039 157.0 NaN NaN 2.646207 00:53:00 87.0 NaN 7612.979004 157.0 NaN NaN 2.645122 00:53:03 87.0 NaN 7619.605957 158.0 NaN NaN 2.644240 01:01:25 87.0 NaN 8948.444336 148.0 NaN NaN 2.709680 01:03:22 NaN NaN 9025.351562 111.0 NaN NaN 0.742738 Total nan after fill: 0 . group_dist = activity[&#39;dist&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_dist) #There is non missing values in distance series. print(activity[activity[&#39;dist&#39;].isnull()]) group_speed = activity[&#39;speed&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_speed) #There is non missing values in speed series. print(activity[activity[&#39;speed&#39;].isnull()]) . There are nan records: 0 Empty Activity Columns: [run_cadence, alt, dist, hr, lon, lat, speed] Index: [] There are nan records: 0 Empty Activity Columns: [run_cadence, alt, dist, hr, lon, lat, speed] Index: [] . The first question is to see how my heart data changed over time during my workout. In the figure below I present my heart data varying as a function time. For plotting the data I have used the matplotlib package. . import pandas as pd import numpy as np import matplotlib.patches as mpatches from matplotlib import pyplot as plt plt.style.use(&#39;seaborn-poster&#39;) ZONE_COLORS_0 = { 1: &#39;#ffffcc&#39;, 2: &#39;#a1dab4&#39;, 3: &#39;#41b6c4&#39;, 4: &#39;#2c7fb8&#39;, 5: &#39;#253494&#39; } def format_time_delta(time_delta): &quot;&quot;&quot;Create string after formatting time deltas.&quot;&quot;&quot; timel = [] for i in time_delta: hours, res = divmod(i, 3600) minutes, seconds = divmod(res, 60) timel.append(&#39;{:02d}:{:02d}:{:02d}&#39;.format(int(hours), int(minutes), int(seconds))) return timel def _make_time_labels(delta_seconds, nlab=5): &quot;&quot;&quot;Make n time formatted labels for data i seconds&quot;&quot;&quot; label_pos = np.linspace(min(delta_seconds), max(delta_seconds), nlab, dtype=np.int_) label_lab = format_time_delta(label_pos) return label_pos, label_lab def heart_rate_zone_limits(maxpulse=187): &quot;&quot;&quot;Return the limits for the heart rate zones.&quot;&quot;&quot; lims = [(0.5, 0.6), (0.6, 0.7), (0.7, 0.8), (0.8, 0.9), (0.9, 1.0)] return [(maxpulse * i[0], maxpulse * i[1]) for i in lims] def plot_hr(data, maxpulse=184): &quot;&quot;&quot;Plot the heart rate per time with training zones.&quot;&quot;&quot; fig = plt.figure() ax1 = fig.add_subplot(111) ax1.set_facecolor(&#39;0.90&#39;) xdata = data.index.total_seconds().tolist() ydata = data[&#39;hr&#39;].tolist() handles = [] legends = [] zones = heart_rate_zone_limits(maxpulse=maxpulse) for i, zone in enumerate(zones): patch = mpatches.Patch(color=ZONE_COLORS_0[i+1]) legend = &#39;Zone = {}&#39;.format(i + 1) handles.append(patch) legends.append(legend) ax1.axhspan(zone[0], zone[1], color=ZONE_COLORS_0[i+1]) ax1.plot(xdata, ydata, color=&#39;#262626&#39;, lw=3) ax1.legend(handles, legends) ax1.set_ylim(min(ydata) - 2, max(ydata) + 2) label_pos, label_lab = _make_time_labels(xdata, 5) ax1.set_xticks(label_pos) ax1.set_xticklabels(label_lab, rotation=25) ax1.set_xlabel(&#39;Time&#39;) ax1.set_ylabel(&#39;Heart rate / bpm&#39;) fig.tight_layout() return fig fig = plot_hr(activity, maxpulse=184) . From the chart we can conclude that during periodic intervals, I had a rapid loss of the heart rate , probably due to a stop during the workout. Another important insight is that my training zone kept most of the time between the Z2-Z3 (endurance-tempo run). But how did the altitude interfer in this variation ? . For this question, based on my elevation profile (the altitude variation) as a function time, I plot the elevation against function of time to check the influence of the altitude. . def find_regions(yval): &quot;&quot;&quot;Find borders for regions with equal values. Parameters - yval : array_like The values we are to locate regions for. Returns - new_regions : list of lists of numbers The regions where yval is constant. These are on the form ``[start_index, end_index, constant_y]`` with the interpretation that ``yval=constant-y`` for the index range ``[start_index, end_index]`` &quot;&quot;&quot; regions = [] region_y = None i = None for i, ypos in enumerate(yval): if region_y is None: region_y = ypos if ypos != region_y: regions.append([i, region_y]) region_y = ypos # for adding the last region if i is not None: regions.append([i, region_y]) new_regions = [] for i, region in enumerate(regions): if i == 0: reg = [0, region[0], region[1]] else: reg = [regions[i-1][0], region[0], region[1]] new_regions.append(reg) return new_regions def calculate_hr_zones(data, max_heart_rate=184): limits = heart_rate_zone_limits(max_heart_rate) bins = [i[0] for i in limits] hr_zone = np.digitize(data[&#39;hr&#39;], bins, right=False) hr_zone_limis = find_regions(hr_zone) return hr_zone_limis def plot_elevation_hrz(track_name, track_type, data): &quot;&quot;&quot;Plot the elevation profile with heart rate annotations.&quot;&quot;&quot; fig = plt.figure() ax1 = fig.add_subplot(111) ax1.set_facecolor(&#39;0.90&#39;) ax1.set_title(&#39;{}: {}&#39;.format(track_name, track_type)) xdata = data.index.total_seconds().tolist() ydata = data[&#39;alt&#39;].tolist() ax1.plot(xdata, ydata, color=&#39;#262626&#39;, lw=3) handles = [] legends = [] for i in calculate_hr_zones(activity): xpos = xdata[i[0]:i[1]+1] ypos = ydata[i[0]:i[1]+1] ax1.fill_between(xpos, 0, ypos, alpha=1.0, color=ZONE_COLORS_0[i[2]]) for i in range(1, 6): patch = mpatches.Patch(color=ZONE_COLORS_0[i]) legend = &#39;Zone = {}&#39;.format(i) handles.append(patch) legends.append(legend) ax1.legend(handles, legends) ax1.set_ylim(min(ydata) - 2, max(ydata) + 2) label_pos, label_lab = _make_time_labels(xdata, 5) ax1.set_xticks(label_pos) ax1.set_xticklabels(label_lab, rotation=25) ax1.set_xlabel(&#39;Time&#39;) ax1.set_ylabel(&#39;Elevation / m&#39;) fig.tight_layout() return fig fig = plot_elevation_hrz(track_name=&#39;Sanharo 11km&#39;, track_type=&#39;Running&#39;, data=activity) . As we can see at the chart, some intervals due to the elevation gain , the effort is increasingly accordingly, which hits my heart rate. Probably, while running into some elevation, the height and speed increasingly difficult my heart to get enough oxygen to my muscles. Now, let&#39;s see whether the speed also take effect in my heart rate variation. . In the plot below, it shows the correlation between speed x altitude x heart rate. The velocity keeps steadily along all the workout, but when there is a elevation gain and the speed keeps the same, probably there is a variation on my heart rate (Zone Z3 to Zone Z4). . plt.style.use(&#39;seaborn-talk&#39;) def smooth(signal, points): &quot;&quot;&quot;Smooth the given signal using a rectangular window.&quot;&quot;&quot; window = np.ones(points) / points return np.convolve(signal, window, mode=&#39;same&#39;) def plot_dist_hr_velocity(data): fig = plt.figure() ax1 = fig.add_subplot(111) x = activity[&#39;dist&#39;].tolist() y = activity[&#39;alt&#39;].tolist() line1, = ax1.plot(x, y, lw=5) # Fill the area: ax1.fill_between(x, y, y2=min(y), alpha=0.3) ax1.set(xlabel=&#39;Distance / km&#39;, ylabel=&#39;Elevation&#39;) # Add heart rate: ax2 = ax1.twinx() # Smooth the heart rate for plotting: z = data[&#39;hr&#39;].tolist() heart = smooth(z, 51) line2, = ax2.plot(x, heart, color=&#39;#1b9e77&#39;, alpha=0.8, lw=5) ax2.set_ylim(0, 200) ax2.set(ylabel=&#39;Heart rate / bpm&#39;) # Add velocity: ax3 = ax1.twinx() ax3.spines[&#39;right&#39;].set_position((&#39;axes&#39;, 1.2)) # Smooth the velocity for plotting: velocity = data[&#39;speed&#39;] vel = 3.6 * smooth(velocity, 51) line3, = ax3.plot(x, vel, alpha=0.8, color=&#39;#7570b3&#39;, lw=5) ax3.set(ylabel=&#39;Velocity / km/h&#39;) ax3.set_ylim(0, 20) # Style plot: axes = (ax1, ax2, ax3) lines = (line1, line2, line3) for axi, linei in zip(axes, lines): axi.yaxis.label.set_color(linei.get_color()) axi.tick_params(axis=&#39;y&#39;, colors=linei.get_color()) key = &#39;right&#39; if axi != ax1 else &#39;left&#39; axi.spines[key].set_edgecolor(linei.get_color()) axi.spines[key].set_linewidth(2) ax1.spines[&#39;top&#39;].set_visible(False) for axi in (ax2, ax3): for key in axi.spines: axi.spines[key].set_visible(False) axi.spines[&#39;right&#39;].set_visible(True) # Add legend: ax1.legend( (line1, line2, line3), (&#39;Elevation&#39;, &#39;Heart rate&#39;, &#39;Velocity&#39;), loc=&#39;upper left&#39;, frameon=False ) fig = plot_dist_hr_velocity(activity) . Finally, let&#39;s see how many minutes were spent in each HR zone. The plot below shows that most time of the training my heart was between Z3 and Z4 zones. . from matplotlib.cm import get_cmap plt.style.use(&#39;seaborn-talk&#39;) def get_limits_text(max_heart_rate=184): limits = heart_rate_zone_limits(max_heart_rate) txt = { 0: f&#39;$&lt;${int(limits[0][0])} bpm&#39;, 1: f&#39;{int(limits[0][0])}‒{int(limits[0][1])} bpm&#39;, 2: f&#39;{int(limits[1][0])}‒{int(limits[1][1])} bpm&#39;, 3: f&#39;{int(limits[2][0])}‒{int(limits[2][1])} bpm&#39;, 4: f&#39;{int(limits[3][0])}‒{int(limits[3][1])} bpm&#39;, 5: f&#39;$&gt;${int(limits[3][1])} bpm&#39;, } return txt def plot_hr_distribution(data): fig = plt.figure() ax1 = fig.add_subplot(111) time = data.index.total_seconds().tolist() time_in_zones = {} for start, stop, value in calculate_hr_zones(activity): seconds = (time[stop] - time[start]) if value not in time_in_zones: time_in_zones[value] = 0 time_in_zones[value] += seconds sum_time = sum([val for _, val in time_in_zones.items()]) # Check consistency: print(&#39;Times are equal?&#39;, sum_time == (time[-1] - time[0])) zone_txt = get_limits_text() zones = sorted(list(time_in_zones.keys())) percent = { key: 100 * val / sum_time for key, val in time_in_zones.items() } labels = [ f&#39;Zone {i} ({zone_txt[i]}) n({percent[i]:.1f}%)&#39; for i in zones ] values = [time_in_zones[i] for i in zones] times = format_time_delta(values) cmap = get_cmap(name=&#39;Reds&#39;) colors = cmap(np.linspace(0, 1, len(zones) + 1)) colors = colors[1:] # Skip the first color rects = ax1.barh(zones, values, align=&#39;center&#39;, tick_label=labels) for i, recti in enumerate(rects): recti.set_facecolor(colors[i]) width = int(recti.get_width()) yloc = recti.get_y() + recti.get_height() / 2 ax1.annotate( times[i], xy=(width, yloc), xytext=(3, 0), textcoords=&quot;offset points&quot;, ha=&#39;left&#39;, va=&#39;center&#39;, fontsize=&#39;x-large&#39; ) ax1.spines[&#39;top&#39;].set_visible(False) ax1.spines[&#39;right&#39;].set_visible(False) ax1.spines[&#39;bottom&#39;].set_visible(False) ax1.tick_params(bottom=False) ax1.tick_params(labelbottom=False) fig.tight_layout() return fig fig = plot_hr_distribution(activity) . Times are equal? True . With the plots produced at hand, I could check if the training was effective. In this workout, I found out, that I could set my heart rate alert to check when I have to leave the zone by running faster or slower depending on my workout plan and how the altitude had a play in my heart rate variation. . What&#39;s coming to next releases of Runpandas . In future releases, we will provide special methods to runpandas in order to compute the training zones to each record in the activity and the time spent in each zone. We are also planning special plots like those above to be called directly from the package. Stay tunned! .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/training/metrics/features/2021/05/20/trainingzones.html",
            "relUrl": "/general/jupyter/training/metrics/features/2021/05/20/trainingzones.html",
            "date": " • May 20, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Release 0.4.0 with new running metrics and examples package!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . It has beeen a while since our last release, this is because we are working hard in new features in our new release of RunPandas 0.4. Let&#39;s highlight them: . The Activity now provides extra running statistics such as Vertical Altitude Speed (VAM), mean speed, mean pace, gradient, and mean heart rate. | Now we provide in our runpandas.MeasureSeries the capability of conversions such as distance conversion (km - miles), latitudes and longitudes (degrees - radians) and pace conversion (min/km and min/mile). | There is an auxiliar package for loading activity examples for testing and demo purposes: runpandas.datasets . The goal is to enrich with several real examples in FIT, GPX and TCX format files. | Finally, there is a CI workflow for uploading automatically a package to Pypi after release. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to some new running metrics such as mean pace and mean speed. . First let&#39;s explain the differences between mean pace and mean speed. Although both values express similar information, they are the reverse of each other. The Pace is how much time you need to cover a particular distance, while speed is an indicator of the number of meters you are able to cover within one second. These values can be presented different, depending on the measure units used to express these metrics. Pace is given in unit of time per unit of distance, whereas speed is distance over time. . The formulas are: . Speed (m/s) = distance (m) / time (s) . Pace (s/m) = time (sec) / distance (m) . We provide in runpandas new acessors (runpandas.acessors) for computing those metrics: . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . #compute the distance using haversine formula between two consecutive latitude, longitudes observations. activity[&#39;distpos&#39;] = activity.compute.distance() #compute the speed normalized per interval. activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;speed&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 0.335758 00:00:12 1.939984 00:00:16 2.295962 Name: speed, dtype: float64 . print(&#39;Mean speed m/s:&#39;, activity.mean_speed()) print(&#39;Mean pace s/m:&#39;, activity.mean_pace()) . Mean speed m/s: 2.3545989706029533 Mean pace s/m: 0 days 00:00:00.424701 . Generally this is shown in different units like speed (km/h) and pace (min/km): . #convert m/s to km/h by multiplying the factor of 3.6 print(&#39;Mean speed km/h:&#39;, activity.mean_speed() * 3.6) #We define a auxiliar function to convert the pace from sec/m to min/km: def convert_pace_secmeters2minkms(seconds): from pandas import Timedelta pace_min = int((seconds * 1000) / 60) pace_sec = int(seconds * 1000 - (pace_min * 60)) total_seconds = (pace_min * 60) + pace_sec return Timedelta(seconds=total_seconds) pace_min_km = convert_pace_secmeters2minkms(activity.mean_pace().total_seconds()) print(&#39;Mean pace min/km:&#39;, pace_min_km) . Mean speed km/h: 8.476556294170631 Mean pace min/km: 0 days 00:07:04 . Support to gradient and vertical speed. . Gradient is a measure of the route steepness-the magnitude of its incline or slope as compared to the horizontal. Most often presented as a percentage, the gradient of a climb will normally fall somewhere between 3-15 percent. For practical use, it is usually used for estimating the difficulty of the climb during the route. . #Gradient computed through the distance points activity[&#39;grad&#39;] = activity.compute.gradient() activity[&#39;grad&#39;] . time 00:00:00 NaN 00:00:01 NaN 00:00:06 0.000000 00:00:12 -0.121218 00:00:16 0.000000 ... 00:32:51 0.028739 00:32:56 -0.028715 00:33:02 -0.042557 00:33:07 -0.051672 00:33:11 -0.097842 Name: grad, Length: 383, dtype: float64 . VAM (Vertical Altitude Speed) similar to speed except it tracks how fast you go up vertically rather than horizontally between two points. While speed is measured in miles or kilometers per hour, VAM is measured in vertical meters per hour (vmh). It tells you how many meters you would climb if you went up a moderate grade for an hour. . #Vertical Altitude Speed (VAM) in m/s activity[&#39;vam&#39;] = activity.compute.vertical_speed() activity[&#39;vam&#39;] . time 00:00:00 NaN 00:00:01 0.000000 00:00:06 0.000000 00:00:12 -0.240336 00:00:16 0.000000 ... 00:32:51 0.096118 00:32:56 -0.096118 00:33:02 -0.160217 00:33:07 -0.192285 00:33:11 -0.360504 Name: vam, Length: 383, dtype: float64 . Support to other metrics such as mean heart_pace . #Meart heart rate through the activity &#39;bpm&#39;, int(activity.mean_heart_rate()) . (&#39;bpm&#39;, 156) . Some conversion functions available for measure metrics . #convert the speed m/s to km/h activity[&#39;speed&#39;].kph . time 00:00:00 NaN 00:00:01 1.199325 00:00:06 1.208731 00:00:12 6.983941 00:00:16 8.265462 ... 00:32:51 11.864734 00:32:56 12.001946 00:33:02 13.600020 00:33:07 13.428554 00:33:11 13.155589 Name: speed, Length: 383, dtype: float64 . #gradient converted from degrees to percent activity[&#39;grad&#39;].pct . time 00:00:00 NaN 00:00:01 NaN 00:00:06 0.000000 00:00:12 -12.121772 00:00:16 0.000000 ... 00:32:51 2.873890 00:32:56 -2.871543 00:33:02 -4.255745 00:33:07 -5.167165 00:33:11 -9.784157 Name: grad, Length: 383, dtype: float64 . #Total Altitude descent and ascent print(&#39;Ascent&#39;, sum(activity[&#39;alt&#39;].ascent)) print(&#39;Descent&#39;, sum(activity[&#39;alt&#39;].descent)) . Ascent 153.80981445000006 Descent -166.30712890300006 . #distance from meters to kms activity[&#39;dist&#39;].km . time 00:00:00 0.000000 00:00:01 0.000000 00:00:06 0.001107 00:00:12 0.013003 00:00:16 0.022405 ... 00:32:51 4.613642 00:32:56 4.630378 00:33:02 4.652966 00:33:07 4.671573 00:33:11 4.686311 Name: dist, Length: 383, dtype: float64 . An example activities package including several real word activities from different formats. . The runpandas package also comes with extra batteries, such as our runpandas.datasets package, which includes a range of example data for testing purposes. There is a dedicated repository with all the data available. An index of the data is kept here. . example_fit = rpd.activity_examples(path=&#39;Garmin_Fenix_6S_Pro-Running.fit&#39;) print(example_fit.summary) print(&#39;Included metrics:&#39;, example_fit.included_data) . Synced from watch Garmin Fenix 6S Included metrics: [&lt;MetricsEnum.latitude: &#39;latitude&#39;&gt;, &lt;MetricsEnum.longitude: &#39;longitude&#39;&gt;, &lt;MetricsEnum.elevation: &#39;elevation&#39;&gt;, &lt;MetricsEnum.heartrate: &#39;heartrate&#39;&gt;, &lt;MetricsEnum.cadence: &#39;cadence&#39;&gt;, &lt;MetricsEnum.distance: &#39;distance&#39;&gt;, &lt;MetricsEnum.temperature: &#39;temperature&#39;&gt;] . rpd.read_file(example_fit.path).head() . enhanced_speed enhanced_altitude unknown_87 fractional_cadence lap session unknown_108 dist cad hr lon lat temp . time . 00:00:00 0.000 | 254.0 | 0 | 0.0 | 0 | 0 | NaN | 0.00 | 0 | 101 | 13.843376 | 51.066280 | 8 | . 00:00:01 0.000 | 254.0 | 0 | 0.0 | 0 | 0 | NaN | 0.00 | 0 | 101 | 13.843374 | 51.066274 | 8 | . 00:00:10 1.698 | 254.0 | 0 | 0.0 | 0 | 1 | 2362.0 | 0.00 | 83 | 97 | 13.843176 | 51.066249 | 8 | . 00:00:12 2.267 | 254.0 | 0 | 0.0 | 0 | 1 | 2362.0 | 3.95 | 84 | 99 | 13.843118 | 51.066250 | 8 | . 00:00:21 2.127 | 254.6 | 0 | 0.5 | 0 | 1 | 2552.0 | 16.67 | 87 | 100 | 13.842940 | 51.066231 | 8 | . In case of you just only want to see all the activities in a specific file type , you can filter the runpandas.activities_examples, which returns a filter iterable that you can iterate over: . fit_examples = rpd.activity_examples(file_type=rpd.FileTypeEnum.FIT) for example in fit_examples: #Download and play with the filtered examples print(example.path) . https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Fenix_6S_Pro-Running.fit https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Fenix2_running_with_hrm.fit https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Forerunner_910XT-Running.fit . What is coming next ? . Working hard in advanced running metrics such as power , heart rate zones and the feature of printing the summary of the activity with the main statistics. . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/04/24/release-v04.html",
            "relUrl": "/general/jupyter/releases/2021/04/24/release-v04.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Release 0.3.0 with moving metrics!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We are very excited to announce RunPandas 0.3. This release comes with new features and fixes, let&#39;s highlight them: . Support to moving metrics, with the capability of detecting periods of inactivity. | Support to compute some running general statistics such as total time elapsed and moving time elapsed. | Support to imputated statistics: speed in m/s and total distance and distance per position. | Added Zenodo DOI badge | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to calculated running metrics: total elapsed time, speed and total distance . The Activity dataframe now contains special properties that presents some statistics from the workout such as elapsed time, speed and the distance of workout in meters. . #Disable INFO Logging for a better visualization import logging logging.getLogger().setLevel(logging.CRITICAL) . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . The total ellapsed time is the duration from the moment you hit start on your device until the moment you finish the activity. The total distance is the total of meters ran by the athetle in the activity. The speed is measured in meters per second, and returns a runpandas.MeasureSeries.Speed series with the ratio of the distance traveled per record and the number of seconds to run it. . Occasionally, some observations such as speed, distance and others must be calculated based on available data in the given activity. In runpandas there are special accessors (runpandas.acessors) that computes some of these metrics. We will compute the speed and the distance per position observations using the latitude and longitude for each record and calculate the haversine distance in meters and the speed in meters per second. . #total time elapsed for the activity print(activity.ellapsed_time) #distance of workout in meters print(activity.distance) . 0 days 00:33:11 4686.31103516 . #compute the distance using haversine formula between two consecutive latitude, longitudes observations. activity[&#39;distpos&#39;] = activity.compute.distance() activity[&#39;distpos&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 1.678792 00:00:12 11.639901 00:00:16 9.183847 Name: distpos, dtype: float64 . #compute the speed using the distance per position and the time recorded in seconds to run it. activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;speed&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 0.335758 00:00:12 1.939984 00:00:16 2.295962 Name: speed, dtype: float64 . In runpandas we will also have special atributes at the runpandas.MeasureSeries that can compute transformations such as speed conversion from m/s to km/h. . #kph property that converts m/s to km/h. activity[&#39;speed&#39;].kph . time 00:00:00 NaN 00:00:01 1.199325 00:00:06 1.208731 00:00:12 6.983941 00:00:16 8.265462 ... 00:32:51 11.864734 00:32:56 12.001946 00:33:02 13.600020 00:33:07 13.428554 00:33:11 13.155589 Name: speed, Length: 383, dtype: float64 . Support to detection of periods of inactivity (Moving time) . With the advent of the advanced tracking devices, they are capable of estimating the time that the runner was active. Then new devices can now calculate the moving time based on the GPS locations, distance, and speed of the activity. There are cases that the athlete can also use the pause button to deliberately pause the activity for any reason (stoplights, active rests, bathroom stops or even stopping for photos). . Runpandas will attempt to calculate based on the metrics available in the activity the moving time by detecting all the periods of inactivity. The formula is based on the speed per record (distance recorded) below a specified threshold. It is a powerful metric that the runner can now know to see his real performance, removing any bias related to stopped periods. This metric is quite popular also in several tracking platforms such as Garmin and Strava. . With the new dataframe auxiliar method Activity.only_moving, runpandas detects the periods of inactivity and returns the moving series containing all the observations considered to be stopped. It returns a runpandas.Activity dataframe with a special column named moving indexed by the Activity&#39;s TimeIndex. It is pandas.Series containing a vector of booleans which indicates the stopped periods. Boolean indexing it will help build quick filters to ignore any observations considered by the algorithm as a inactivity. . activity_only_moving = activity.only_moving() print(activity_only_moving[&#39;moving&#39;].head()) . time 00:00:00 False 00:00:01 False 00:00:06 False 00:00:12 True 00:00:16 True Name: moving, dtype: bool . Now we can compute the stopped time and the moving time. . print(&#39;The stopped period:&#39;, activity_only_moving[activity_only_moving[&#39;moving&#39;] == False].index.sum()) . The stopped period: 0 days 00:00:07 . print(&#39;The moving time:&#39;, activity_only_moving.moving_time) . The moving time: 0 days 00:33:05 . What is coming next ? . We will load several running metrics and statistics to our activities and measure series in order to provide the user deeper details about their running activities. It will includes heart time zones, average speed, personal best records per distance, and more! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/03/17/release-v03.html",
            "relUrl": "/general/jupyter/releases/2021/03/17/release-v03.html",
            "date": " • Mar 17, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Understanding moving time vs ellapsed time, distance and speed/pace calculations",
            "content": "Sport tracking applications and the social networks are quite popular among the runners nowadays. Everyone wants to perform the best run looking for a better pace, distance or time. But have you wondered how these metrics are calculated ? . In this post we’ll use gpx-file downloaded from Strava social application, extract, and analyse the gpx data of one single route. We’ll start with extracting the data from the gpx-file into a convenient runpandas.Activity dataframe. From there we’ll explore the data and try to replicate the stats and graphs that the interface of one most popular running application provides us with. . Getting the data . Most of the popular tracking apps allow you to download your activity as a gpx or tcx file. In this post, we will analyse a 12km run from Strava. The gpx-file, short for GPS Exchange Format, can usually be obtained by clicking on export. The screenshot below shows you where you can download your gpx-file in Strava. You can download the file used in this article here. . . Now, we want to load our gpx data into a runpandas.Activity. Take a look at your start point and end point and make sure everything makes sense (i.e. start time &lt; end time). If not, there might be something wrong with your data, or you might have forgotten about some tracks or segments. . import runpandas activity = runpandas.read_file(&#39;./data/post-metrics.gpx&#39;) print(&#39;Start&#39;, activity.index[0],&#39;End:&#39;, activity.index[-1]) print(activity.iloc[0][&#39;lat&#39;], activity.iloc[-1][&#39;lat&#39;]) . Start 0 days 00:00:00 End: 0 days 01:25:27 -8.045075 -8.036119 . The head of the activity (frame) should look like this: . activity.head(8) . cad alt hr lon lat . time . 00:00:00 84.0 | 12.7 | 174.0 | -34.893787 | -8.045075 | . 00:00:04 84.0 | 12.7 | 174.0 | -34.893787 | -8.045075 | . 00:00:06 84.0 | 12.7 | 174.0 | -34.893810 | -8.045115 | . 00:00:08 84.0 | 12.7 | 174.0 | -34.893852 | -8.045168 | . 00:00:10 84.0 | 12.7 | 174.0 | -34.893890 | -8.045216 | . 00:00:13 84.0 | 12.7 | 174.0 | -34.893898 | -8.045266 | . 00:00:16 85.0 | 12.7 | 174.0 | -34.893898 | -8.045282 | . 00:00:19 86.0 | 12.7 | 174.0 | -34.893906 | -8.045329 | . It is important to notice that the time interval between two data points isn&#39;t constant. This happens because the device which records the data can&#39;t always provide the GPS-data due to connectivity problems or even to hardware limitation. In case of such a failure/limitation the data point is skipped (without an error) and the app will collect the data at the next time interval. So keep in mind that for further analysis we can&#39;t assume that the interval between all points is the same. . Plotting the data . Now with the data loaded, we can explore it with some basic plots. Strava provides some interesting graphs to the runner such as the 2D map (longitude vs latitude) and elevation gain during the activity (altitude vs time). Using native plotting tools we can come to quite similar results. . import matplotlib.pyplot as plt plt.plot(activity[&#39;lon&#39;], activity[&#39;lat&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fa8cb4f0790&gt;] . . axis = activity.plot.area(y=&#39;alt&#39;) axis.set_ylim(0,100) . (0.0, 100.0) . . Calculating the total distance . Now let&#39;s going through the key metrics of the activity such as distance and speed. A quick look can misguide you into incorrect calculations. The first one is the distance between two LL-points (latitude, longitude) which it isn&#39;t a straight line, but spherical. . . There are two main approaches to calculate the distance between two points on a spherical surface: the Haversine distance and the Vincenty distance. The two formulas take a different approach on calculating the distance, but this is outside the scoop of this post. The maths behind both approaches can be found here. . Another issue about the distance calculation is if the data have been calculated solely based on latitude and longitude, without taking into consideration the elevation gain or loss, then the distance covered can be underestimated. The easiest way to do this, is to compute the spherical 2d distance and then use the Euclidean formula to add the altitude measurements. The formula below shows this last step. . If the uncorrected distance covered at time point $t_{i}$ is $d_{2,i}$, to correct the distance covered between time point $t_{i-1}$ and time point $t_{i}$ to begin{equation} d_{i} - d_{i-1} = sqrt{ left(d_{2,i} - d_{2,i-1} right)^{ ! !2} + left(a_{i} - a_{i-1} right)^{ ! !2}} end{equation} , where $d_{i}$ and $a_{i}$ are the corrected cumulative distance and the altitude at time $t_{i}$, respectively. . Now with the theoretical background presented, we can start implementing these formulas in our code. We will apply in all data points all possible implementations of our distance formula (Haversine or Vicenty and 2d or 3d) and compute the total distance for every data point by using the dataframe function cumsum. . There are geodesic python libraries already available with Vicenty and Haversine formulas, so we will import them here for our distance calculations. . #pip install haversine &amp; pip install vincenty from vincenty import vincenty as vn from haversine import haversine as hv from haversine import Unit import numpy as np . activity[&#39;shift_lon&#39;] = activity.shift(1)[&#39;lon&#39;] activity[&#39;shift_lat&#39;] = activity.shift(1)[&#39;lat&#39;] #compute the vincenty 2d distance activity[&#39;distance_vin_2d&#39;] = activity[[&#39;lat&#39;, &#39;lon&#39;, &#39;shift_lat&#39;, &#39;shift_lon&#39;]].apply(lambda x: vn( (x[0], x[1]),(x[2], x[3])), axis=1) #transform the value in meters activity[&#39;distance_vin_2d&#39;] = activity[&#39;distance_vin_2d&#39;] * 1000 #compute the haversine 2d distance activity[&#39;distance_hav_2d&#39;] = activity[[&#39;lat&#39;, &#39;lon&#39;, &#39;shift_lat&#39;, &#39;shift_lon&#39;]].apply(lambda x: hv((x[0], x[1]),(x[2], x[3]), unit=Unit.METERS), axis=1) #compute the total distance activity[&#39;distance_vin_no_alt&#39;] = activity[&#39;distance_vin_2d&#39;].cumsum() activity[&#39;distance_hav_no_alt&#39;] = activity[&#39;distance_hav_2d&#39;].cumsum() #compute the vincenty and haversine 3d activity[&#39;shift_alt&#39;] = activity.shift(1)[&#39;alt&#39;] activity[&#39;alt_dif&#39;] = activity[[&#39;alt&#39;, &#39;shift_alt&#39;]].apply(lambda x: x[1] - x[0], axis=1) activity[&#39;distance_vin_3d&#39;] = activity[[&#39;distance_vin_2d&#39;, &#39;alt_dif&#39;]].apply(lambda x: np.sqrt(x[0]**2 + (x[1])**2), axis=1) activity[&#39;distance_hav_3d&#39;] = activity[[&#39;distance_hav_2d&#39;, &#39;alt_dif&#39;]].apply(lambda x: np.sqrt(x[0]**2 + (x[1])**2), axis=1) #compute the total distances for vincenty and haversined 3D activity[&#39;distance_vin&#39;] = activity[&#39;distance_vin_3d&#39;].cumsum() activity[&#39;distance_hav&#39;] = activity[&#39;distance_hav_3d&#39;].cumsum() activity.drop([&#39;shift_lon&#39;, &#39;shift_lat&#39;, &#39;shift_alt&#39;], axis=1) #present the results activity[[&#39;distance_vin&#39;, &#39;distance_hav&#39;, &#39;distance_hav_3d&#39;, &#39;distance_vin_3d&#39;]] . distance_vin distance_hav distance_hav_3d distance_vin_3d . time . 00:00:00 NaN | NaN | NaN | NaN | . 00:00:04 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 00:00:06 5.099000 | 5.118162 | 5.118162 | 5.099000 | . 00:00:08 12.568000 | 12.609153 | 7.490991 | 7.469000 | . 00:00:10 19.330000 | 19.390883 | 6.781730 | 6.762000 | . ... ... | ... | ... | ... | . 01:25:17 12544.272150 | 12564.172393 | 6.437592 | 6.421000 | . 01:25:21 12559.222485 | 12579.203834 | 15.031441 | 14.950334 | . 01:25:23 12564.868485 | 12584.874982 | 5.671148 | 5.646000 | . 01:25:25 12570.232485 | 12590.267705 | 5.392723 | 5.364000 | . 01:25:27 12575.313485 | 12595.361143 | 5.093437 | 5.081000 | . 1697 rows × 4 columns . For futher convenice, we can extract the data in our previously created activity. Let&#39;s check the results with the following print comand. . print(&#39;Vicenty 2D: &#39;, activity[&#39;distance_vin_no_alt&#39;].max()) print(&#39;Haversine 2D: &#39;, activity[&#39;distance_hav_no_alt&#39;].max()) print(&#39;Vincenty 3D: &#39;, activity[&#39;distance_vin&#39;].max()) print(&#39;Haversine 3D: &#39;, activity[&#39;distance_hav&#39;].max()) . Vicenty 2D: 12574.600999999993 Haversine 2D: 12594.649752172338 Vincenty 3D: 12575.313484827602 Haversine 3D: 12595.361142855156 . If we compare the distance calculations between the app and ours, we will see they are almost similar. . . But why do we have 50m of difference between our internal calculations and the distance showed in the app ? It is explained in an article from Strava&#39;s support team. . A flat surface is assumed, and vertical speed from topography is not accounted for. — Strava In this scenario our 2d calculations are right and the we might conclude the app doesn’t take elevation into account. The difference between the distance proposed by the app and our estimate is about 50m (0.03%). Note that this difference will increase if you undertake more altitude-intense activities (mountain biking or hiking). . Now let&#39;s going forward to our next metric, the total activity time ellapsed x moving time. . Calculating the time ellapsed x moving time . def strfdelta(tdelta, fmt): d = {&quot;days&quot;: tdelta.days} d[&quot;hours&quot;], rem = divmod(tdelta.seconds, 3600) d[&quot;minutes&quot;], d[&quot;seconds&quot;] = divmod(rem, 60) return fmt.format(**d) print(&#39;Total time: &#39; , strfdelta(activity.index[-1], &quot;{hours} hour {minutes} min {seconds} sec&quot;)) . Total time: 1 hour 25 min 27 sec . The total time elapsed totally agrees with our calculations, but the moving time seems to be diferent. Let us explain the basic concepts: Elapsed time is the duration from the moment you hit start on your device or phone to the moment you finish the activity. It includes stoplights, coffee breaks, bathroom stops and stopping for photos. Moving time, on the other hand, is a measure of how long you were active, this can be realistic when we have to slow down and stop for a traffic light, for example. . Let’s see if we can figure out which threshold Strava uses to stop the timer (and therefore boost our average speed). To do so, we need to create a new variable that calculates our movement in meters per second (and not just movement per data point, hence why we created the time difference variable). Let’s do this for our haversine 2d distance, since that’s the closest approximation of the distance proposed by the app. . import pandas as pd import numpy as np activity[&#39;time&#39;] = activity.index activity[&#39;time_dif&#39;] = (activity.time - activity.time.shift(1).fillna(activity.time.iloc[0]))/np.timedelta64(1,&#39;s&#39;) activity[&#39;distance_dif_per_sec&#39;] = activity[&#39;distance_hav_2d&#39;] / activity[&#39;time_dif&#39;] activity[&#39;distance_dif_per_sec&#39;] . time 00:00:00 NaN 00:00:04 0.000000 00:00:06 2.559081 00:00:08 3.745496 00:00:10 3.390865 ... 01:25:17 3.218796 01:25:21 3.757777 01:25:23 2.835574 01:25:25 2.696362 01:25:27 2.546719 Name: distance_dif_per_sec, Length: 1697, dtype: float64 . With this new variable we can iterate through a list of thresholds. Let&#39;s assume values between 50 cm and 1 meter, and try to evaluate which one adds up to a timer time-out closest to 640 seconds (~=10 minutes). . for treshold in [0.5, 0.6, 0.7, 0.8, 0.9, 1]: print(treshold, &#39;m&#39;, &#39; : Time:&#39;, sum(activity[activity[&#39;distance_dif_per_sec&#39;] &lt; treshold][&#39;time_dif&#39;]), &#39; seconds&#39;) . 0.5 m : Time: 574.0 seconds 0.6 m : Time: 577.0 seconds 0.7 m : Time: 640.0 seconds 0.8 m : Time: 640.0 seconds 0.9 m : Time: 640.0 seconds 1 m : Time: 640.0 seconds . As we can see at the table above, the movement per second was less than 80-70 centimeters, the application didn&#39;t consider it as movement and discard those intervals (it&#39;s about 2.9 km/h , a speed far below that most people do in their walking pace). Since we don&#39;t have the algorithm used for the real calculation in the app, we can get to an approximate moving time. . total_time = activity[&#39;time_dif&#39;].sum() stopped_time = sum(activity[activity[&#39;distance_dif_per_sec&#39;] &lt; 0.8][&#39;time_dif&#39;]) pd.Timedelta(seconds=total_time - stopped_time) . Timedelta(&#39;0 days 01:14:47&#39;) . Calculating the speed and pace . With the moving time and distance calculated, we can now calculate the pace and speed. Speed is calculated by dividing the distance traveled in meters by the time it took in seconds, and then converted to km/h. . activity[&#39;speed&#39;] = (activity[&#39;distance_hav_2d&#39;] / activity [&#39;time_dif&#39;]) * 3.6 . Next we will filter out all the data where the movement per second is larger than 80 centimeters, based on the threshold we evaluated above. . activity_with_timeout = activity[activity[&#39;distance_dif_per_sec&#39;] &gt; 0.8] . Finally, we compute the weighted average speed and convert it to minutes and seconds per kilometers to get the Pace metric. . def pace(speed, fmt): d = {&quot;hours&quot;: 0} d[&quot;minutes&quot;] = np.floor(60 / speed) d[&quot;seconds&quot;] = round(((60 / speed - np.floor(60 / speed))*60), 0) return fmt.format(**d) avg_km_h = (sum((activity_with_timeout[&#39;speed&#39;] * activity_with_timeout[&#39;time_dif&#39;])) / sum(activity_with_timeout[&#39;time_dif&#39;])) print(&#39;Speed:&#39;, avg_km_h , &#39;km/h&#39;) print(&#39;Cadence:&#39; , pace(avg_km_h, &quot;{hours} hour {minutes} min {seconds} sec&quot;)) . Speed: 10.065838469772745 km/h Cadence: 0 hour 5.0 min 58.0 sec . The results compared to the proposed by our app show similar values, with average speed of 5 minutes and 58 seconds per kilometer, a difference of only just 2 secs. . Let&#39;s plot our average speed for every 10 seconds to see our speed floats during the run. For this plot we will need the cumulative sum of our time differente to 10 seconds and plot the aggregated speed against it. . activity[&#39;time_10s&#39;] = list(map(lambda x: round(x, -1), np.cumsum(activity[&#39;time_dif&#39;]))) plt.plot(activity.groupby([&#39;time_10s&#39;]).mean()[&#39;speed&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fa8c893f550&gt;] . The result shown is a smooth line plot where we check the speed (km/h) vs the time in seconds. . Calculating the elevation gain . The last metric we will explore is the elevation gain. According to the apps documentation, the cumulative elevation gain refers to the sum of every gain elevation throughout an entire Activity. . Based on that, we can compute the elevation gain by mapping over our altitude difference column of our dataframe. . activity_with_timeout.loc[activity_with_timeout[&#39;alt_dif&#39;] &gt; 0][&#39;alt_dif&#39;].sum() . 38.0 . The elevation calculated is far away from what the app showed (about 25m). Checking the altitude difference column values we can see that there are measures down to 10 centimeters. After reading the docummentation, we found out that the elevation data go through a noise correction algorithm. It is based on the a threshold where climbing needs to occur consistently for more than 10 meters for activities without strong barometric or two meters for an activity with the barometric data before it&#39;s added to the total elevation gain. . elevations = zip(list(activity_with_timeout[&#39;alt&#39;]), list(activity_with_timeout[&#39;distance_hav_2d&#39;])) THRESHOLD_METERS = 10 def calculate_elevation_gain(elevations): elevations = list(elevations) thresholdStartingPoint = elevations[0][0] diff_distance = 0 count_diff = 0 gain = 0 valueAgainstThreshold = 0 for elevation, distance in elevations: diff = elevation - thresholdStartingPoint diff_distance+=distance if diff &gt; 0: valueAgainstThreshold += diff if abs(diff_distance) &gt;= THRESHOLD_METERS: gain += valueAgainstThreshold diff_distance = 0 valueAgainstThreshold = 0 else: diff_distance = 0 valueAgainstThreshold = 0 thresholdStartingPoint = elevation return gain #plt.plot(activity[&#39;alt_dif&#39;]) print(calculate_elevation_gain(elevations)) . 25.30000000000002 . The new result is 25.2m, very close to the elevation propose by the app. Based on that, we could recalculate the 3rd distances to get these new elevation values into account to get the distance closest to the 2d distance. . What&#39;s next ? . In this article we presented some popular metrics in runner&#39;s world such as moving time, cadence, pace and elevation gain. The calculations behind the metrics were also detailed and we gave a possible approximation of some of the algorithms used by a famous tracking running application, since we don&#39;t have access, of course,how they implemented it. . The next steps will be implement these metrics as properties, methods of the runpandas.Activity dataframe. We will release it soon with examples detailed at one of our future posts. Keep following here! . — Please feel free to bring any inconsistencies or mistakes by leaving a comment below.- .",
            "url": "https://corriporai.github.io/pandasrunner/calculation/gps/metrics/jupyter/features/tracking/2021/01/29/metrics.html",
            "relUrl": "/calculation/gps/metrics/jupyter/features/tracking/2021/01/29/metrics.html",
            "date": " • Jan 29, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Release 0.2.0 and support to Strava!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We are very excited to announce RunPandas 0.2. This release comes with new features and fixes, let&#39;s highlight them: . Improved docummentation with new sections such as User Guide, Install Guide, API Reference and Changelog. | Support to new code and docummentation third-party plugins like CodeFactor, Pepy, Zenodo and Binder. | Support to read multiple tracking files from a single directory | Added the feature of fetching activity data from social network Strava. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Read multiple tracking files from a single directory . With the new module function runpandas.read_dir , you can reall all the files in a directory and iterate over them. It uses runpandas.read_file and returns a generator. It is important to notice that read_dir expects all the files to be of a supported file format in the directory. . from pathlib import Path import runpandas directory = Path(&quot;path/to/some/dir/&quot;) for activity in runpandas.read_dir(directory): # Do things with the activities . Support to fetch activity stream data from Strava . We addded the support to fetch a single activity stream from the social sports app Strava. The function runpandas.read_strava assumes that you have an API access token and already performed an API authentication. You can use a support script available at our repository strava_auth_handler.py that we developed using the library stravalib. The basic usage is simple and it saves the API token into a file. . It is required to have a client_id and and a client_secret, for that you must have a developer account at strava and create an application. See further at strava: (https://developers.strava.com/) . Here a simple example about how to call : . $ python scripts/strava_auth_handler.py --client_id YOUCLIENTID --client_secret YOURCLIENTSECRET $ more access_token.json &quot;{ &quot;access_token &quot;: &quot;YOURACCESSTOKEN &quot;, &quot;refresh_token &quot;: &quot;YOURREFRESHTOKEN &quot;, &quot;expires_at &quot;: 1607634877}&quot; . read_strava() returns a runpandas.Activity with column runpandas.MeasureSeries matching Runpandas nomenclature. . #Disable INFO Logging for a better visualization import logging logging.getLogger().setLevel(logging.CRITICAL) . import runpandas activity = runpandas.read_strava(activity_id=4437021783, access_token=&quot;c1370af8341f5c5696988d54a1560130737f5954&quot;) activity.head(5) . 2020-12-06 06:36:27 . moving velocity_smooth grade_smooth alt cad dist hr lon lat . time . 00:00:00 False | 0.0 | 1.1 | 6.4 | 79 | 0.0 | 111 | -34.847439 | -8.016994 | . 00:00:04 True | 1.4 | 1.2 | 6.4 | 79 | 5.6 | 111 | -34.847324 | -8.016978 | . 00:00:06 True | 1.6 | 0.9 | 6.5 | 79 | 9.5 | 111 | -34.847252 | -8.016969 | . 00:00:09 True | 2.3 | 1.2 | 6.6 | 79 | 16.9 | 111 | -34.847221 | -8.016894 | . 00:00:12 True | 2.3 | 1.1 | 6.6 | 79 | 23.2 | 111 | -34.847176 | -8.016860 | . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/01/13/release-v02.html",
            "relUrl": "/general/jupyter/releases/2021/01/13/release-v02.html",
            "date": " • Jan 13, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "The first runpandas release is alive! Welcome to the release 0.1.0!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . Today we are happy to announce the initial release of runpandas, which makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to make the pandas data analysis package support reading, transforming and enable running metrics analytics. . How to use runpandas . Require the runpandas module in you Python Code and use our tracking file reader in case of reading local files in tcx, gpx or fit format. . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . The data file is loaded into a runpandas.Activity , which is a subclass of the pandas.DataFrame and provides some additional features. The library also provides for certain columns specific methods that extends the pandas.Series subclasses. In this example below, we get time, altitude, distance, heart rate and geo position (lat/long). . activity.head(5) . alt dist hr lon lat . time . 00:00:00 178.942627 | 0.000000 | 62.0 | -79.093187 | 35.951880 | . 00:00:01 178.942627 | 0.000000 | 62.0 | -79.093184 | 35.951880 | . 00:00:06 178.942627 | 1.106947 | 62.0 | -79.093172 | 35.951868 | . 00:00:12 177.500610 | 13.003035 | 62.0 | -79.093228 | 35.951774 | . 00:00:16 177.500610 | 22.405027 | 60.0 | -79.093141 | 35.951732 | . For instance, if you want to get the base unit for the altitude alt data or the distance dist data: . activity.alt.base_unit . &#39;m&#39; . activity.alt.sum() . 65883.68151855901 . activity.dist.base_unit . &#39;m&#39; . activity.dist[-1] . 4686.31103516 . Since the Activity is a DataFrame, we can play with data and create some visualizations. In this example we use the built in matplotlib based plot function to present the distance x time. . activity[[&#39;dist&#39;]].plot() . &lt;AxesSubplot:xlabel=&#39;time&#39;&gt; . Finally, let&#39;s watch a glimpse of the map route by plotting a 2d map using logintude vs latitude. . activity.plot(x=&#39;lon&#39;, y=&#39;lat&#39;) . &lt;AxesSubplot:xlabel=&#39;lon&#39;&gt; . That&#39;s some of features available! Please check out the runpandas docummentation link for the package&#39;s full API. . How to install runpandas . The release version of runpandas (0.1.0) is available on PyPI, the Python Package Index repository as runpandas link. . If you haven&#39;t already installed, start by downloading and installing with pip: . $ pip install runpandas --upgrade . Please note that we currently only support Python 3.6+. You are now ready to start using the runpandas. . Roadmap . We have big plans for runpandas, including not limited to: . Adding suport reading running tracking sessions from social application Strava; | Adding support reading track files giving a directory as parameter; | Better docummentation with user guide and install guidelines; | Support to session of activities | Support to special plots such as routes, average heart zones, personal bests for specific distances. | . You can see the live roadmap of features at our issues repository. . Thanks . It is our first release after two months of planning and coding. We hope that you find runpandas helpful - it is still very young, and result of some of my ideas and needs to perform personal running analysis. So don&#39;t be afraid to get in touch and let us know what features you would like to add next, Feel free to raise an issue if you spot any bugs! .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/01/07/release-v01.html",
            "relUrl": "/general/jupyter/releases/2021/01/07/release-v01.html",
            "date": " • Jan 7, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Welcome to runpandas",
            "content": "What is runpandas ? . Welcome to the runpandas library. The framework was developed by me, Marcel Caraciolo targeted at getting the most from your running data. . Recent technological advances to GPS-enabled tracking devices is transforming the aspects of training and competition in fitness activities such as running, cycling and swimming. Those devices produces detailed tracking data among several sports data available for anyone interested at its analysis. This enables a descriptive analysis associated with the related data, such as performance, impact of volume of training or just reviewing the historical activities. There are several devices or applications for sports tracking offered by manufacturers of the tracking devices, such as Garmin, Polar, and through a wide range of applications for devices such as smartphones and smartwatches, e.g., Strava, Endomondo, and Runtastic Running GPS Tracker. . Limiting to range of data science open-source packages available, there is only a handful of packages specific to sport data and their analysis. Within Python ecosystem, one of the most popular programming languages for data science, there is a gap to fill between the collection of tracking data and the analysis of such data. Pandas is a popular package for data analysis, and several specific domain libraries as built on top of it. At my research at time, I didn’t find many sports data analysis package within the Python + Pandas ecosystem. . As a possible alternative, runpandas package comes as a set of utilities to import sports data from GPS-enabled devices or even track activities applications, and, after careful processing, organises them in data frames which can provide information about the units of measurement (e.g. distance and speed units) as well of any data operations that have been carried out (e.g., personal best records, heart efforts, elevation gain). Runpandas extends the datatypes used by pandas, so it can benefit its core operations for the handling of measurement units and for summarising and visualising tracking data. . . Real motivation behind runpandas . Many runners use Strava, Garmin , Nike plus , Runstatic App (iOS and Android) to track running activities. The APP and its companion website jointly provide many visual charts with analytical metrics to help runners review their running performances to set up new training plans or make adjustments. To a data scientist runner like me, it would be ideal that our data be downloaded and analyzed locally in my own way to have more fun or get different analysis. . Don’t get me wrong, I am huge fan and user of several running apps, but sometimes I get frustrated with the data processing and visualization that major providers offer, or sometimes I want just to play around with my tracking data and plot my running routes using Maps libraries or to calculate my personal best times for specific distances. Runpandas is an ellegible solution for data science runners like me, fans of digging sports data combined with all possibilities of rich analysis matching against weather, temperature, marathons, routes datasets. So, welcome to the world of running analytics, where data science meets the running. . How can I get started ? . . If you read until here, it is probably because you are interested at runpandas or the possibilities of performing your own analysis. I will give you some options: . If you want to check the documentation for more details on using runpandas: Read the Docs | If you already know the library, and want to contribute: Github | You are just a curious or a runner, and wants to see the some examples: | Another introduction to runpandas is my undergoing book Analysing your own running data with Python on Jupyter notebooks: | . . Marcel Caraciolo, Computer Engineer and Bioinformatics Specialist at Genomika Einstein laboratory. Currently responsible for lab systems product management. Interested at data science, productivity techiques and product management. Amateur runner and lego architecture sets lover. @marcelcaraciolo corriporai.github.io/pandasrunner . .",
            "url": "https://corriporai.github.io/pandasrunner/general/2020/08/01/welcome-to-runpandas.html",
            "relUrl": "/general/2020/08/01/welcome-to-runpandas.html",
            "date": " • Aug 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". My name is Marcel Caraciolo, creator of runpandas. When I am not running or coding, I manage the bioinformatics team at the Genomika Einstein, a genetics molecular laboratory, and product manager for some laboratory management systems. Amateur runner, lover of Lego Architecture sets and passioned about productivity and agile techniques. .",
          "url": "https://corriporai.github.io/pandasrunner/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://corriporai.github.io/pandasrunner/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}