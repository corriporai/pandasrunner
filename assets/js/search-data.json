{
  
    
        "post0": {
            "title": "Release 0.5.2 improvements on support to Python 3.10 and new Pandas releases. Strava Client Authentication now integrated!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We published this minor release with some bug fixes , new Python and Pandas releases support and Strava Client Authentication. In this release of RunPandas 0.5.2, we include: . CI now updated to include build tests with Python 3.9 and Python 3.10. It removed 3.6 Python official support. | CI now updated to include build tests with Pandas version 1.4.2 . | Strava comes with social client authentication tool integrated. Thanks to contributor @bitner ! | Fixes on Test suite and read the docs build suite. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . In order to download the Strava activities, you must authenticate your dev app through Strava servers in order to get a valid access token. Previously, this task had to be performed outside runpandas. Now Runpandas is powered with this handful tool, so you can easily can get the access token and store it locally , so you can use it as long as it doesn&#39;t expire it. . . Screenshot from the Strava Authentication Authorization WebSite . How does it work ? . We load the environment variables from our terminal or use a .env file with the STRAVA social app personal access tokens. You can create your own using the link instructions here: https://developers.strava.com/ . %load_ext autoreload %autoreload 2 import warnings warnings.filterwarnings(&#39;ignore&#39;) import runpandas import os import pandas as pd pd.set_option(&#39;display.max_rows&#39;, 500) . from dotenv import load_dotenv load_dotenv() . True . Firstly, import the runpandas StravaClient, create a Client instance, and read in the client ID and secret loaded previously. Next the one time authentication. The command client.authenticate_web will open a browser with a URL for the athlete to use to approve access to their data from the app. . The athlete is then prompted to log in to the Strava website and give consent to the requesting application. Once the user authorizes, it will store the access token and refresh token. From this point this access token, which lasts for 6 hours, will be what you need to access data. The client also save it locally so it can be re-read and refreshed as needed. . client = runpandas.StravaClient() client.authenticate_web() . problems on reading token.json file. It considers an empty file. . {&#39;access_token&#39;: &#39;e728378922ebe5e07371904c83771d18a716864f&#39;, &#39;refresh_token&#39;: &#39;59c8537628a19d70330e5aca2ec5a558023a2c03&#39;, &#39;expires_at&#39;: 1660964653} . As shown above, the activity now after loaded can be analysed as any other activity in runpandas! . activity = runpandas.read_strava(&#39;7329257123&#39;) activity.summary() . Unable to set attribute media_type on entity &lt;ActivityPhotoPrimary id=None&gt; . Session Running: 18-06-2022 07:08:07 Total distance (meters) 21389.8 Total ellapsed time 0 days 02:02:20 Total moving time 0 days 02:02:19 Average speed (km/h) NaN Average moving speed (km/h) NaN Average pace (per 1 km) NaN Average pace moving (per 1 km) NaN Average cadence 87.7889 Average moving cadence 87.847 Average heart rate 155.674 Average moving heart rate 155.713 Average temperature NaN dtype: object . What is coming next ? . The next releases will focus on supporting marathon results and some plots support. It will be awesome, keep tunned! . Sorry . Sorry for the long delay since the last release, I was kept busy working on other projects. But I will be more frequent here updating our favorite data running sports package! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2022/08/19/release-052.html",
            "relUrl": "/general/jupyter/releases/2022/08/19/release-052.html",
            "date": " • Aug 19, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Using Runpandas to explore Nike Run Activity Data",
            "content": "Using the Nike Run to analyze your activities. . My wife started to run seriously since last year and used the Nike Run app to track her runs. Unfortunately, there isn&#39;t an open API to get the data and get advanced analytics on her activities. So she asked me, if there was a way to perform some analysis on her own. At this tutorial, I will show how I fetched the data from Nike Run social app. Then, I will show how I explored that data using Python and RunPandas. Even this article is focused specifically on Nike Run activities, it will be useful for anyone interesteing in learning more about how get your running data and play with it. . Getting your data . There are three things you will need up front. . A Nike Run member account | A environment to run Python. | To start, I will assume you have a Nike Run account with at least one activity logged. | . There is a commandline program called nrc-exporter that automates the data export to a local directory. We will use it here. The first step, is to use the terminal and install the package using pip package installer. . pip install nrc-exporter . To start using you will need the the authentication token that you can get when you login at the Nike Web account. Here are the steps: . Login into your Nike account; | Open the developer tools -&gt; Application. Then, you need to copy the token (Authorization field) as shown at the image below: | . . At your terminal, just execute the nrc-exporter with the given token as shown below: . nrc-exporter -t token . You will see the screen below after running the tool: . . All your running data will be downloaded to a folder named activities from where you executed the script. All the activities are in JSON format. If this step did not work for you, you can see other alternatives at the website of the owner of the tool nrc-exporter. Take a look there! . Analyzing your activity data . In this section, I will walk you through how I used Runpandas, a library focused on running data exploratory analysis, to answer some questions that she asked me to look into: . Have my runs gotten faster over time? | Is my max speed higher on shorter runs? | Do I run longer distances on the weekend than during the week? | Do I run faster on the weekend than during the week? | How many days do I rest compared to days I run? | How many kilometers did I cover ? | Which month of the year do I run the fastest? | Which month of the year do I run the longest distance? | How has the average distance per run changed over the years? | How has the average time per run changed over the years? | How has my average speed per run changed over the years? | Am I ready for a half-marathon? What would it be my finishing time ? | . Data Import . Now, to get the data into a table, I’ll fun the following code. To read the json directory, you can run the runpandas.read_dir_nikerun method to create a Runpandas Activity Dataframe combining the workouts as individual rows . If you are unfamiliar with Pandas or Runpandas, consider them as Excel tables. . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . import runpandas as rpd session = rpd.read_dir_nikerun(&#39;./data/nikerun_data/&#39;) . The data frame sessions holds the all the running data from the nike_run_session directory. Let’s look at some of the data. . session . calories nikefuel steps alt hr lon lat . start time . 2021-05-21 09:17:20+00:00 00:00:00 NaN | NaN | NaN | 9.371477 | NaN | -34.894570 | -8.046016 | . 00:00:07 1.719 | NaN | 19.0 | 9.369224 | NaN | -34.894669 | -8.045975 | . 00:00:13 0.688 | 3.835712 | 14.0 | 9.451016 | NaN | -34.894765 | -8.045947 | . 00:00:17 0.689 | NaN | 14.0 | 8.976615 | 134.0 | -34.894868 | -8.045923 | . 00:00:21 0.696 | 6.499274 | 14.0 | 10.422757 | NaN | -34.894963 | -8.045918 | . ... ... ... | ... | ... | ... | ... | ... | ... | . 2020-08-21 09:20:32.999000+00:00 00:50:19.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882294 | -8.093134 | . 00:50:20.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882290 | -8.093105 | . 00:50:21.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882283 | -8.093076 | . 00:50:22.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882277 | -8.093048 | . 00:50:23.001000 NaN | NaN | NaN | NaN | NaN | -34.882276 | -8.093032 | . 47711 rows × 7 columns . By calling sessions.columns, I can see this list of features included in our dataset. NikeRun provides interesting columns such as calories, steps, altitude, heart rate, latitude and longitude. We are missing some valuable data such as speed, pace and the moving time. . session.columns . Index([&#39;calories&#39;, &#39;nikefuel&#39;, &#39;steps&#39;, &#39;alt&#39;, &#39;hr&#39;, &#39;lon&#39;, &#39;lat&#39;], dtype=&#39;object&#39;) . Runpandas provides special accessors that extends the capabilities of Pandas library. For sesssions we have the runpandas.types.acessors.session._SessionAcessor with several methods that computes these running metrics for all of our activities included in the DataFrame. . #In this session we compute the distance and the distance per position across all workouts session = session.session.distance() #comput the speed for each activity session = session.session.speed(from_distances=True) #compute the pace for each activity session = session.session.pace() #compute the inactivity periods for each activity session = session.session.only_moving() . session . calories nikefuel steps alt hr lon lat distpos dist speed pace moving . start time . 2021-05-21 09:17:20+00:00 00:00:00 NaN | NaN | NaN | 9.371477 | NaN | -34.894570 | -8.046016 | NaN | NaN | NaN | NaT | False | . 00:00:07 1.719 | NaN | 19.0 | 9.369224 | NaN | -34.894669 | -8.045975 | 11.880769 | 11.880769 | 1.697253 | 00:00:00.589187 | True | . 00:00:13 0.688 | 3.835712 | 14.0 | 9.451016 | NaN | -34.894765 | -8.045947 | 10.969975 | 22.850744 | 1.828329 | 00:00:00.546947 | True | . 00:00:17 0.689 | NaN | 14.0 | 8.976615 | 134.0 | -34.894868 | -8.045923 | 11.716767 | 34.567511 | 2.929192 | 00:00:00.341391 | True | . 00:00:21 0.696 | 6.499274 | 14.0 | 10.422757 | NaN | -34.894963 | -8.045918 | 10.399457 | 44.966968 | 2.599864 | 00:00:00.384635 | True | . ... ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2020-08-21 09:20:32.999000+00:00 00:50:19.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882294 | -8.093134 | 3.292688 | 7961.077354 | 3.292688 | 00:00:00.303703 | True | . 00:50:20.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882290 | -8.093105 | 3.231813 | 7964.309167 | 3.231813 | 00:00:00.309423 | True | . 00:50:21.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882283 | -8.093076 | 3.242027 | 7967.551194 | 3.242027 | 00:00:00.308449 | True | . 00:50:22.001000 NaN | NaN | NaN | 5.323750 | NaN | -34.882277 | -8.093048 | 3.271412 | 7970.822606 | 3.271412 | 00:00:00.305678 | True | . 00:50:23.001000 NaN | NaN | NaN | NaN | NaN | -34.882276 | -8.093032 | 1.790247 | 7972.612852 | 1.790247 | 00:00:00.558582 | True | . 47711 rows × 12 columns . Now that I have the data I want I’m ready to start doing some visualization and analysis. . Answering basic questions . The first question to answer is to see how many activities that my wife ran from 2020 until now (2021). The method runpandas.types.acessors.session._SessionAcessor.count answers exactly this question. . print(&#39;There are &#39;, session.session.count(), &#39; activities available in this session.&#39;) . There are 67 activities available in this session. . But if we need to performa deeper analysis over all activities, it would be necessary a lot of conversions and aggregations to perform an overall analysis. Runpandas has a special method runpandas.types.acessors.session._SessionAcessor.summarize that summarizes all statistics for all activities, and it drastically simplifies further processing. . summary = session.session.summarize() summary . moving_time mean_speed max_speed mean_pace max_pace mean_moving_speed mean_moving_pace mean_cadence max_cadence mean_moving_cadence mean_heart_rate max_heart_rate mean_moving_heart_rate mean_temperature min_temperature max_temperature total_distance ellapsed_time . start . 2020-07-03 09:50:53.162000+00:00 00:25:29.838000 | 2.642051 | 4.879655 | 00:06:18 | 00:03:24 | 2.665008 | 00:06:15 | NaN | NaN | NaN | 178.819923 | 188.0 | 178.872587 | NaN | NaN | NaN | 4089.467333 | 00:25:47.838000 | . 2020-07-05 09:33:20.999000+00:00 00:05:04.999000 | 2.227637 | 6.998021 | 00:07:28 | 00:02:22 | 3.072098 | 00:05:25 | NaN | NaN | NaN | 168.345455 | 176.0 | 168.900000 | NaN | NaN | NaN | 980.162640 | 00:07:20.001000 | . 2020-07-05 09:41:59.999000+00:00 00:18:19 | 1.918949 | 6.563570 | 00:08:41 | 00:02:32 | 2.729788 | 00:06:06 | NaN | NaN | NaN | 173.894180 | 185.0 | 174.577143 | NaN | NaN | NaN | 3139.401118 | 00:27:16 | . 2020-07-13 09:13:58.718000+00:00 00:40:21.281000 | 2.509703 | 8.520387 | 00:06:38 | 00:01:57 | 2.573151 | 00:06:28 | NaN | NaN | NaN | 170.808176 | 185.0 | 170.795527 | NaN | NaN | NaN | 6282.491059 | 00:41:43.281000 | . 2020-07-17 09:33:02.308000+00:00 00:32:07.691000 | 2.643278 | 8.365431 | 00:06:18 | 00:01:59 | 2.643278 | 00:06:18 | NaN | NaN | NaN | 176.436242 | 186.0 | 176.436242 | NaN | NaN | NaN | 5095.423045 | 00:32:07.691000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-06-20 09:16:55.163000+00:00 00:59:44.512000 | 2.492640 | 6.065895 | 00:06:41 | 00:02:44 | 2.749453 | 00:06:03 | NaN | NaN | NaN | 170.539809 | 190.0 | 171.231392 | NaN | NaN | NaN | 9965.168311 | 01:06:37.837000 | . 2021-06-23 09:37:44+00:00 00:26:49.001000 | 2.501796 | 5.641343 | 00:06:39 | 00:02:57 | 2.568947 | 00:06:29 | NaN | NaN | NaN | 156.864865 | 171.0 | 156.957031 | NaN | NaN | NaN | 4165.492241 | 00:27:45.001000 | . 2021-06-27 09:50:08.664000+00:00 00:31:42.336000 | 2.646493 | 32.734124 | 00:06:17 | 00:00:30 | 2.661853 | 00:06:15 | NaN | NaN | NaN | 166.642857 | 176.0 | 166.721116 | NaN | NaN | NaN | 5074.217061 | 00:31:57.336000 | . 2021-07-04 11:23:19.418000+00:00 00:47:47.583000 | 2.602263 | 4.212320 | 00:06:24 | 00:03:57 | 2.856801 | 00:05:50 | NaN | NaN | NaN | 177.821862 | 192.0 | 177.956967 | NaN | NaN | NaN | 8248.084577 | 00:52:49.582000 | . 2021-07-18 09:44:55.359000+00:00 01:01:38.246000 | 2.637809 | 18.912265 | 00:06:19 | 00:00:52 | 2.796773 | 00:05:57 | NaN | NaN | NaN | 173.730159 | 193.0 | 173.843694 | NaN | NaN | NaN | 10397.297738 | 01:05:41.641000 | . 67 rows × 18 columns . We have all the main statistics required our downstream analysis. Each row includes the the running summary . Let’s look at some of the data: . print( summary[[&#39;total_distance&#39;, &#39;ellapsed_time&#39;]] .sample(5) .sort_index() .to_string(formatters={ &#39;total_distance&#39;: &#39;{:.0f}m&#39;.format, })) . total_distance ellapsed_time start 2020-08-09 09:47:14.372000+00:00 6274m 00:31:38.627000 2020-10-18 20:29:56+00:00 6151m 00:42:22 2021-03-20 09:28:54.161000+00:00 5215m 00:38:54.840000 2021-03-28 09:31:37+00:00 8863m 01:03:34 2021-06-11 09:30:44+00:00 4206m 00:26:39.001000 . This shows five randomly selected rows from the data frame. Let us find out over which time period these activities were recorded: . first_date = summary.index.min() last_date = summary.index.max() print(&#39;Activities recorded from %s to %s, total of %d days.&#39; % ( first_date.strftime(&#39;%Y-%m-%d&#39;), last_date.strftime(&#39;%Y-%m-%d&#39;), (last_date - first_date).days)) . Activities recorded from 2020-07-03 to 2021-07-18, total of 379 days. . One year of training! We must remember that the data shows only the activities that were recorded on Nike Run. . summary[&#39;days_diff&#39;] = summary.index.to_series().diff().dt.days summary[&#39;total_distance&#39;] = summary[&#39;total_distance&#39;] / 1000 #conver meters to kms summary[&#39;mean_speed&#39;] = summary[&#39;mean_speed&#39;] * 3.6 #convert to km/h print(&#39;Period:&#39;, (summary.index.max() - summary.index.min()).days, &#39;days&#39;) print(&#39;Total activities:&#39;, len(summary), &#39;activities&#39;) print(&#39;Kms total:&#39;, summary.total_distance.sum()) print(&#39;Interval between two runs (average)):&#39;, round(summary.days_diff.mean(),2), &#39;days&#39;) print(&#39;Average Pace (min/km):&#39;, summary.mean_pace.mean()) print(&#39;Average Distance (km):&#39;, round(summary.total_distance.mean(),2)) . Period: 379 days Total activities: 67 activities Kms total: 458.36890461102126 Interval between two runs (average)): 5.27 days Average Pace (min/km): 0 days 00:06:29.477611 Average Distance (km): 6.84 . We also got some basic statistics using the pandas aggregation methods such as mean, sum, max and min. As you can see above, my wife ran 67 times with a total distance of 458kms in an interval range of 5 days between runs and a average pace of 06:29&#39; min/km and an average distance of 6.84kms. . Looking more at individual activities . what were the top three activities in which she covered the longest distance? . print( (summary[&#39;total_distance&#39;] /1000).nlargest(3) .to_string(float_format=&#39;%.1fkm&#39;)) . start 2021-06-13 09:22:30.985000+00:00 0.0km 2021-04-25 09:38:37.511000+00:00 0.0km 2021-02-07 09:15:40.107000+00:00 0.0km . And what were the top three activities on which she spent the most time? . print( (summary[&#39;ellapsed_time&#39;] .nlargest(4)) .to_string(float_format=&#39;%.1fh&#39;)) . start 2021-06-13 09:22:30.985000+00:00 01:40:11.016000 2020-12-06 09:36:28.872000+00:00 01:26:28.128000 2021-02-07 09:15:40.107000+00:00 01:23:01.894000 2021-04-25 09:38:37.511000+00:00 01:19:04.490000 . Answering some research questions . What is her average time and distance per day on trainnings ? . print( summary[[&#39;total_distance&#39;, &#39;ellapsed_time&#39;]] .mean() .to_frame(&#39;mean&#39;) .T) . total_distance ellapsed_time mean 6.84133 00:44:25.656985 . Apparently she covers about 6.8km and 44min per day on average—during activities she recorded. . Asking questions about months, quarters, and years . With Pandas, we can also group and aggregate data to other periods of time. For example, let’s find the day/month/quarter/year for each activity in which she covered, and see the total distance, average speed and number of trainings. We will decompose the timestamp in Month, Week, Weekday, Year and YearMonth. . import pandas as pd summary = summary.assign(Year=summary.index.year, Month=summary.index.month, Week=summary.index.week, Weekday=summary.index.weekday) summary[&#39;Year-month&#39;] = pd.to_datetime(summary[[&#39;Year&#39;,&#39;Month&#39;]].assign(day=1)).dt.to_period(&#39;M&#39;) summary[&#39;Year-week&#39;] = summary.index.strftime(&#39;%Y-w%U&#39;) summary . moving_time mean_speed max_speed mean_pace max_pace mean_moving_speed mean_moving_pace mean_cadence max_cadence mean_moving_cadence ... max_temperature total_distance ellapsed_time days_diff Year Month Week Weekday Year-month Year-week . start . 2020-07-03 09:50:53.162000+00:00 00:25:29.838000 | 9.511385 | 4.879655 | 00:06:18 | 00:03:24 | 2.665008 | 00:06:15 | NaN | NaN | NaN | ... | NaN | 4.089467 | 00:25:47.838000 | NaN | 2020 | 7 | 27 | 4 | 2020-07 | 2020-w26 | . 2020-07-05 09:33:20.999000+00:00 00:05:04.999000 | 8.019494 | 6.998021 | 00:07:28 | 00:02:22 | 3.072098 | 00:05:25 | NaN | NaN | NaN | ... | NaN | 0.980163 | 00:07:20.001000 | 1.0 | 2020 | 7 | 27 | 6 | 2020-07 | 2020-w27 | . 2020-07-05 09:41:59.999000+00:00 00:18:19 | 6.908218 | 6.563570 | 00:08:41 | 00:02:32 | 2.729788 | 00:06:06 | NaN | NaN | NaN | ... | NaN | 3.139401 | 00:27:16 | 0.0 | 2020 | 7 | 27 | 6 | 2020-07 | 2020-w27 | . 2020-07-13 09:13:58.718000+00:00 00:40:21.281000 | 9.034930 | 8.520387 | 00:06:38 | 00:01:57 | 2.573151 | 00:06:28 | NaN | NaN | NaN | ... | NaN | 6.282491 | 00:41:43.281000 | 7.0 | 2020 | 7 | 29 | 0 | 2020-07 | 2020-w28 | . 2020-07-17 09:33:02.308000+00:00 00:32:07.691000 | 9.515800 | 8.365431 | 00:06:18 | 00:01:59 | 2.643278 | 00:06:18 | NaN | NaN | NaN | ... | NaN | 5.095423 | 00:32:07.691000 | 4.0 | 2020 | 7 | 29 | 4 | 2020-07 | 2020-w28 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-06-20 09:16:55.163000+00:00 00:59:44.512000 | 8.973504 | 6.065895 | 00:06:41 | 00:02:44 | 2.749453 | 00:06:03 | NaN | NaN | NaN | ... | NaN | 9.965168 | 01:06:37.837000 | 6.0 | 2021 | 6 | 24 | 6 | 2021-06 | 2021-w25 | . 2021-06-23 09:37:44+00:00 00:26:49.001000 | 9.006464 | 5.641343 | 00:06:39 | 00:02:57 | 2.568947 | 00:06:29 | NaN | NaN | NaN | ... | NaN | 4.165492 | 00:27:45.001000 | 3.0 | 2021 | 6 | 25 | 2 | 2021-06 | 2021-w25 | . 2021-06-27 09:50:08.664000+00:00 00:31:42.336000 | 9.527376 | 32.734124 | 00:06:17 | 00:00:30 | 2.661853 | 00:06:15 | NaN | NaN | NaN | ... | NaN | 5.074217 | 00:31:57.336000 | 4.0 | 2021 | 6 | 25 | 6 | 2021-06 | 2021-w26 | . 2021-07-04 11:23:19.418000+00:00 00:47:47.583000 | 9.368145 | 4.212320 | 00:06:24 | 00:03:57 | 2.856801 | 00:05:50 | NaN | NaN | NaN | ... | NaN | 8.248085 | 00:52:49.582000 | 7.0 | 2021 | 7 | 26 | 6 | 2021-07 | 2021-w27 | . 2021-07-18 09:44:55.359000+00:00 01:01:38.246000 | 9.496114 | 18.912265 | 00:06:19 | 00:00:52 | 2.796773 | 00:05:57 | NaN | NaN | NaN | ... | NaN | 10.397298 | 01:05:41.641000 | 13.0 | 2021 | 7 | 28 | 6 | 2021-07 | 2021-w29 | . 67 rows × 25 columns . Now we can aggregate and plot some charts using matplotlib package to see her training over the computed periods. . import matplotlib.pyplot as plt fig, axr = plt.subplots(3,1, figsize=(14,14 )) ticks = summary.groupby(summary[&#39;Year-month&#39;]).agg({&#39;total_distance&#39;: &#39;sum&#39;}).index.astype(&#39;str&#39;).to_list() axr[0].bar(summary.groupby(summary[&#39;Year-month&#39;]).agg({&#39;total_distance&#39;: &#39;sum&#39;}).index.astype(&#39;str&#39;), summary.groupby(summary[&#39;Year-month&#39;]).agg({&#39;total_distance&#39;: &#39;sum&#39;}).values.flatten(), yerr=summary.groupby(summary[&#39;Year-month&#39;]).agg({&#39;total_distance&#39;: &#39;std&#39;}).values.flatten(), tick_label=ticks, label=&#39;Number of kilometers&#39;) axr[0].set_title(&#39;Total number of kilometers&#39;) axr[0].set_ylabel(&#39;Km&#39;) summary.boxplot([&#39;mean_speed&#39;], by=&#39;Year-month&#39;, ax=axr[1]) axr[1].set_xticklabels(ticks) axr[1].set_ylabel(&#39;Km/h&#39;) summary.groupby(&#39;Year-month&#39;)[&#39;mean_speed&#39;].count().plot.bar(ax=axr[2], color=&#39;C1&#39;) axr[2].set_xticklabels(ticks) axr[2].set_title(&#39;Number of trainings&#39;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:24.856791 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ fig, axr = plt.subplots(3, figsize=(14,14), sharex=True) summary.boxplot([&#39;mean_speed&#39;], by=&#39;Year-week&#39;, ax=axr[0]) axr[0].set_ylabel(&#39;Km/h&#39;) summary.groupby(&#39;Year-week&#39;)[&#39;total_distance&#39;].sum().plot.bar(ax=axr[1]) axr[1].set_title(&#39;Total number of kilometers&#39;) axr[1].set_ylabel(&#39;Km&#39;) summary.groupby(&#39;Year-week&#39;)[&#39;mean_speed&#39;].count().plot.bar(ax=axr[2], color=&#39;C1&#39;) axr[2].set_title(&#39;Number of trainings&#39;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:27.156462 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ weekdays = [&#39;Monday&#39;, &#39;Tuesday&#39;, &#39;Wednesday&#39;, &#39;Thursday&#39;, &#39;Friday&#39;, &#39;Saturday&#39;, &#39;Sunday&#39;] fig, axr = plt.subplots(3, figsize=(14,14)) summary.groupby(&#39;Weekday&#39;)[&#39;total_distance&#39;].sum().plot.area(ax=axr[0]) axr[0].set_title(&#39;Total number of kilometers&#39;) axr[0].set_ylabel(&#39;Km&#39;) axr[0].set_xticks([0,1,2,3,4,5,6]) axr[0].set_xticklabels(weekdays) summary.boxplot([&#39;mean_speed&#39;], by=&#39;Weekday&#39;, ax=axr[1]) axr[1].set_ylabel(&#39;Km/h&#39;) axr[1].set_xticks([0,1,2,3,4,5,6]) axr[1].set_xticklabels(weekdays) summary.groupby(&#39;Weekday&#39;)[&#39;mean_speed&#39;].count().plot.area(ax=axr[2], color=&#39;C1&#39;) axr[2].set_title(&#39;Number of trainings&#39;) axr[2].set_xticklabels(weekdays) axr[2].set_xticks([0,1,2,3,4,5,6]) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:29.272343 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ Conclusions until now from the plots above: . The month that she ran more kms was December 2020. It corresponds to the number of the trainings also in the same month: 8 activities. | Her Average speed didn&#39;t improve over the years, but the boxplots present from February 2021 until now a smaller variation over the mean. | She trains one or twice a week. For a beginner the volume is ok, but not for someone training for a marathon. | The day of the week that she runs a lot is on Sundays and then Fridays. Sunday is a rest day for her from her job, so it makes sense, more time for training! | . Does she run longer distances on the weekend than during the week? Let&#39;s evaluate it by applying some pandas grouping functions. The idea is to aggregate over the weekday column. . import numpy as np summary[&#39;ellapsed_time_minutes&#39;] = summary[&#39;ellapsed_time&#39;] / np.timedelta64(1, &#39;m&#39;) summary[&#39;count&#39;] = 1 summary_by_day = summary.groupby([pd.Grouper(freq=&#39;D&#39;, level=0)]).sum() . weekdays = [&#39;Monday&#39;, &#39;Tuesday&#39;, &#39;Wednesday&#39;, &#39;Thursday&#39;, &#39;Friday&#39;, &#39;Saturday&#39;, &#39;Sunday&#39;] summary_by_day[[&#39;total_distance&#39;, &#39;ellapsed_time_minutes&#39;, &#39;count&#39;]].groupby(lambda d: weekdays[d.weekday()]).mean().agg([&#39;idxmax&#39;, &#39;max&#39;]).T.unstack(level=0).swaplevel(1) . idxmax total_distance Sunday ellapsed_time_minutes Sunday count Sunday max total_distance 4.13675 ellapsed_time_minutes 27.2632 count 0.545455 dtype: object . The answer above corresponds to what we interpreted from the plots, she runs most of time and distance on Sundays! . We can do the same for the months of the year: . months = &#39;Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec&#39;.split() summary_by_month = summary.groupby([pd.Grouper(freq=&#39;M&#39;, level=0)]).sum() summary_by_month[[&#39;total_distance&#39;, &#39;ellapsed_time_minutes&#39;, &#39;count&#39;]].groupby(lambda m: months[m.month-1]).mean().agg([&#39;idxmax&#39;, &#39;max&#39;]).T.unstack(level=0).swaplevel(1) . idxmax total_distance Dec ellapsed_time_minutes Dec count Dec max total_distance 58.5305 ellapsed_time_minutes 393.46 count 8 dtype: object . December was the month of the year in which she does most of her running on average . Correlations . Another question she asked was if she started running faster, on average, over the past few months? To answer this question, I will plot the relationship between date and average pace, to see any trend. . #let&#39;s convert the pace to float number in minutes import datetime summary[&#39;mean_moving_pace_float&#39;] = summary[&#39;mean_moving_pace&#39;] / datetime.timedelta(minutes=1) import matplotlib.pyplot as plt import matplotlib.dates as mdates plt.subplots(figsize=(8, 5)) plt.plot(summary.index, summary.mean_moving_pace_float, color=&#39;silver&#39;, label = &#39;average pace&#39;) #add trend line x = np.asarray(summary.index) #convert data to numpy array x2 = mdates.date2num(x) y = np.asarray(summary.mean_moving_pace_float) z=np.polyfit(x2,y,1) p=np.poly1d(z) plt.plot(x,p(x2),&#39;r--&#39;) #format the figure and display fig.autofmt_xdate(rotation=45) fig.tight_layout() fig.show() plt.title(&quot;Pace Evolution&quot;) plt.xlabel(&quot;Runnings&quot;) plt.ylabel(&quot;Pace&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7fe0e3e92fd0&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:30.372341 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ There isn&#39;t a indication of improvement over time, The change is a little , with a little increase over the time (trend line). But could it be the distance ,how far she runs , she slows down ? Let&#39;s see the correlation. The following code will create a regression plot of her average speed vs distance. . #Seaborn is a data visualization library. import seaborn as sns sns.set(style=&quot;ticks&quot;, context=&quot;talk&quot;) sns.regplot(x=&#39;total_distance&#39;, y = summary.mean_moving_speed * 3.6, data = summary).set_title(&quot;Average Speed vs Distance&quot;) . Text(0.5, 1.0, &#39;Average Speed vs Distance&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:31.690242 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ There is not relationship as we can see from the data above, from the total distance vs moving speed, by the way, even in far distances she maintains the velocity. How about her my max speed higher on shorter runs? Is it true ? She performs on friday several shorter runs. Let&#39;s see through data: . sns.scatterplot(x=&#39;total_distance&#39;, y = summary.max_speed, data = summary).set_title(&quot;Max Speed vs Distance&quot;) . Text(0.5, 1.0, &#39;Max Speed vs Distance&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:32.102856 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ There are some outliers,let&#39;s remove them. Maybe due to some incorrect calculation or record registering. . summary_without_outliers = summary[summary[&#39;max_speed&#39;].between(1,15)] sns.regplot(x=&#39;total_distance&#39;, y = summary_without_outliers.max_speed, data = summary_without_outliers).set_title(&quot;Max Speed vs Distance&quot;) . Text(0.5, 1.0, &#39;Max Speed vs Distance&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:32.551067 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ Interesting that her speed improved as the total distance grew, which shows that long distances don&#39;t affect her performance. She is probably a long runner! . How has the average distance, time and speed per run changed over the years? Let&#39;s see the plots over the year axis. . import matplotlib.pyplot as plt fig, axr = plt.subplots(3,1, figsize=(14,14 )) ticks = summary.groupby(summary[&#39;Year&#39;]).agg({&#39;total_distance&#39;: &#39;sum&#39;}).index.astype(&#39;str&#39;).to_list() axr[0].bar(summary.groupby(summary[&#39;Year&#39;]).agg({&#39;total_distance&#39;: &#39;sum&#39;}).index.astype(&#39;str&#39;), summary.groupby(summary[&#39;Year&#39;]).agg({&#39;total_distance&#39;: &#39;sum&#39;}).values.flatten(), yerr=summary.groupby(summary[&#39;Year&#39;]).agg({&#39;total_distance&#39;: &#39;std&#39;}).values.flatten(), tick_label=ticks, label=&#39;Number of kilometers&#39;) axr[0].set_title(&#39;Total number of kilometers&#39;) axr[0].set_ylabel(&#39;Km&#39;) summary.boxplot([&#39;mean_speed&#39;], by=&#39;Year&#39;, ax=axr[1]) axr[1].set_xticklabels(ticks) axr[1].set_ylabel(&#39;Km/h&#39;) summary.groupby(&#39;Year&#39;)[&#39;mean_speed&#39;].count().plot.bar(ax=axr[2], color=&#39;C1&#39;) axr[2].set_xticklabels(ticks) axr[2].set_title(&#39;Number of trainings&#39;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:33.075601 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ It shows that in 2021 she is running more than 2020 at almost the same period, and that her speed improved from 2020 to 2021 (the box plot show the average is greater in 2021 and less variation). She told me that she reforced the number of trainings and the exercises she has been doing to strengthen her legs. . Which month of the year do she run the fastest? . summary[[&#39;mean_speed&#39;, &#39;Year-month&#39;]].groupby(&#39;Year-month&#39;).mean().agg([&#39;idxmax&#39;, &#39;max&#39;]).unstack(level=0) . mean_speed idxmax 2020-09 max 10.1761 dtype: object . It was on september 2020. With the average speed of 10.1761. It was one her first best 5km, we will check this later on this post. . Finally, how much time she rest vs the time she run. We can see below that there is a 5 days interval on average between the runs, which means 1 run per week. Does it affect her performance ? . summary[&#39;days_diff&#39;].mean() . 5.2727272727272725 . fig,ax = plt.subplots(figsize=(8, 5)) ax.plot(summary.index, summary.mean_moving_pace_float, color=&#39;silver&#39;) ax.set_xlabel(&#39;race&#39;) ax.set_ylabel(&#39;pace&#39;,color=&#39;silver&#39;) ax2=ax.twinx() ax2.plot(summary.index, summary.days_diff,color=&#39;purple&#39;) ax2.set_ylabel(&#39;Day without running&#39;,color=&#39;indigo&#39;, rotation=270) plt.title(&#39;Pace vs Days without running&#39;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:33.768130 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ sns.regplot(x=&#39;days_diff&#39;, y = summary.mean_moving_pace_float, data = summary).set_title(&quot;Days Diff vs Mean Pace&quot;) . Text(0.5, 1.0, &#39;Days Diff vs Mean Pace&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:34.392857 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ No relationship between the rest days vs her pace , which means the rest day doesn&#39;t affect her pace. . Performance over 5, 10 and 15km . Finally, I was interested in seeing her performance evolution in pace over time in 5km, 10km and 15kms. For this analysis, I had to filter the session dataframe based on distances. In this tutorial, I will assume that the distances between 5km - 5.9km , 10km - 10.9km, 15km - 15.9km will be normalized as 5, 10 , 15km. . summary_5km = summary[summary[&#39;total_distance&#39;].between(5,5.9)] summary_5km = summary_5km[summary_5km[&#39;mean_moving_pace_float&#39;].between(5,8)] summary_10km = summary[summary[&#39;total_distance&#39;].between(10,10.9)] summary_15km = summary[summary[&#39;total_distance&#39;].between(15,15.9)] . fig, axs = plt.subplots(3, figsize=(18, 16)) fig.suptitle(&#39;Average Moving Pace over time (5km, 10km, 15km)&#39;) axs[0].plot(summary_5km.index, summary_5km.mean_moving_pace_float, marker=&#39;*&#39;) axs[0].set_title(&#39;5km&#39;) axs[1].plot(summary_10km.index, summary_10km.mean_moving_pace_float, marker=&#39;*&#39;) axs[1].set_title(&#39;10km&#39;) axs[2].plot(summary_15km.index, summary_15km.mean_moving_pace_float, marker=&#39;*&#39;) axs[2].set_title(&#39;15km&#39;) plt.xlabel(&#39;Date&#39;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:34.963478 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ Her best performance on 5km was between october 2020, but her pace kept steadily along the months. In 10kms she had an amazing improvement, with the pace reducing about 40 seconds/km. The 15km she ran only one, so we don&#39;t have further information to discuss it. . Is she ready for a half-marathon ? . Half-Marathon is the one of the most popular races for anyone thats don&#39;t want to run the 42.195km of a full marathon and want to feel a little the taste of running half the way. Half-Marathons are quite popular and many runners even practicing for the marathon or deciding to run longer distances after the 10kms. My wife is preparing herself at the end of the year for a Half-marathon (21km) and asked me what was her predicted finishing time . . It comes to rescue machine learning techniques that can help using our historical data to predict or classify the finish time based on the distance or some variables available. There are several models to choose in order to solve this task. I will choose one of the most classical statistics models : The linear regression. Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. In our case here, we will relate the distance, the altitude to the estimated finishing time using a linear regression model. . . Illustration of a linear regression model sample. . We will use the open-source library scikit-learn, it is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python. This library, which is largely written in Python, is built upon NumPy, SciPy and Matplotlib. . from sklearn import datasets, linear_model from sklearn.metrics import mean_squared_error, r2_score . X_train = summary[[&#39;total_distance&#39;]].values Y_train = summary[&#39;ellapsed_time_minutes&#39;] X_test = np.array([21.0975]).reshape(1,-1) . regr = linear_model.LinearRegression() regr.fit(X_train, Y_train) Y_pred = regr.predict(X_test) print(&#39;Distance: {} Km, Speed: {} Km/h, Time: {} hours n&#39;.format(X_test[0][0], X_test[0][0]/float(Y_pred[0]/60), Y_pred[0]/60)) . Distance: 21.0975 Km, Speed: 9.019953470620834 Km/h, Time: 2.33898102342959 hours . We arranged all the distances as inputs and all ellapsed time in minutes as outputs and used them as training set. For testing, we want the expected finish time for the distance of 21.0975km (the half marathon official distance). We used the method regr.fit to train the model with the historical data and we asked to predict (regr.predict) the finishing time. Based on this simple model, it tell us that she will finish it in 2hrs33minutes. For a beginner it is an average finishing time, not so good, but it can get better with hard training! . plt.figure(figsize=(15,4)) plt.scatter(X_train, regr.predict(X_train)/60, label=&#39;predicted&#39;) plt.scatter(X_test, Y_pred/60, label=&#39;predicted 21km&#39;) plt.scatter(X_train, Y_train/60, label=&#39;historical&#39;) plt.plot([0, X_test], [0, Y_pred/60], &#39;--&#39;, color=&#39;C2&#39;) plt.ylabel(&#39;Hours&#39;) plt.xlabel(&#39;Kilometers&#39;) plt.legend(loc=&#39;upper left&#39;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-23T15:38:48.457628 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ Conclusions . She is a weekeend long runner, and it still in preparation for running her half-marathon. More volume and training will help her to achieve her goals! For long distances there some clues that she will perform with excellent times. | . There are so many ways you might explore this data. What I did above is just one example. Runpandas with other tools such as pandas, matplotlib and scikit-learn can really help you explore your running data and answer the questions that are interesting to you. Being able to captur and analyze this data open doors for any data runners that are seeking to explore their historical running activities. I hope you found this helpful and if there is anything I missed, you would like to see, or you think is incorrect, please comment below. Additionally, here are some resources you might find helpful. . matplotlib | seaborn | scikit-learn | nrc-exporter | linear regression | .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/07/23/session-metrics.html",
            "relUrl": "/general/jupyter/releases/2021/07/23/session-metrics.html",
            "date": " • Jul 23, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Release 0.5.1 support to Nike Run Club app tracking files",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We published this minor release with one more social tracking app reading data support: Nike Run Club. In this release of RunPandas 0.5.1, we include: . Reader module support to Nike Run Club app runpandas.read_nikerun. Reading and handling the JSON tracking file from the Nike Run API into a runpandas.Activity` Reader module support to Nike Run Club app. Reading and handling the JSON tracking file from the Nike Run API into arunpandas.Activity` | Read and traverse a directory of Nike Run JSON activities by combining them into a single Activity by the function runpandas.read_dir_nikerun. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . What is Nike Run App? . Nike Run Club is one of the most popular free fitness apps that tracks users&#39; runs, capturing time, distance, pace, heart rate (with a fitness tracker), and route with an impressively precise GPS. It is available on Android and IOS platforms. . . Main Features . Nike Run Club doesn&#39;t offer a official method to export your historical fitness data, unfortunately. However there are several third-party tools available to overcome this issue. One of them is use the open-source tool NRC-Exporter, written in Python, that makes possible by commandline to export all your runs which have associated GPS data and converts them into the GPX format. . . Screenshot from the NRC-Exporter Official Repository Website . The NRC exporter makes available the activity JSON files, which after are converted to GPX format. You can work with both of these formats: GPX or JSON. In this post we will show how to load the JSON files. After running the extractor you will have a directory of all JSON files. It should look something like this: . $ tree activities activities ├── 0019f189-d32f-437f-a4d4-ef4f15304324.json ├── 0069911c-2cc8-489b-8335-8e613a81124s.json ├── 01a09869-0a95-49f2-bd84-75065b701c33.json └── 07e1fa42-a9a9-4626-bbef-60269dc4a111.json . Now you can load these JSON files into our runpandas reading package. . Reading a single workout . Let&#39;s load an exported run from Nike Run using the method runpandas.read_nikerun. This method was specially built for loading the exported JSON Nike Run activities, with all the handling data included. . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . #!pip install runpandas import runpandas as rpd activity = rpd.read_nikerun(&#39;./data/nikerun-sample.json&#39;) . activity . calories nikefuel steps alt hr lon lat . time . 00:00:00 NaN | NaN | NaN | 9.340020 | NaN | -34.894413 | -8.046077 | . 00:00:02.900000 NaN | NaN | NaN | 9.315611 | NaN | -34.894470 | -8.046149 | . 00:00:05.748000 0.447 | NaN | 7.0 | 9.323614 | NaN | -34.894564 | -8.046194 | . 00:00:10.586000 0.729 | 4.327005 | 14.0 | 9.260836 | 138.0 | -34.894624 | -8.046292 | . 00:00:15.585000 0.728 | NaN | 14.0 | 9.334247 | 139.0 | -34.894678 | -8.046401 | . ... ... | ... | ... | ... | ... | ... | ... | . 00:52:39.582000 0.826 | 7.061214 | 13.0 | 9.331132 | 189.0 | -34.894534 | -8.046602 | . 00:52:43.582000 0.411 | NaN | 8.0 | 9.316407 | NaN | -34.894465 | -8.046533 | . 00:52:44.582000 NaN | NaN | 7.0 | 9.512563 | NaN | -34.894443 | -8.046515 | . 00:52:45.582000 NaN | NaN | NaN | 9.324933 | NaN | -34.894429 | -8.046494 | . 00:52:49.582000 NaN | 7.064754 | 7.0 | NaN | 190.0 | -34.894395 | -8.046398 | . 727 rows × 7 columns . As shown above, the activity now after loaded can be analysed as any other activity in runpandas! . #compute the common metrics for the running activity such as distance per position, speed, pace, etc. activity[&#39;distpos&#39;] = activity.compute.distance() activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity_only_moving = activity.only_moving() . activity_only_moving.summary() . Session Running: 04-07-2021 11:23:19 Total distance (meters) 8248.08 Total ellapsed time 0 days 00:52:49.582000 Total moving time 0 days 00:47:47.583000 Average speed (km/h) 9.36815 Average moving speed (km/h) 10.2845 Average pace (per 1 km) 0 days 00:06:24 Average pace moving (per 1 km) 0 days 00:05:50 Average cadence NaN Average moving cadence NaN Average heart rate 177.822 Average moving heart rate 177.957 Average temperature NaN dtype: object . Reading multiple workouts . We also provides the method runpandas.read_dir_nikerun, which allows the user to read all the tracking files in JSON format in a directory and combined them into a runpandas.Actvity split by sessions based on the timestamp of each activity. Does it sound familiar to you? Exactly, it works as same as the runpandas.read_directory_aggregate, but it is specific for the Nike Run JSON output files. . To illustrate this in action, let&#39;s load a session of 6 activities of a single runner exported from he Nike Run account: . #!pip install runpandas import runpandas as rpd session = rpd.read_dir_nikerun(&#39;./data/nikerun_session&#39;) . session . calories nikefuel steps alt hr lon lat . start time . 2021-01-31 09:18:46.676000+00:00 00:00:00 NaN | NaN | NaN | 7.308532 | NaN | -34.891723 | -8.046471 | . 00:00:03 0.873 | NaN | 7.0 | 7.328482 | NaN | -34.891698 | -8.046576 | . 00:00:06 0.862 | NaN | 8.0 | 7.314730 | NaN | -34.891674 | -8.046687 | . 00:00:08.999000 0.150 | 2.056452 | 7.0 | 7.311658 | NaN | -34.891632 | -8.046807 | . 00:00:12.999000 0.509 | NaN | 14.0 | 7.334774 | NaN | -34.891624 | -8.046902 | . ... ... ... | ... | ... | ... | ... | ... | ... | . 2020-09-18 09:23:20.620000+00:00 00:25:38.379000 0.737 | NaN | 12.0 | 1.117384 | 176.0 | -34.897463 | -8.126419 | . 00:25:42.379000 0.362 | 5.205709 | 7.0 | 0.950017 | 176.0 | -34.897494 | -8.126517 | . 00:25:46.378000 0.725 | NaN | 14.0 | 0.950000 | NaN | -34.897489 | -8.126607 | . 00:25:52.378000 NaN | 5.242402 | 11.0 | 0.950000 | 175.0 | -34.897485 | -8.126700 | . 00:25:56.378000 NaN | NaN | NaN | NaN | NaN | -34.897540 | -8.126788 | . 3742 rows × 7 columns . print(&#39;There are &#39;, session.session.count(), &#39;activities&#39;) . There are 6 activities . #In this example we compute the distance and the distance per position across all workouts session = session.session.distance() #comput the speed for each activity session = session.session.speed(from_distances=True) #compute the pace for each activity session = session.session.pace() #compute the inactivity periods for each activity session = session.session.only_moving() . summary = session.session.summarize() summary . moving_time mean_speed max_speed mean_pace max_pace mean_moving_speed mean_moving_pace mean_cadence max_cadence mean_moving_cadence mean_heart_rate max_heart_rate mean_moving_heart_rate mean_temperature min_temperature max_temperature total_distance ellapsed_time . start . 2020-08-16 10:06:00.150000+00:00 00:17:51.850000 | 2.190390 | 15.123177 | 00:07:36 | 00:01:06 | 2.237329 | 00:07:26 | NaN | NaN | NaN | 160.772152 | 179.0 | 160.788462 | NaN | NaN | NaN | 2420.052106 | 00:18:24.850000 | . 2020-09-18 09:23:20.620000+00:00 00:25:49.378000 | 2.697902 | 13.684714 | 00:06:10 | 00:01:13 | 2.707618 | 00:06:09 | NaN | NaN | NaN | 171.626415 | 183.0 | 171.623574 | NaN | NaN | NaN | 4198.955573 | 00:25:56.378000 | . 2021-01-31 09:18:46.676000+00:00 00:53:54.324000 | 2.452860 | 13.833715 | 00:06:47 | 00:01:12 | 2.615802 | 00:06:22 | NaN | NaN | NaN | 168.152542 | 186.0 | 168.320683 | NaN | NaN | NaN | 8502.408803 | 00:57:46.325000 | . 2021-04-02 09:39:34+00:00 00:30:31 | 2.779288 | 10.529306 | 00:05:59 | 00:01:34 | 2.800375 | 00:05:57 | NaN | NaN | NaN | 178.212625 | 189.0 | 178.203333 | NaN | NaN | NaN | 5138.905933 | 00:30:49.001000 | . 2021-06-11 09:30:44+00:00 00:25:50 | 2.630604 | 6.038798 | 00:06:20 | 00:02:45 | 2.693010 | 00:06:11 | NaN | NaN | NaN | 167.064516 | 180.0 | 167.285714 | NaN | NaN | NaN | 4206.337676 | 00:26:39.001000 | . 2021-07-04 11:23:19.418000+00:00 00:47:47.583000 | 2.602263 | 4.212320 | 00:06:24 | 00:03:57 | 2.856801 | 00:05:50 | NaN | NaN | NaN | 177.821862 | 192.0 | 177.956967 | NaN | NaN | NaN | 8248.084577 | 00:52:49.582000 | . print(&#39;Session Interval:&#39;, (summary.index.to_series().max() - summary.index.to_series().min()).days, &#39;days&#39;) print(&#39;Total Workouts:&#39;, len(summary), &#39;runnings&#39;) print(&#39;Tota KM Distance:&#39;, summary[&#39;total_distance&#39;].sum() / 1000) print(&#39;Average Pace (all runs):&#39;, summary.mean_pace.mean()) print(&#39;Average Moving Pace (all runs):&#39;, summary.mean_moving_pace.mean()) print(&#39;Average KM Distance (all runs):&#39;, round(summary.total_distance.mean()/ 1000,2)) . Session Interval: 322 days Total Workouts: 6 runnings Tota KM Distance: 32.714744667475955 Average Pace (all runs): 0 days 00:06:32.666666 Average Moving Pace (all runs): 0 days 00:06:19.166666 Average KM Distance (all runs): 5.45 . As we illustrated above, we can extract several statistics from the session workouts using the same methods and acessors available from runpandas. . What is coming next ? . The next releases will focus on supporting marathon results. It will be awesome, keep tunned! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/07/21/release-051.html",
            "relUrl": "/general/jupyter/releases/2021/07/21/release-051.html",
            "date": " • Jul 21, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Release 0.5.0 with summary statistics and aggregation of multiple activities!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We published this major release with summary statistics for a single activity and the possibility of combining multiple workouts into a one multi-dimensional dataframe (season) , enabling other types of analysis, including historical performance over a period of time. In this release of RunPandas 0.5.0, we include: . Now the Activity can be summarised through common summary statistics using the runpandas.types.summary method. | We enable now the analysis over multiple activities by combining them into a single Activity. This results into new possibilities of aggregated analysis over a group of workouts. | There is a new acessor runpandas.acessors.season , that computes the running metrics through the combined activities. | Finally, there is a runpandas.types.session_summary method that includes summary statistics over the season (group) of activities. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Summary statistics for a single workout . The runpandas provides for the data runners the runpandas.types.summary method for the Activity dataframe. This methods computes the estimates of the total distance covered, the total duration, the time spent moving, and several averages metrics such as speed, pace, cadence, and heart rate, calculated based on total duration ot the time spent moving. . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . #!pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . activity . alt dist hr lon lat . time . 00:00:00 178.942627 | 0.000000 | 62 | -79.093187 | 35.951880 | . 00:00:01 178.942627 | 0.000000 | 62 | -79.093184 | 35.951880 | . 00:00:06 178.942627 | 1.106947 | 62 | -79.093172 | 35.951868 | . 00:00:12 177.500610 | 13.003035 | 62 | -79.093228 | 35.951774 | . 00:00:16 177.500610 | 22.405027 | 60 | -79.093141 | 35.951732 | . ... ... | ... | ... | ... | ... | . 00:32:51 170.290649 | 4613.641602 | 178 | -79.093241 | 35.951341 | . 00:32:56 169.810059 | 4630.377930 | 178 | -79.093192 | 35.951486 | . 00:33:02 168.848755 | 4652.966309 | 179 | -79.093086 | 35.951671 | . 00:33:07 167.887329 | 4671.572754 | 179 | -79.093000 | 35.951824 | . 00:33:11 166.445312 | 4686.311035 | 180 | -79.093014 | 35.951954 | . 383 rows × 5 columns . #compute the common metrics for the running activity such as distance per position, speed, pace, etc. activity[&#39;distpos&#39;] = activity.compute.distance() activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;vam&#39;] = activity.compute.vertical_speed() activity_only_moving = activity.only_moving() . activity_only_moving.summary() . Session Running: 26-12-2012 21:29:53 Total distance (meters) 4686.31 Total ellapsed time 0 days 00:33:11 Total moving time 0 days 00:33:05 Average speed (km/h) 8.47656 Average moving speed (km/h) 8.49853 Average pace (per 1 km) 0 days 00:07:04 Average pace moving (per 1 km) 0 days 00:07:03 Average cadence NaN Average moving cadence NaN Average heart rate 156.653 Average moving heart rate 157.4 Average temperature NaN dtype: object . The result above is an object of pandas.Series including the main running statistics from the workout. . Combining multiple activities into a Grouped Activity Dataframe . Runpandas powered by pandas libraries comes with the pandas.MultiIndex, which allows the dataframe have multiple columns as a row identifier, while having each index column related to another through a parent/child relationship. In our scenario we have the start time from each activity as the first index level and the timestamps from the activity as the second index level. This enables advanced statistical analysis acrosss one period of training sessions or over a period time. . The code chunk below loads the data using the method runpandas.read_directory_aggregate, which allows the user to read all the tracking files of a support format in a directory and combine them in a data frame split by sessions based on the timestamps of each activity. It means that for each workout file will be stored in separate lines in the dataframe. . import runpandas session = runpandas.read_dir_aggregate(dirname=&#39;./data/session/&#39;) . session . alt hr lon lat . start time . 2020-08-30 09:08:51.012 00:00:00 NaN | NaN | -34.893609 | -8.045055 | . 00:00:01.091000 NaN | NaN | -34.893624 | -8.045054 | . 00:00:02.091000 NaN | NaN | -34.893641 | -8.045061 | . 00:00:03.098000 NaN | NaN | -34.893655 | -8.045063 | . 00:00:04.098000 NaN | NaN | -34.893655 | -8.045065 | . ... ... ... | ... | ... | ... | . 2021-07-04 11:23:19.418 00:52:39.582000 0.050001 | 189.0 | -34.894534 | -8.046602 | . 00:52:43.582000 NaN | NaN | -34.894465 | -8.046533 | . 00:52:44.582000 NaN | NaN | -34.894443 | -8.046515 | . 00:52:45.582000 NaN | NaN | -34.894429 | -8.046494 | . 00:52:49.582000 NaN | 190.0 | -34.894395 | -8.046398 | . 48794 rows × 4 columns . session.index #MultiIndex (start, timestamp) . MultiIndex([(&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:00&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:01.091000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:02.091000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:03.098000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:04.098000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:05.096000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:06.096000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:07.097000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:08.097000&#39;), (&#39;2020-08-30 09:08:51.012000&#39;, &#39;00:00:09.102000&#39;), ... (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:18.584000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:22.584000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:26.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:30.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:35.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:39.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:43.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:44.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:45.582000&#39;), (&#39;2021-07-04 11:23:19.418000&#39;, &#39;00:52:49.582000&#39;)], names=[&#39;start&#39;, &#39;time&#39;], length=48794) . Session compute metrics methods . The package comes now with an acessor runpandas.types.acessors.session._SessionAcessor that holds special methods for computing the running metrics across all the activities. The calls delegate to the single activity metrics acessors. . #In this example we compute the distance and the distance per position across all workouts session = session.session.distance() session . alt hr lon lat distpos dist . start time . 2020-08-30 09:08:51.012 00:00:00 NaN | NaN | -34.893609 | -8.045055 | NaN | NaN | . 00:00:01.091000 NaN | NaN | -34.893624 | -8.045054 | 1.690587 | 1.690587 | . 00:00:02.091000 NaN | NaN | -34.893641 | -8.045061 | 2.095596 | 3.786183 | . 00:00:03.098000 NaN | NaN | -34.893655 | -8.045063 | 1.594298 | 5.380481 | . 00:00:04.098000 NaN | NaN | -34.893655 | -8.045065 | 0.163334 | 5.543815 | . ... ... ... | ... | ... | ... | ... | ... | . 2021-07-04 11:23:19.418 00:52:39.582000 0.050001 | 189.0 | -34.894534 | -8.046602 | 12.015437 | 8220.018885 | . 00:52:43.582000 NaN | NaN | -34.894465 | -8.046533 | 10.749779 | 8230.768664 | . 00:52:44.582000 NaN | NaN | -34.894443 | -8.046515 | 3.163638 | 8233.932302 | . 00:52:45.582000 NaN | NaN | -34.894429 | -8.046494 | 2.851535 | 8236.783837 | . 00:52:49.582000 NaN | 190.0 | -34.894395 | -8.046398 | 11.300740 | 8248.084577 | . 48794 rows × 6 columns . #comput the speed for each activity session = session.session.speed(from_distances=True) #compute the pace for each activity session = session.session.pace() #compute the inactivity periods for each activity session = session.session.only_moving() . How many activities are there in the activity ? There is a custom method count that returns the total number of activities in the season frame. . print (session.session.count(), &#39;activities&#39;) . 68 activities . Session summary statistics . After the loading and metrics computation for all the activities, we now can load the basic summaries about the training sessions: time spent, total distance, mean speed and other insightful statistics for each running activity. For this task, we may accomplish it by calling the method runpandas.types.session._SessionAcessor.summarize . It will return a basic Dataframe including all the aggregated statistics per activity from the season frame. . summary = session.session.summarize() summary . moving_time mean_speed max_speed mean_pace max_pace mean_moving_speed mean_moving_pace mean_cadence max_cadence mean_moving_cadence mean_heart_rate max_heart_rate mean_moving_heart_rate mean_temperature min_temperature max_temperature total_distance ellapsed_time . start . 2020-07-03 09:50:53.162 00:25:29.838000 | 2.642051 | 4.879655 | 00:06:18 | 00:03:24 | 2.665008 | 00:06:15 | NaN | NaN | NaN | 178.819923 | 188.0 | 178.872587 | NaN | NaN | NaN | 4089.467333 | 00:25:47.838000 | . 2020-07-05 09:33:20.999 00:05:04.999000 | 2.227637 | 6.998021 | 00:07:28 | 00:02:22 | 3.072098 | 00:05:25 | NaN | NaN | NaN | 168.345455 | 176.0 | 168.900000 | NaN | NaN | NaN | 980.162640 | 00:07:20.001000 | . 2020-07-05 09:41:59.999 00:18:19 | 1.918949 | 6.563570 | 00:08:41 | 00:02:32 | 2.729788 | 00:06:06 | NaN | NaN | NaN | 173.894180 | 185.0 | 174.577143 | NaN | NaN | NaN | 3139.401118 | 00:27:16 | . 2020-07-13 09:13:58.718 00:40:21.281000 | 2.509703 | 8.520387 | 00:06:38 | 00:01:57 | 2.573151 | 00:06:28 | NaN | NaN | NaN | 170.808176 | 185.0 | 170.795527 | NaN | NaN | NaN | 6282.491059 | 00:41:43.281000 | . 2020-07-17 09:33:02.308 00:32:07.691000 | 2.643278 | 8.365431 | 00:06:18 | 00:01:59 | 2.643278 | 00:06:18 | NaN | NaN | NaN | 176.436242 | 186.0 | 176.436242 | NaN | NaN | NaN | 5095.423045 | 00:32:07.691000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-06-13 09:22:30.985 01:32:33.018000 | 2.612872 | 23.583956 | 00:06:22 | 00:00:42 | 2.810855 | 00:05:55 | NaN | NaN | NaN | 169.340812 | 183.0 | 169.655879 | NaN | NaN | NaN | 15706.017295 | 01:40:11.016000 | . 2021-06-20 09:16:55.163 00:59:44.512000 | 2.492640 | 6.065895 | 00:06:41 | 00:02:44 | 2.749453 | 00:06:03 | NaN | NaN | NaN | 170.539809 | 190.0 | 171.231392 | NaN | NaN | NaN | 9965.168311 | 01:06:37.837000 | . 2021-06-23 09:37:44.000 00:26:49.001000 | 2.501796 | 5.641343 | 00:06:39 | 00:02:57 | 2.568947 | 00:06:29 | NaN | NaN | NaN | 156.864865 | 171.0 | 156.957031 | NaN | NaN | NaN | 4165.492241 | 00:27:45.001000 | . 2021-06-27 09:50:08.664 00:31:42.336000 | 2.646493 | 32.734124 | 00:06:17 | 00:00:30 | 2.661853 | 00:06:15 | NaN | NaN | NaN | 166.642857 | 176.0 | 166.721116 | NaN | NaN | NaN | 5074.217061 | 00:31:57.336000 | . 2021-07-04 11:23:19.418 00:47:47.583000 | 2.602263 | 4.212320 | 00:06:24 | 00:03:57 | 2.856801 | 00:05:50 | NaN | NaN | NaN | 177.821862 | 192.0 | 177.956967 | NaN | NaN | NaN | 8248.084577 | 00:52:49.582000 | . 68 rows × 18 columns . print(&#39;Session Interval:&#39;, (summary.index.to_series().max() - summary.index.to_series().min()).days, &#39;days&#39;) print(&#39;Total Workouts:&#39;, len(summary), &#39;runnings&#39;) print(&#39;Tota KM Distance:&#39;, summary[&#39;total_distance&#39;].sum() / 1000) print(&#39;Average Pace (all runs):&#39;, summary.mean_pace.mean()) print(&#39;Average Moving Pace (all runs):&#39;, summary.mean_moving_pace.mean()) print(&#39;Average KM Distance (all runs):&#39;, round(summary.total_distance.mean()/ 1000,2)) . Session Interval: 366 days Total Workouts: 68 runnings Tota KM Distance: 491.77377537338896 Average Pace (all runs): 0 days 00:07:18.411764 Average Moving Pace (all runs): 0 days 00:06:02.147058 Average KM Distance (all runs): 7.23 . As we can see above, we analyzed the period of 366 days (one year) of running workouts. In this period, she ran 68 times which achieved the total distance of 491 km! The average moving pace is 06&#39;02&quot; per km and average distance of 7.23km! Great numbers for a starter runner! . What is coming next ? . The next releases will focus on reading of Nike Run app workouts and support plugin for marathon results. It will be awesome, keep tunned! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/07/16/release050.html",
            "relUrl": "/general/jupyter/releases/2021/07/16/release050.html",
            "date": " • Jul 16, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Release 0.4.1 powered by heart zone metrics!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We published this minor release with some new metrics and changes to better improve our build process. In this release of RunPandas 0.4.1, we include: . The Activity now provides some special methods in runpandas.acessors that computes the heart training zones for each record and the time spent for each training zone. | We published for the first time our package to the Anaconda scientific package repository. | Finally, we have changed our CI build implementation from Travis CI to Github actions. Unfortunately, the Travis CI became highly limited to open-source projects, which resulted into several builds to not run anymore due to lack of credits. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to heart training zones metrics . Now runpandas comes with useful methods to data runners who desires to explore their heart rate data and check the heart rate range variation and the respective training zones or the time ellapsed through each training zone during the workout. . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . import runpandas activity = runpandas.read_file(&#39;./data/11km.tcx&#39;) print(&#39;Start&#39;, activity.index[0],&#39;End:&#39;, activity.index[-1]) print(activity.iloc[0][&#39;lat&#39;], activity.iloc[-1][&#39;lat&#39;]) . Start 0 days 00:00:00 End: 0 days 01:16:06 -8.364486 -8.364462 . First, let&#39;s perform a QC evaluation on the data, to check if there&#39;s any invalid or missing data required for the analysis. As you can see in the cell below, there are 5 records with heart rate data missing. We will replace all these with the first HR sensor data available. . import numpy as np group_hr = activity[&#39;hr&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_hr) #There is 5 missing values in HR. Let&#39;s see the positions where they are placed in the frame. print(activity[activity[&#39;hr&#39;].isnull()]) #We will replace all NaN values with the first HR sensor data available activity[&#39;hr&#39;].fillna(activity.iloc[5][&#39;hr&#39;], inplace=True) print(&#39;Total nan after fill:&#39;, activity[&#39;hr&#39;].isnull().sum()) . There are nan records: 5 run_cadence alt dist hr lon lat time 00:00:00 NaN 668.801819 0.000000 NaN -36.577568 -8.364486 00:00:07 NaN 668.714722 5.749573 NaN -36.577465 -8.364492 00:00:10 NaN 668.680603 11.615299 NaN -36.577423 -8.364470 00:00:12 83.0 668.639099 17.306795 NaN -36.577366 -8.364449 00:00:15 82.0 668.600464 22.672394 NaN -36.577312 -8.364429 speed time 00:00:00 0.000000 00:00:07 0.000000 00:00:10 0.000000 00:00:12 2.262762 00:00:15 2.317986 Total nan after fill: 0 . Let&#39;s see how to add a column with the heart rate zone label to the data frame. For this task, we will use the special method runpandas.compute.heart_zone . The parameters are the bins argument which contains the left and right bounds for each training zone and the labels argument corresponding to the zone labels . activity[&#39;heartrate_zone&#39;] = activity.compute.heart_zone( labels=[&quot;Rest&quot;, &quot;Z1&quot;, &quot;Z2&quot;, &quot;Z3&quot;, &quot;Z4&quot;, &quot;Z5&quot;], bins=[0, 92, 110, 129, 147, 166, 184]) activity[&quot;heartrate_zone&quot;].tail() . time 01:15:54 Z4 01:15:56 Z4 01:16:00 Z4 01:16:02 Z4 01:16:06 Z4 Name: heartrate_zone, dtype: category Categories (6, object): [Rest &lt; Z1 &lt; Z2 &lt; Z3 &lt; Z4 &lt; Z5] . To calculate the time in zone, there is also a special method runpandas.compute.time_in_zone which computes the time spent for each training zone. . time_in_zone = activity.compute.time_in_zone( labels=[&quot;Rest&quot;, &quot;Z1&quot;, &quot;Z2&quot;, &quot;Z3&quot;, &quot;Z4&quot;, &quot;Z5&quot;], bins=[0, 92, 110, 129, 147, 166, 184]) time_in_zone . hr_zone Rest 00:00:00 Z1 00:04:10 Z2 00:07:05 Z3 00:31:45 Z4 00:33:06 Z5 00:00:00 Name: time_diff, dtype: timedelta64[ns] . Anaconda Package . We decided to publish our runpandas packages at one of the most popular pythonic scientific package repositories : Anaconda . There are more millions data science packages published focusing on scientific areas. In this release we published at the owner&#39;s package repository (https://anaconda.org/marcelcaraciolo/runpandas), but the goal is to publish it at the conda-forge main repository. We will work on this task to submit our package as a release candidate. . Changing the Build script to suppor the Github Actions . Since last year the CI/CD provider TravisCI started to put several limitations to their free tier quotes , specially to open-source projects with had a specific ammount of time-credits for builds. We understood that for them it was a big decision , because building open source products and maintain them is extremely difficult. Since runpandas is a fully open source package, I decided to find other CI provider. . Github Actions came to the rescue, since it remains free for any open-source project hosted in Github. Finally, I moved in this release all the build scripts to the Github actions. . . For further information about the Github Actions and see how it works, please check this article and this post. . What is coming next ? . The next releases will come with power metrics and support to the workout summary visualization. So stay tunned! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/05/28/release-v041.html",
            "relUrl": "/general/jupyter/releases/2021/05/28/release-v041.html",
            "date": " • May 28, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Running powered by heart training zones.",
            "content": "Many runners use the heart rate (HR) data to plan their training strategies. Heart rate is an individual metric and differs between athletes running the same pace, therefore, it can help them to pace themselves properly and can be a useful metric to gauge fatigue and fitness level. One of the most popular systems used by marathon trainers including the heart rate are the ones introduced by Daniels Running Formula and those adopted by Garmin services; in both they define zones taking account the maximum heart rate and resting heart rate. These zones are broad for the convenience of the athlete when performing workouts at a given intensity. This intensity should vary depending on the purpose of the workout (recovery, threshold, VO2 max intervals , etc.). . Below, we present the zones using percentage of maximum heart rate (HRmax) as cuttofs. . Table 1. Training Modes for Different Heart Rate Zones (Daniels vs Garmin Cutoffs) . But why heart rate is an important marker of running effort ? Studies suggest that the human running is an energy transfer process. Running economy can be measured by how fast one can run, given a level of oxygen consumption (VO2). VO2 level is almost linearly correlated with running pace (effort) and high correlated with heart rate. The new devices provide HR recordings and it is easier to measure the HR instead of other markers. . Figure 2. Relationship between HR, VO2, Lactate, and Running Pace. Photo taken from the Website Mcmillanrunning . For many experienced runners, it would be important to analyze your historical workouts, explore your heart rate range variation and check the ellapsed time through each training zone in order to ensure that you are running at the right effort level to maximize your workout. In this post we will present how we can explore our heart rate (HR) records and the respective training zones based on the data provided from the smartwatches or tracking running apps. . Analyzing the heart data and building the respective training zones . Finding my maximum HR . The easiest way resorts to a empirical equation, HRmax = 220 - Age. It is drawn from some epidemiological studies; thus, may not personalized. A better way is to monitor HR while running uphill intervals or use your historical data to compute your HRmax. In this scenario let&#39;s use the empirical HRmax. My current age is 36, so my max heart rate would be 184 (HRmax = 220-36). . Computing the training zones . As we explained above, the heart rate is grouped by zones: active recovery (easy running), general aerobic (marathon pace), basic endurance or the lactate threshold zone (tempo run) and the anaerobic or the VO2 max work(interval). For my maximum heart rate of 184, based on the Garmin&#39;s thresholds, the zones can be calculated as: . Zone heart_rate . Z1 (Active recovery) | | 110 | . Z2 (Endurance) | | 129 | . Z3 (Tempo) | | 147 | . Z4 (Threshold) | | 166 | . Z5 (VO2 Max) | | 184 | . Using the Heart Rate Zones to Review a Workout . Now that we have the training zones, by using runpandas we could play with our workouts and evaluate the quality of the workouts based on its training zones. . In this example, I selected one of my workouts to further explore these zones and how they correlate with the sensors data available recorded. . import runpandas activity = runpandas.read_file(&#39;./data/11km.tcx&#39;) print(&#39;Start&#39;, activity.index[0],&#39;End:&#39;, activity.index[-1]) print(activity.iloc[0][&#39;lat&#39;], activity.iloc[-1][&#39;lat&#39;]) . Start 0 days 00:00:00 End: 0 days 01:16:06 -8.364486 -8.364462 . First, let&#39;s perform a QC evaluation on the data, to check if there&#39;s any invalid or missing data required for the analysis. As you can see in the cell below, there are 5 records with heart rate data missing. We will replace all these with the first HR sensor data available. . import numpy as np group_hr = activity[&#39;hr&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_hr) #There is 5 missing values in HR. Let&#39;s see the positions where they are placed in the frame. print(activity[activity[&#39;hr&#39;].isnull()]) #We will replace all NaN values with the first HR sensor data available activity[&#39;hr&#39;].fillna(activity.iloc[5][&#39;hr&#39;], inplace=True) print(&#39;Total nan after fill:&#39;, activity[&#39;hr&#39;].isnull().sum()) . There are nan records: 5 run_cadence alt dist hr lon lat time 00:00:00 NaN 668.801819 0.000000 NaN -36.577568 -8.364486 00:00:07 NaN 668.714722 5.749573 NaN -36.577465 -8.364492 00:00:10 NaN 668.680603 11.615299 NaN -36.577423 -8.364470 00:00:12 83.0 668.639099 17.306795 NaN -36.577366 -8.364449 00:00:15 82.0 668.600464 22.672394 NaN -36.577312 -8.364429 speed time 00:00:00 0.000000 00:00:07 0.000000 00:00:10 0.000000 00:00:12 2.262762 00:00:15 2.317986 Total nan after fill: 0 . The same QC method will be applied on the elevation , speed and distance sensor data. However, to fill the missing data we will apply a special method in pandas.DataFrame.fillna with the method=&#39;ffill&#39; option. &#39;ffill&#39; stands for &#39;forward fill&#39; and will propagate last valid observation forward. . group_alt = activity[&#39;alt&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_alt) #There is 16 missing values in HR. Let&#39;s see the positions where they are placed in the frame. print(activity[activity[&#39;alt&#39;].isnull()]) #We will replace all NaN values with the last valid alt sensor data available activity[&#39;alt&#39;].fillna(method=&#39;ffill&#39;, inplace=True) print(&#39;Total nan after fill:&#39;, activity[&#39;alt&#39;].isnull().sum()) . There are nan records: 16 run_cadence alt dist hr lon lat speed time 00:17:28 NaN NaN 2423.089355 105.0 NaN NaN 0.000000 00:17:31 NaN NaN 2430.292969 105.0 NaN NaN 0.830682 00:33:40 86.0 NaN 4918.916016 156.0 NaN NaN 2.692340 00:34:14 84.0 NaN 4985.800293 148.0 NaN NaN 2.390405 00:34:25 84.0 NaN 4998.516602 144.0 NaN NaN 2.554120 00:36:11 NaN NaN 5001.374512 101.0 NaN NaN 0.000000 00:46:43 86.0 NaN 6641.856445 138.0 NaN NaN 2.226430 00:46:44 86.0 NaN 6645.643555 138.0 NaN NaN 2.167022 00:46:49 57.0 NaN 6652.708008 136.0 NaN NaN 1.493457 00:48:43 57.0 NaN 6944.145996 147.0 NaN NaN 1.513124 00:52:55 87.0 NaN 7601.044434 158.0 NaN NaN 2.645489 00:52:58 87.0 NaN 7607.790039 157.0 NaN NaN 2.646207 00:53:00 87.0 NaN 7612.979004 157.0 NaN NaN 2.645122 00:53:03 87.0 NaN 7619.605957 158.0 NaN NaN 2.644240 01:01:25 87.0 NaN 8948.444336 148.0 NaN NaN 2.709680 01:03:22 NaN NaN 9025.351562 111.0 NaN NaN 0.742738 Total nan after fill: 0 . group_dist = activity[&#39;dist&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_dist) #There is non missing values in distance series. print(activity[activity[&#39;dist&#39;].isnull()]) group_speed = activity[&#39;speed&#39;].isnull().sum() print(&quot;There are nan records: %d&quot; % group_speed) #There is non missing values in speed series. print(activity[activity[&#39;speed&#39;].isnull()]) . There are nan records: 0 Empty Activity Columns: [run_cadence, alt, dist, hr, lon, lat, speed] Index: [] There are nan records: 0 Empty Activity Columns: [run_cadence, alt, dist, hr, lon, lat, speed] Index: [] . The first question is to see how my heart data changed over time during my workout. In the figure below I present my heart data varying as a function time. For plotting the data I have used the matplotlib package. . import pandas as pd import numpy as np import matplotlib.patches as mpatches from matplotlib import pyplot as plt plt.style.use(&#39;seaborn-poster&#39;) ZONE_COLORS_0 = { 1: &#39;#ffffcc&#39;, 2: &#39;#a1dab4&#39;, 3: &#39;#41b6c4&#39;, 4: &#39;#2c7fb8&#39;, 5: &#39;#253494&#39; } def format_time_delta(time_delta): &quot;&quot;&quot;Create string after formatting time deltas.&quot;&quot;&quot; timel = [] for i in time_delta: hours, res = divmod(i, 3600) minutes, seconds = divmod(res, 60) timel.append(&#39;{:02d}:{:02d}:{:02d}&#39;.format(int(hours), int(minutes), int(seconds))) return timel def _make_time_labels(delta_seconds, nlab=5): &quot;&quot;&quot;Make n time formatted labels for data i seconds&quot;&quot;&quot; label_pos = np.linspace(min(delta_seconds), max(delta_seconds), nlab, dtype=np.int_) label_lab = format_time_delta(label_pos) return label_pos, label_lab def heart_rate_zone_limits(maxpulse=187): &quot;&quot;&quot;Return the limits for the heart rate zones.&quot;&quot;&quot; lims = [(0.5, 0.6), (0.6, 0.7), (0.7, 0.8), (0.8, 0.9), (0.9, 1.0)] return [(maxpulse * i[0], maxpulse * i[1]) for i in lims] def plot_hr(data, maxpulse=184): &quot;&quot;&quot;Plot the heart rate per time with training zones.&quot;&quot;&quot; fig = plt.figure() ax1 = fig.add_subplot(111) ax1.set_facecolor(&#39;0.90&#39;) xdata = data.index.total_seconds().tolist() ydata = data[&#39;hr&#39;].tolist() handles = [] legends = [] zones = heart_rate_zone_limits(maxpulse=maxpulse) for i, zone in enumerate(zones): patch = mpatches.Patch(color=ZONE_COLORS_0[i+1]) legend = &#39;Zone = {}&#39;.format(i + 1) handles.append(patch) legends.append(legend) ax1.axhspan(zone[0], zone[1], color=ZONE_COLORS_0[i+1]) ax1.plot(xdata, ydata, color=&#39;#262626&#39;, lw=3) ax1.legend(handles, legends) ax1.set_ylim(min(ydata) - 2, max(ydata) + 2) label_pos, label_lab = _make_time_labels(xdata, 5) ax1.set_xticks(label_pos) ax1.set_xticklabels(label_lab, rotation=25) ax1.set_xlabel(&#39;Time&#39;) ax1.set_ylabel(&#39;Heart rate / bpm&#39;) fig.tight_layout() return fig fig = plot_hr(activity, maxpulse=184) . From the chart we can conclude that during periodic intervals, I had a rapid loss of the heart rate , probably due to a stop during the workout. Another important insight is that my training zone kept most of the time between the Z2-Z3 (endurance-tempo run). But how did the altitude interfer in this variation ? . For this question, based on my elevation profile (the altitude variation) as a function time, I plot the elevation against function of time to check the influence of the altitude. . def find_regions(yval): &quot;&quot;&quot;Find borders for regions with equal values. Parameters - yval : array_like The values we are to locate regions for. Returns - new_regions : list of lists of numbers The regions where yval is constant. These are on the form ``[start_index, end_index, constant_y]`` with the interpretation that ``yval=constant-y`` for the index range ``[start_index, end_index]`` &quot;&quot;&quot; regions = [] region_y = None i = None for i, ypos in enumerate(yval): if region_y is None: region_y = ypos if ypos != region_y: regions.append([i, region_y]) region_y = ypos # for adding the last region if i is not None: regions.append([i, region_y]) new_regions = [] for i, region in enumerate(regions): if i == 0: reg = [0, region[0], region[1]] else: reg = [regions[i-1][0], region[0], region[1]] new_regions.append(reg) return new_regions def calculate_hr_zones(data, max_heart_rate=184): limits = heart_rate_zone_limits(max_heart_rate) bins = [i[0] for i in limits] hr_zone = np.digitize(data[&#39;hr&#39;], bins, right=False) hr_zone_limis = find_regions(hr_zone) return hr_zone_limis def plot_elevation_hrz(track_name, track_type, data): &quot;&quot;&quot;Plot the elevation profile with heart rate annotations.&quot;&quot;&quot; fig = plt.figure() ax1 = fig.add_subplot(111) ax1.set_facecolor(&#39;0.90&#39;) ax1.set_title(&#39;{}: {}&#39;.format(track_name, track_type)) xdata = data.index.total_seconds().tolist() ydata = data[&#39;alt&#39;].tolist() ax1.plot(xdata, ydata, color=&#39;#262626&#39;, lw=3) handles = [] legends = [] for i in calculate_hr_zones(activity): xpos = xdata[i[0]:i[1]+1] ypos = ydata[i[0]:i[1]+1] ax1.fill_between(xpos, 0, ypos, alpha=1.0, color=ZONE_COLORS_0[i[2]]) for i in range(1, 6): patch = mpatches.Patch(color=ZONE_COLORS_0[i]) legend = &#39;Zone = {}&#39;.format(i) handles.append(patch) legends.append(legend) ax1.legend(handles, legends) ax1.set_ylim(min(ydata) - 2, max(ydata) + 2) label_pos, label_lab = _make_time_labels(xdata, 5) ax1.set_xticks(label_pos) ax1.set_xticklabels(label_lab, rotation=25) ax1.set_xlabel(&#39;Time&#39;) ax1.set_ylabel(&#39;Elevation / m&#39;) fig.tight_layout() return fig fig = plot_elevation_hrz(track_name=&#39;Sanharo 11km&#39;, track_type=&#39;Running&#39;, data=activity) . As we can see at the chart, some intervals due to the elevation gain , the effort is increasingly accordingly, which hits my heart rate. Probably, while running into some elevation, the height and speed increasingly difficult my heart to get enough oxygen to my muscles. Now, let&#39;s see whether the speed also take effect in my heart rate variation. . In the plot below, it shows the correlation between speed x altitude x heart rate. The velocity keeps steadily along all the workout, but when there is a elevation gain and the speed keeps the same, probably there is a variation on my heart rate (Zone Z3 to Zone Z4). . plt.style.use(&#39;seaborn-talk&#39;) def smooth(signal, points): &quot;&quot;&quot;Smooth the given signal using a rectangular window.&quot;&quot;&quot; window = np.ones(points) / points return np.convolve(signal, window, mode=&#39;same&#39;) def plot_dist_hr_velocity(data): fig = plt.figure() ax1 = fig.add_subplot(111) x = activity[&#39;dist&#39;].tolist() y = activity[&#39;alt&#39;].tolist() line1, = ax1.plot(x, y, lw=5) # Fill the area: ax1.fill_between(x, y, y2=min(y), alpha=0.3) ax1.set(xlabel=&#39;Distance / km&#39;, ylabel=&#39;Elevation&#39;) # Add heart rate: ax2 = ax1.twinx() # Smooth the heart rate for plotting: z = data[&#39;hr&#39;].tolist() heart = smooth(z, 51) line2, = ax2.plot(x, heart, color=&#39;#1b9e77&#39;, alpha=0.8, lw=5) ax2.set_ylim(0, 200) ax2.set(ylabel=&#39;Heart rate / bpm&#39;) # Add velocity: ax3 = ax1.twinx() ax3.spines[&#39;right&#39;].set_position((&#39;axes&#39;, 1.2)) # Smooth the velocity for plotting: velocity = data[&#39;speed&#39;] vel = 3.6 * smooth(velocity, 51) line3, = ax3.plot(x, vel, alpha=0.8, color=&#39;#7570b3&#39;, lw=5) ax3.set(ylabel=&#39;Velocity / km/h&#39;) ax3.set_ylim(0, 20) # Style plot: axes = (ax1, ax2, ax3) lines = (line1, line2, line3) for axi, linei in zip(axes, lines): axi.yaxis.label.set_color(linei.get_color()) axi.tick_params(axis=&#39;y&#39;, colors=linei.get_color()) key = &#39;right&#39; if axi != ax1 else &#39;left&#39; axi.spines[key].set_edgecolor(linei.get_color()) axi.spines[key].set_linewidth(2) ax1.spines[&#39;top&#39;].set_visible(False) for axi in (ax2, ax3): for key in axi.spines: axi.spines[key].set_visible(False) axi.spines[&#39;right&#39;].set_visible(True) # Add legend: ax1.legend( (line1, line2, line3), (&#39;Elevation&#39;, &#39;Heart rate&#39;, &#39;Velocity&#39;), loc=&#39;upper left&#39;, frameon=False ) fig = plot_dist_hr_velocity(activity) . Finally, let&#39;s see how many minutes were spent in each HR zone. The plot below shows that most time of the training my heart was between Z3 and Z4 zones. . from matplotlib.cm import get_cmap plt.style.use(&#39;seaborn-talk&#39;) def get_limits_text(max_heart_rate=184): limits = heart_rate_zone_limits(max_heart_rate) txt = { 0: f&#39;$&lt;${int(limits[0][0])} bpm&#39;, 1: f&#39;{int(limits[0][0])}‒{int(limits[0][1])} bpm&#39;, 2: f&#39;{int(limits[1][0])}‒{int(limits[1][1])} bpm&#39;, 3: f&#39;{int(limits[2][0])}‒{int(limits[2][1])} bpm&#39;, 4: f&#39;{int(limits[3][0])}‒{int(limits[3][1])} bpm&#39;, 5: f&#39;$&gt;${int(limits[3][1])} bpm&#39;, } return txt def plot_hr_distribution(data): fig = plt.figure() ax1 = fig.add_subplot(111) time = data.index.total_seconds().tolist() time_in_zones = {} for start, stop, value in calculate_hr_zones(activity): seconds = (time[stop] - time[start]) if value not in time_in_zones: time_in_zones[value] = 0 time_in_zones[value] += seconds sum_time = sum([val for _, val in time_in_zones.items()]) # Check consistency: print(&#39;Times are equal?&#39;, sum_time == (time[-1] - time[0])) zone_txt = get_limits_text() zones = sorted(list(time_in_zones.keys())) percent = { key: 100 * val / sum_time for key, val in time_in_zones.items() } labels = [ f&#39;Zone {i} ({zone_txt[i]}) n({percent[i]:.1f}%)&#39; for i in zones ] values = [time_in_zones[i] for i in zones] times = format_time_delta(values) cmap = get_cmap(name=&#39;Reds&#39;) colors = cmap(np.linspace(0, 1, len(zones) + 1)) colors = colors[1:] # Skip the first color rects = ax1.barh(zones, values, align=&#39;center&#39;, tick_label=labels) for i, recti in enumerate(rects): recti.set_facecolor(colors[i]) width = int(recti.get_width()) yloc = recti.get_y() + recti.get_height() / 2 ax1.annotate( times[i], xy=(width, yloc), xytext=(3, 0), textcoords=&quot;offset points&quot;, ha=&#39;left&#39;, va=&#39;center&#39;, fontsize=&#39;x-large&#39; ) ax1.spines[&#39;top&#39;].set_visible(False) ax1.spines[&#39;right&#39;].set_visible(False) ax1.spines[&#39;bottom&#39;].set_visible(False) ax1.tick_params(bottom=False) ax1.tick_params(labelbottom=False) fig.tight_layout() return fig fig = plot_hr_distribution(activity) . Times are equal? True . With the plots produced at hand, I could check if the training was effective. In this workout, I found out, that I could set my heart rate alert to check when I have to leave the zone by running faster or slower depending on my workout plan and how the altitude had a play in my heart rate variation. . What&#39;s coming to next releases of Runpandas . In future releases, we will provide special methods to runpandas in order to compute the training zones to each record in the activity and the time spent in each zone. We are also planning special plots like those above to be called directly from the package. Stay tunned! .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/training/metrics/features/2021/05/20/trainingzones.html",
            "relUrl": "/general/jupyter/training/metrics/features/2021/05/20/trainingzones.html",
            "date": " • May 20, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Release 0.4.0 with new running metrics and examples package!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . It has beeen a while since our last release, this is because we are working hard in new features in our new release of RunPandas 0.4. Let&#39;s highlight them: . The Activity now provides extra running statistics such as Vertical Altitude Speed (VAM), mean speed, mean pace, gradient, and mean heart rate. | Now we provide in our runpandas.MeasureSeries the capability of conversions such as distance conversion (km - miles), latitudes and longitudes (degrees - radians) and pace conversion (min/km and min/mile). | There is an auxiliar package for loading activity examples for testing and demo purposes: runpandas.datasets . The goal is to enrich with several real examples in FIT, GPX and TCX format files. | Finally, there is a CI workflow for uploading automatically a package to Pypi after release. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to some new running metrics such as mean pace and mean speed. . First let&#39;s explain the differences between mean pace and mean speed. Although both values express similar information, they are the reverse of each other. The Pace is how much time you need to cover a particular distance, while speed is an indicator of the number of meters you are able to cover within one second. These values can be presented different, depending on the measure units used to express these metrics. Pace is given in unit of time per unit of distance, whereas speed is distance over time. . The formulas are: . Speed (m/s) = distance (m) / time (s) . Pace (s/m) = time (sec) / distance (m) . We provide in runpandas new acessors (runpandas.acessors) for computing those metrics: . #Disable Warnings for a better visualization import warnings warnings.filterwarnings(&#39;ignore&#39;) . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . #compute the distance using haversine formula between two consecutive latitude, longitudes observations. activity[&#39;distpos&#39;] = activity.compute.distance() #compute the speed normalized per interval. activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;speed&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 0.335758 00:00:12 1.939984 00:00:16 2.295962 Name: speed, dtype: float64 . print(&#39;Mean speed m/s:&#39;, activity.mean_speed()) print(&#39;Mean pace s/m:&#39;, activity.mean_pace()) . Mean speed m/s: 2.3545989706029533 Mean pace s/m: 0 days 00:00:00.424701 . Generally this is shown in different units like speed (km/h) and pace (min/km): . #convert m/s to km/h by multiplying the factor of 3.6 print(&#39;Mean speed km/h:&#39;, activity.mean_speed() * 3.6) #We define a auxiliar function to convert the pace from sec/m to min/km: def convert_pace_secmeters2minkms(seconds): from pandas import Timedelta pace_min = int((seconds * 1000) / 60) pace_sec = int(seconds * 1000 - (pace_min * 60)) total_seconds = (pace_min * 60) + pace_sec return Timedelta(seconds=total_seconds) pace_min_km = convert_pace_secmeters2minkms(activity.mean_pace().total_seconds()) print(&#39;Mean pace min/km:&#39;, pace_min_km) . Mean speed km/h: 8.476556294170631 Mean pace min/km: 0 days 00:07:04 . Support to gradient and vertical speed. . Gradient is a measure of the route steepness-the magnitude of its incline or slope as compared to the horizontal. Most often presented as a percentage, the gradient of a climb will normally fall somewhere between 3-15 percent. For practical use, it is usually used for estimating the difficulty of the climb during the route. . #Gradient computed through the distance points activity[&#39;grad&#39;] = activity.compute.gradient() activity[&#39;grad&#39;] . time 00:00:00 NaN 00:00:01 NaN 00:00:06 0.000000 00:00:12 -0.121218 00:00:16 0.000000 ... 00:32:51 0.028739 00:32:56 -0.028715 00:33:02 -0.042557 00:33:07 -0.051672 00:33:11 -0.097842 Name: grad, Length: 383, dtype: float64 . VAM (Vertical Altitude Speed) similar to speed except it tracks how fast you go up vertically rather than horizontally between two points. While speed is measured in miles or kilometers per hour, VAM is measured in vertical meters per hour (vmh). It tells you how many meters you would climb if you went up a moderate grade for an hour. . #Vertical Altitude Speed (VAM) in m/s activity[&#39;vam&#39;] = activity.compute.vertical_speed() activity[&#39;vam&#39;] . time 00:00:00 NaN 00:00:01 0.000000 00:00:06 0.000000 00:00:12 -0.240336 00:00:16 0.000000 ... 00:32:51 0.096118 00:32:56 -0.096118 00:33:02 -0.160217 00:33:07 -0.192285 00:33:11 -0.360504 Name: vam, Length: 383, dtype: float64 . Support to other metrics such as mean heart_pace . #Meart heart rate through the activity &#39;bpm&#39;, int(activity.mean_heart_rate()) . (&#39;bpm&#39;, 156) . Some conversion functions available for measure metrics . #convert the speed m/s to km/h activity[&#39;speed&#39;].kph . time 00:00:00 NaN 00:00:01 1.199325 00:00:06 1.208731 00:00:12 6.983941 00:00:16 8.265462 ... 00:32:51 11.864734 00:32:56 12.001946 00:33:02 13.600020 00:33:07 13.428554 00:33:11 13.155589 Name: speed, Length: 383, dtype: float64 . #gradient converted from degrees to percent activity[&#39;grad&#39;].pct . time 00:00:00 NaN 00:00:01 NaN 00:00:06 0.000000 00:00:12 -12.121772 00:00:16 0.000000 ... 00:32:51 2.873890 00:32:56 -2.871543 00:33:02 -4.255745 00:33:07 -5.167165 00:33:11 -9.784157 Name: grad, Length: 383, dtype: float64 . #Total Altitude descent and ascent print(&#39;Ascent&#39;, sum(activity[&#39;alt&#39;].ascent)) print(&#39;Descent&#39;, sum(activity[&#39;alt&#39;].descent)) . Ascent 153.80981445000006 Descent -166.30712890300006 . #distance from meters to kms activity[&#39;dist&#39;].km . time 00:00:00 0.000000 00:00:01 0.000000 00:00:06 0.001107 00:00:12 0.013003 00:00:16 0.022405 ... 00:32:51 4.613642 00:32:56 4.630378 00:33:02 4.652966 00:33:07 4.671573 00:33:11 4.686311 Name: dist, Length: 383, dtype: float64 . An example activities package including several real word activities from different formats. . The runpandas package also comes with extra batteries, such as our runpandas.datasets package, which includes a range of example data for testing purposes. There is a dedicated repository with all the data available. An index of the data is kept here. . example_fit = rpd.activity_examples(path=&#39;Garmin_Fenix_6S_Pro-Running.fit&#39;) print(example_fit.summary) print(&#39;Included metrics:&#39;, example_fit.included_data) . Synced from watch Garmin Fenix 6S Included metrics: [&lt;MetricsEnum.latitude: &#39;latitude&#39;&gt;, &lt;MetricsEnum.longitude: &#39;longitude&#39;&gt;, &lt;MetricsEnum.elevation: &#39;elevation&#39;&gt;, &lt;MetricsEnum.heartrate: &#39;heartrate&#39;&gt;, &lt;MetricsEnum.cadence: &#39;cadence&#39;&gt;, &lt;MetricsEnum.distance: &#39;distance&#39;&gt;, &lt;MetricsEnum.temperature: &#39;temperature&#39;&gt;] . rpd.read_file(example_fit.path).head() . enhanced_speed enhanced_altitude unknown_87 fractional_cadence lap session unknown_108 dist cad hr lon lat temp . time . 00:00:00 0.000 | 254.0 | 0 | 0.0 | 0 | 0 | NaN | 0.00 | 0 | 101 | 13.843376 | 51.066280 | 8 | . 00:00:01 0.000 | 254.0 | 0 | 0.0 | 0 | 0 | NaN | 0.00 | 0 | 101 | 13.843374 | 51.066274 | 8 | . 00:00:10 1.698 | 254.0 | 0 | 0.0 | 0 | 1 | 2362.0 | 0.00 | 83 | 97 | 13.843176 | 51.066249 | 8 | . 00:00:12 2.267 | 254.0 | 0 | 0.0 | 0 | 1 | 2362.0 | 3.95 | 84 | 99 | 13.843118 | 51.066250 | 8 | . 00:00:21 2.127 | 254.6 | 0 | 0.5 | 0 | 1 | 2552.0 | 16.67 | 87 | 100 | 13.842940 | 51.066231 | 8 | . In case of you just only want to see all the activities in a specific file type , you can filter the runpandas.activities_examples, which returns a filter iterable that you can iterate over: . fit_examples = rpd.activity_examples(file_type=rpd.FileTypeEnum.FIT) for example in fit_examples: #Download and play with the filtered examples print(example.path) . https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Fenix_6S_Pro-Running.fit https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Fenix2_running_with_hrm.fit https://raw.githubusercontent.com/corriporai/runpandas-data/master/activities/Garmin_Forerunner_910XT-Running.fit . What is coming next ? . Working hard in advanced running metrics such as power , heart rate zones and the feature of printing the summary of the activity with the main statistics. . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/04/24/release-v04.html",
            "relUrl": "/general/jupyter/releases/2021/04/24/release-v04.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Release 0.3.0 with moving metrics!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We are very excited to announce RunPandas 0.3. This release comes with new features and fixes, let&#39;s highlight them: . Support to moving metrics, with the capability of detecting periods of inactivity. | Support to compute some running general statistics such as total time elapsed and moving time elapsed. | Support to imputated statistics: speed in m/s and total distance and distance per position. | Added Zenodo DOI badge | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Support to calculated running metrics: total elapsed time, speed and total distance . The Activity dataframe now contains special properties that presents some statistics from the workout such as elapsed time, speed and the distance of workout in meters. . #Disable INFO Logging for a better visualization import logging logging.getLogger().setLevel(logging.CRITICAL) . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . The total ellapsed time is the duration from the moment you hit start on your device until the moment you finish the activity. The total distance is the total of meters ran by the athetle in the activity. The speed is measured in meters per second, and returns a runpandas.MeasureSeries.Speed series with the ratio of the distance traveled per record and the number of seconds to run it. . Occasionally, some observations such as speed, distance and others must be calculated based on available data in the given activity. In runpandas there are special accessors (runpandas.acessors) that computes some of these metrics. We will compute the speed and the distance per position observations using the latitude and longitude for each record and calculate the haversine distance in meters and the speed in meters per second. . #total time elapsed for the activity print(activity.ellapsed_time) #distance of workout in meters print(activity.distance) . 0 days 00:33:11 4686.31103516 . #compute the distance using haversine formula between two consecutive latitude, longitudes observations. activity[&#39;distpos&#39;] = activity.compute.distance() activity[&#39;distpos&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 1.678792 00:00:12 11.639901 00:00:16 9.183847 Name: distpos, dtype: float64 . #compute the speed using the distance per position and the time recorded in seconds to run it. activity[&#39;speed&#39;] = activity.compute.speed(from_distances=True) activity[&#39;speed&#39;].head() . time 00:00:00 NaN 00:00:01 0.333146 00:00:06 0.335758 00:00:12 1.939984 00:00:16 2.295962 Name: speed, dtype: float64 . In runpandas we will also have special atributes at the runpandas.MeasureSeries that can compute transformations such as speed conversion from m/s to km/h. . #kph property that converts m/s to km/h. activity[&#39;speed&#39;].kph . time 00:00:00 NaN 00:00:01 1.199325 00:00:06 1.208731 00:00:12 6.983941 00:00:16 8.265462 ... 00:32:51 11.864734 00:32:56 12.001946 00:33:02 13.600020 00:33:07 13.428554 00:33:11 13.155589 Name: speed, Length: 383, dtype: float64 . Support to detection of periods of inactivity (Moving time) . With the advent of the advanced tracking devices, they are capable of estimating the time that the runner was active. Then new devices can now calculate the moving time based on the GPS locations, distance, and speed of the activity. There are cases that the athlete can also use the pause button to deliberately pause the activity for any reason (stoplights, active rests, bathroom stops or even stopping for photos). . Runpandas will attempt to calculate based on the metrics available in the activity the moving time by detecting all the periods of inactivity. The formula is based on the speed per record (distance recorded) below a specified threshold. It is a powerful metric that the runner can now know to see his real performance, removing any bias related to stopped periods. This metric is quite popular also in several tracking platforms such as Garmin and Strava. . With the new dataframe auxiliar method Activity.only_moving, runpandas detects the periods of inactivity and returns the moving series containing all the observations considered to be stopped. It returns a runpandas.Activity dataframe with a special column named moving indexed by the Activity&#39;s TimeIndex. It is pandas.Series containing a vector of booleans which indicates the stopped periods. Boolean indexing it will help build quick filters to ignore any observations considered by the algorithm as a inactivity. . activity_only_moving = activity.only_moving() print(activity_only_moving[&#39;moving&#39;].head()) . time 00:00:00 False 00:00:01 False 00:00:06 False 00:00:12 True 00:00:16 True Name: moving, dtype: bool . Now we can compute the stopped time and the moving time. . print(&#39;The stopped period:&#39;, activity_only_moving[activity_only_moving[&#39;moving&#39;] == False].index.sum()) . The stopped period: 0 days 00:00:07 . print(&#39;The moving time:&#39;, activity_only_moving.moving_time) . The moving time: 0 days 00:33:05 . What is coming next ? . We will load several running metrics and statistics to our activities and measure series in order to provide the user deeper details about their running activities. It will includes heart time zones, average speed, personal best records per distance, and more! . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/03/17/release-v03.html",
            "relUrl": "/general/jupyter/releases/2021/03/17/release-v03.html",
            "date": " • Mar 17, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Understanding moving time vs ellapsed time, distance and speed/pace calculations",
            "content": "Sport tracking applications and the social networks are quite popular among the runners nowadays. Everyone wants to perform the best run looking for a better pace, distance or time. But have you wondered how these metrics are calculated ? . In this post we’ll use gpx-file downloaded from Strava social application, extract, and analyse the gpx data of one single route. We’ll start with extracting the data from the gpx-file into a convenient runpandas.Activity dataframe. From there we’ll explore the data and try to replicate the stats and graphs that the interface of one most popular running application provides us with. . Getting the data . Most of the popular tracking apps allow you to download your activity as a gpx or tcx file. In this post, we will analyse a 12km run from Strava. The gpx-file, short for GPS Exchange Format, can usually be obtained by clicking on export. The screenshot below shows you where you can download your gpx-file in Strava. You can download the file used in this article here. . . Now, we want to load our gpx data into a runpandas.Activity. Take a look at your start point and end point and make sure everything makes sense (i.e. start time &lt; end time). If not, there might be something wrong with your data, or you might have forgotten about some tracks or segments. . import runpandas activity = runpandas.read_file(&#39;./data/post-metrics.gpx&#39;) print(&#39;Start&#39;, activity.index[0],&#39;End:&#39;, activity.index[-1]) print(activity.iloc[0][&#39;lat&#39;], activity.iloc[-1][&#39;lat&#39;]) . Start 0 days 00:00:00 End: 0 days 01:25:27 -8.045075 -8.036119 . The head of the activity (frame) should look like this: . activity.head(8) . cad alt hr lon lat . time . 00:00:00 84.0 | 12.7 | 174.0 | -34.893787 | -8.045075 | . 00:00:04 84.0 | 12.7 | 174.0 | -34.893787 | -8.045075 | . 00:00:06 84.0 | 12.7 | 174.0 | -34.893810 | -8.045115 | . 00:00:08 84.0 | 12.7 | 174.0 | -34.893852 | -8.045168 | . 00:00:10 84.0 | 12.7 | 174.0 | -34.893890 | -8.045216 | . 00:00:13 84.0 | 12.7 | 174.0 | -34.893898 | -8.045266 | . 00:00:16 85.0 | 12.7 | 174.0 | -34.893898 | -8.045282 | . 00:00:19 86.0 | 12.7 | 174.0 | -34.893906 | -8.045329 | . It is important to notice that the time interval between two data points isn&#39;t constant. This happens because the device which records the data can&#39;t always provide the GPS-data due to connectivity problems or even to hardware limitation. In case of such a failure/limitation the data point is skipped (without an error) and the app will collect the data at the next time interval. So keep in mind that for further analysis we can&#39;t assume that the interval between all points is the same. . Plotting the data . Now with the data loaded, we can explore it with some basic plots. Strava provides some interesting graphs to the runner such as the 2D map (longitude vs latitude) and elevation gain during the activity (altitude vs time). Using native plotting tools we can come to quite similar results. . import matplotlib.pyplot as plt plt.plot(activity[&#39;lon&#39;], activity[&#39;lat&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fa8cb4f0790&gt;] . . axis = activity.plot.area(y=&#39;alt&#39;) axis.set_ylim(0,100) . (0.0, 100.0) . . Calculating the total distance . Now let&#39;s going through the key metrics of the activity such as distance and speed. A quick look can misguide you into incorrect calculations. The first one is the distance between two LL-points (latitude, longitude) which it isn&#39;t a straight line, but spherical. . . There are two main approaches to calculate the distance between two points on a spherical surface: the Haversine distance and the Vincenty distance. The two formulas take a different approach on calculating the distance, but this is outside the scoop of this post. The maths behind both approaches can be found here. . Another issue about the distance calculation is if the data have been calculated solely based on latitude and longitude, without taking into consideration the elevation gain or loss, then the distance covered can be underestimated. The easiest way to do this, is to compute the spherical 2d distance and then use the Euclidean formula to add the altitude measurements. The formula below shows this last step. . If the uncorrected distance covered at time point $t_{i}$ is $d_{2,i}$, to correct the distance covered between time point $t_{i-1}$ and time point $t_{i}$ to begin{equation} d_{i} - d_{i-1} = sqrt{ left(d_{2,i} - d_{2,i-1} right)^{ ! !2} + left(a_{i} - a_{i-1} right)^{ ! !2}} end{equation} , where $d_{i}$ and $a_{i}$ are the corrected cumulative distance and the altitude at time $t_{i}$, respectively. . Now with the theoretical background presented, we can start implementing these formulas in our code. We will apply in all data points all possible implementations of our distance formula (Haversine or Vicenty and 2d or 3d) and compute the total distance for every data point by using the dataframe function cumsum. . There are geodesic python libraries already available with Vicenty and Haversine formulas, so we will import them here for our distance calculations. . #pip install haversine &amp; pip install vincenty from vincenty import vincenty as vn from haversine import haversine as hv from haversine import Unit import numpy as np . activity[&#39;shift_lon&#39;] = activity.shift(1)[&#39;lon&#39;] activity[&#39;shift_lat&#39;] = activity.shift(1)[&#39;lat&#39;] #compute the vincenty 2d distance activity[&#39;distance_vin_2d&#39;] = activity[[&#39;lat&#39;, &#39;lon&#39;, &#39;shift_lat&#39;, &#39;shift_lon&#39;]].apply(lambda x: vn( (x[0], x[1]),(x[2], x[3])), axis=1) #transform the value in meters activity[&#39;distance_vin_2d&#39;] = activity[&#39;distance_vin_2d&#39;] * 1000 #compute the haversine 2d distance activity[&#39;distance_hav_2d&#39;] = activity[[&#39;lat&#39;, &#39;lon&#39;, &#39;shift_lat&#39;, &#39;shift_lon&#39;]].apply(lambda x: hv((x[0], x[1]),(x[2], x[3]), unit=Unit.METERS), axis=1) #compute the total distance activity[&#39;distance_vin_no_alt&#39;] = activity[&#39;distance_vin_2d&#39;].cumsum() activity[&#39;distance_hav_no_alt&#39;] = activity[&#39;distance_hav_2d&#39;].cumsum() #compute the vincenty and haversine 3d activity[&#39;shift_alt&#39;] = activity.shift(1)[&#39;alt&#39;] activity[&#39;alt_dif&#39;] = activity[[&#39;alt&#39;, &#39;shift_alt&#39;]].apply(lambda x: x[1] - x[0], axis=1) activity[&#39;distance_vin_3d&#39;] = activity[[&#39;distance_vin_2d&#39;, &#39;alt_dif&#39;]].apply(lambda x: np.sqrt(x[0]**2 + (x[1])**2), axis=1) activity[&#39;distance_hav_3d&#39;] = activity[[&#39;distance_hav_2d&#39;, &#39;alt_dif&#39;]].apply(lambda x: np.sqrt(x[0]**2 + (x[1])**2), axis=1) #compute the total distances for vincenty and haversined 3D activity[&#39;distance_vin&#39;] = activity[&#39;distance_vin_3d&#39;].cumsum() activity[&#39;distance_hav&#39;] = activity[&#39;distance_hav_3d&#39;].cumsum() activity.drop([&#39;shift_lon&#39;, &#39;shift_lat&#39;, &#39;shift_alt&#39;], axis=1) #present the results activity[[&#39;distance_vin&#39;, &#39;distance_hav&#39;, &#39;distance_hav_3d&#39;, &#39;distance_vin_3d&#39;]] . distance_vin distance_hav distance_hav_3d distance_vin_3d . time . 00:00:00 NaN | NaN | NaN | NaN | . 00:00:04 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 00:00:06 5.099000 | 5.118162 | 5.118162 | 5.099000 | . 00:00:08 12.568000 | 12.609153 | 7.490991 | 7.469000 | . 00:00:10 19.330000 | 19.390883 | 6.781730 | 6.762000 | . ... ... | ... | ... | ... | . 01:25:17 12544.272150 | 12564.172393 | 6.437592 | 6.421000 | . 01:25:21 12559.222485 | 12579.203834 | 15.031441 | 14.950334 | . 01:25:23 12564.868485 | 12584.874982 | 5.671148 | 5.646000 | . 01:25:25 12570.232485 | 12590.267705 | 5.392723 | 5.364000 | . 01:25:27 12575.313485 | 12595.361143 | 5.093437 | 5.081000 | . 1697 rows × 4 columns . For futher convenice, we can extract the data in our previously created activity. Let&#39;s check the results with the following print comand. . print(&#39;Vicenty 2D: &#39;, activity[&#39;distance_vin_no_alt&#39;].max()) print(&#39;Haversine 2D: &#39;, activity[&#39;distance_hav_no_alt&#39;].max()) print(&#39;Vincenty 3D: &#39;, activity[&#39;distance_vin&#39;].max()) print(&#39;Haversine 3D: &#39;, activity[&#39;distance_hav&#39;].max()) . Vicenty 2D: 12574.600999999993 Haversine 2D: 12594.649752172338 Vincenty 3D: 12575.313484827602 Haversine 3D: 12595.361142855156 . If we compare the distance calculations between the app and ours, we will see they are almost similar. . . But why do we have 50m of difference between our internal calculations and the distance showed in the app ? It is explained in an article from Strava&#39;s support team. . A flat surface is assumed, and vertical speed from topography is not accounted for. — Strava In this scenario our 2d calculations are right and the we might conclude the app doesn’t take elevation into account. The difference between the distance proposed by the app and our estimate is about 50m (0.03%). Note that this difference will increase if you undertake more altitude-intense activities (mountain biking or hiking). . Now let&#39;s going forward to our next metric, the total activity time ellapsed x moving time. . Calculating the time ellapsed x moving time . def strfdelta(tdelta, fmt): d = {&quot;days&quot;: tdelta.days} d[&quot;hours&quot;], rem = divmod(tdelta.seconds, 3600) d[&quot;minutes&quot;], d[&quot;seconds&quot;] = divmod(rem, 60) return fmt.format(**d) print(&#39;Total time: &#39; , strfdelta(activity.index[-1], &quot;{hours} hour {minutes} min {seconds} sec&quot;)) . Total time: 1 hour 25 min 27 sec . The total time elapsed totally agrees with our calculations, but the moving time seems to be diferent. Let us explain the basic concepts: Elapsed time is the duration from the moment you hit start on your device or phone to the moment you finish the activity. It includes stoplights, coffee breaks, bathroom stops and stopping for photos. Moving time, on the other hand, is a measure of how long you were active, this can be realistic when we have to slow down and stop for a traffic light, for example. . Let’s see if we can figure out which threshold Strava uses to stop the timer (and therefore boost our average speed). To do so, we need to create a new variable that calculates our movement in meters per second (and not just movement per data point, hence why we created the time difference variable). Let’s do this for our haversine 2d distance, since that’s the closest approximation of the distance proposed by the app. . import pandas as pd import numpy as np activity[&#39;time&#39;] = activity.index activity[&#39;time_dif&#39;] = (activity.time - activity.time.shift(1).fillna(activity.time.iloc[0]))/np.timedelta64(1,&#39;s&#39;) activity[&#39;distance_dif_per_sec&#39;] = activity[&#39;distance_hav_2d&#39;] / activity[&#39;time_dif&#39;] activity[&#39;distance_dif_per_sec&#39;] . time 00:00:00 NaN 00:00:04 0.000000 00:00:06 2.559081 00:00:08 3.745496 00:00:10 3.390865 ... 01:25:17 3.218796 01:25:21 3.757777 01:25:23 2.835574 01:25:25 2.696362 01:25:27 2.546719 Name: distance_dif_per_sec, Length: 1697, dtype: float64 . With this new variable we can iterate through a list of thresholds. Let&#39;s assume values between 50 cm and 1 meter, and try to evaluate which one adds up to a timer time-out closest to 640 seconds (~=10 minutes). . for treshold in [0.5, 0.6, 0.7, 0.8, 0.9, 1]: print(treshold, &#39;m&#39;, &#39; : Time:&#39;, sum(activity[activity[&#39;distance_dif_per_sec&#39;] &lt; treshold][&#39;time_dif&#39;]), &#39; seconds&#39;) . 0.5 m : Time: 574.0 seconds 0.6 m : Time: 577.0 seconds 0.7 m : Time: 640.0 seconds 0.8 m : Time: 640.0 seconds 0.9 m : Time: 640.0 seconds 1 m : Time: 640.0 seconds . As we can see at the table above, the movement per second was less than 80-70 centimeters, the application didn&#39;t consider it as movement and discard those intervals (it&#39;s about 2.9 km/h , a speed far below that most people do in their walking pace). Since we don&#39;t have the algorithm used for the real calculation in the app, we can get to an approximate moving time. . total_time = activity[&#39;time_dif&#39;].sum() stopped_time = sum(activity[activity[&#39;distance_dif_per_sec&#39;] &lt; 0.8][&#39;time_dif&#39;]) pd.Timedelta(seconds=total_time - stopped_time) . Timedelta(&#39;0 days 01:14:47&#39;) . Calculating the speed and pace . With the moving time and distance calculated, we can now calculate the pace and speed. Speed is calculated by dividing the distance traveled in meters by the time it took in seconds, and then converted to km/h. . activity[&#39;speed&#39;] = (activity[&#39;distance_hav_2d&#39;] / activity [&#39;time_dif&#39;]) * 3.6 . Next we will filter out all the data where the movement per second is larger than 80 centimeters, based on the threshold we evaluated above. . activity_with_timeout = activity[activity[&#39;distance_dif_per_sec&#39;] &gt; 0.8] . Finally, we compute the weighted average speed and convert it to minutes and seconds per kilometers to get the Pace metric. . def pace(speed, fmt): d = {&quot;hours&quot;: 0} d[&quot;minutes&quot;] = np.floor(60 / speed) d[&quot;seconds&quot;] = round(((60 / speed - np.floor(60 / speed))*60), 0) return fmt.format(**d) avg_km_h = (sum((activity_with_timeout[&#39;speed&#39;] * activity_with_timeout[&#39;time_dif&#39;])) / sum(activity_with_timeout[&#39;time_dif&#39;])) print(&#39;Speed:&#39;, avg_km_h , &#39;km/h&#39;) print(&#39;Cadence:&#39; , pace(avg_km_h, &quot;{hours} hour {minutes} min {seconds} sec&quot;)) . Speed: 10.065838469772745 km/h Cadence: 0 hour 5.0 min 58.0 sec . The results compared to the proposed by our app show similar values, with average speed of 5 minutes and 58 seconds per kilometer, a difference of only just 2 secs. . Let&#39;s plot our average speed for every 10 seconds to see our speed floats during the run. For this plot we will need the cumulative sum of our time differente to 10 seconds and plot the aggregated speed against it. . activity[&#39;time_10s&#39;] = list(map(lambda x: round(x, -1), np.cumsum(activity[&#39;time_dif&#39;]))) plt.plot(activity.groupby([&#39;time_10s&#39;]).mean()[&#39;speed&#39;]) . [&lt;matplotlib.lines.Line2D at 0x7fa8c893f550&gt;] . The result shown is a smooth line plot where we check the speed (km/h) vs the time in seconds. . Calculating the elevation gain . The last metric we will explore is the elevation gain. According to the apps documentation, the cumulative elevation gain refers to the sum of every gain elevation throughout an entire Activity. . Based on that, we can compute the elevation gain by mapping over our altitude difference column of our dataframe. . activity_with_timeout.loc[activity_with_timeout[&#39;alt_dif&#39;] &gt; 0][&#39;alt_dif&#39;].sum() . 38.0 . The elevation calculated is far away from what the app showed (about 25m). Checking the altitude difference column values we can see that there are measures down to 10 centimeters. After reading the docummentation, we found out that the elevation data go through a noise correction algorithm. It is based on the a threshold where climbing needs to occur consistently for more than 10 meters for activities without strong barometric or two meters for an activity with the barometric data before it&#39;s added to the total elevation gain. . elevations = zip(list(activity_with_timeout[&#39;alt&#39;]), list(activity_with_timeout[&#39;distance_hav_2d&#39;])) THRESHOLD_METERS = 10 def calculate_elevation_gain(elevations): elevations = list(elevations) thresholdStartingPoint = elevations[0][0] diff_distance = 0 count_diff = 0 gain = 0 valueAgainstThreshold = 0 for elevation, distance in elevations: diff = elevation - thresholdStartingPoint diff_distance+=distance if diff &gt; 0: valueAgainstThreshold += diff if abs(diff_distance) &gt;= THRESHOLD_METERS: gain += valueAgainstThreshold diff_distance = 0 valueAgainstThreshold = 0 else: diff_distance = 0 valueAgainstThreshold = 0 thresholdStartingPoint = elevation return gain #plt.plot(activity[&#39;alt_dif&#39;]) print(calculate_elevation_gain(elevations)) . 25.30000000000002 . The new result is 25.2m, very close to the elevation propose by the app. Based on that, we could recalculate the 3rd distances to get these new elevation values into account to get the distance closest to the 2d distance. . What&#39;s next ? . In this article we presented some popular metrics in runner&#39;s world such as moving time, cadence, pace and elevation gain. The calculations behind the metrics were also detailed and we gave a possible approximation of some of the algorithms used by a famous tracking running application, since we don&#39;t have access, of course,how they implemented it. . The next steps will be implement these metrics as properties, methods of the runpandas.Activity dataframe. We will release it soon with examples detailed at one of our future posts. Keep following here! . — Please feel free to bring any inconsistencies or mistakes by leaving a comment below.- .",
            "url": "https://corriporai.github.io/pandasrunner/calculation/gps/metrics/jupyter/features/tracking/2021/01/29/metrics.html",
            "relUrl": "/calculation/gps/metrics/jupyter/features/tracking/2021/01/29/metrics.html",
            "date": " • Jan 29, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Release 0.2.0 and support to Strava!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . We are very excited to announce RunPandas 0.2. This release comes with new features and fixes, let&#39;s highlight them: . Improved docummentation with new sections such as User Guide, Install Guide, API Reference and Changelog. | Support to new code and docummentation third-party plugins like CodeFactor, Pepy, Zenodo and Binder. | Support to read multiple tracking files from a single directory | Added the feature of fetching activity data from social network Strava. | . What is Runpandas? . Runpandas is a python package based on pandas data analysis library, that makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to enable reading, transforming and running metrics analytics from several tracking files and apps. . Main Features . Read multiple tracking files from a single directory . With the new module function runpandas.read_dir , you can reall all the files in a directory and iterate over them. It uses runpandas.read_file and returns a generator. It is important to notice that read_dir expects all the files to be of a supported file format in the directory. . from pathlib import Path import runpandas directory = Path(&quot;path/to/some/dir/&quot;) for activity in runpandas.read_dir(directory): # Do things with the activities . Support to fetch activity stream data from Strava . We addded the support to fetch a single activity stream from the social sports app Strava. The function runpandas.read_strava assumes that you have an API access token and already performed an API authentication. You can use a support script available at our repository strava_auth_handler.py that we developed using the library stravalib. The basic usage is simple and it saves the API token into a file. . It is required to have a client_id and and a client_secret, for that you must have a developer account at strava and create an application. See further at strava: (https://developers.strava.com/) . Here a simple example about how to call : . $ python scripts/strava_auth_handler.py --client_id YOUCLIENTID --client_secret YOURCLIENTSECRET $ more access_token.json &quot;{ &quot;access_token &quot;: &quot;YOURACCESSTOKEN &quot;, &quot;refresh_token &quot;: &quot;YOURREFRESHTOKEN &quot;, &quot;expires_at &quot;: 1607634877}&quot; . read_strava() returns a runpandas.Activity with column runpandas.MeasureSeries matching Runpandas nomenclature. . #Disable INFO Logging for a better visualization import logging logging.getLogger().setLevel(logging.CRITICAL) . import runpandas activity = runpandas.read_strava(activity_id=4437021783, access_token=&quot;c1370af8341f5c5696988d54a1560130737f5954&quot;) activity.head(5) . 2020-12-06 06:36:27 . moving velocity_smooth grade_smooth alt cad dist hr lon lat . time . 00:00:00 False | 0.0 | 1.1 | 6.4 | 79 | 0.0 | 111 | -34.847439 | -8.016994 | . 00:00:04 True | 1.4 | 1.2 | 6.4 | 79 | 5.6 | 111 | -34.847324 | -8.016978 | . 00:00:06 True | 1.6 | 0.9 | 6.5 | 79 | 9.5 | 111 | -34.847252 | -8.016969 | . 00:00:09 True | 2.3 | 1.2 | 6.6 | 79 | 16.9 | 111 | -34.847221 | -8.016894 | . 00:00:12 True | 2.3 | 1.1 | 6.6 | 79 | 23.2 | 111 | -34.847176 | -8.016860 | . Thanks . We are constantly developing Runpandas improving its existing features and adding new ones. We will be glad to hear from you about what you like or don’t like, what features you may wish to see in upcoming releases. Please feel free to contact us. .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/01/13/release-v02.html",
            "relUrl": "/general/jupyter/releases/2021/01/13/release-v02.html",
            "date": " • Jan 13, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "The first runpandas release is alive! Welcome to the release 0.1.0!",
            "content": "This current state of the project is early beta, which means that features can be added, removed or changed in backwards incompatible ways. . Today we are happy to announce the initial release of runpandas, which makes it easier to perform data analysis from your running sessions stored at tracking files from cellphones and GPS smartwatches or social sports applications such as Strava, MapMyRUn, NikeRunClub, etc. It is designed to make the pandas data analysis package support reading, transforming and enable running metrics analytics. . How to use runpandas . Require the runpandas module in you Python Code and use our tracking file reader in case of reading local files in tcx, gpx or fit format. . # !pip install runpandas import runpandas as rpd activity = rpd.read_file(&#39;./data/sample.tcx&#39;) . The data file is loaded into a runpandas.Activity , which is a subclass of the pandas.DataFrame and provides some additional features. The library also provides for certain columns specific methods that extends the pandas.Series subclasses. In this example below, we get time, altitude, distance, heart rate and geo position (lat/long). . activity.head(5) . alt dist hr lon lat . time . 00:00:00 178.942627 | 0.000000 | 62.0 | -79.093187 | 35.951880 | . 00:00:01 178.942627 | 0.000000 | 62.0 | -79.093184 | 35.951880 | . 00:00:06 178.942627 | 1.106947 | 62.0 | -79.093172 | 35.951868 | . 00:00:12 177.500610 | 13.003035 | 62.0 | -79.093228 | 35.951774 | . 00:00:16 177.500610 | 22.405027 | 60.0 | -79.093141 | 35.951732 | . For instance, if you want to get the base unit for the altitude alt data or the distance dist data: . activity.alt.base_unit . &#39;m&#39; . activity.alt.sum() . 65883.68151855901 . activity.dist.base_unit . &#39;m&#39; . activity.dist[-1] . 4686.31103516 . Since the Activity is a DataFrame, we can play with data and create some visualizations. In this example we use the built in matplotlib based plot function to present the distance x time. . activity[[&#39;dist&#39;]].plot() . &lt;AxesSubplot:xlabel=&#39;time&#39;&gt; . Finally, let&#39;s watch a glimpse of the map route by plotting a 2d map using logintude vs latitude. . activity.plot(x=&#39;lon&#39;, y=&#39;lat&#39;) . &lt;AxesSubplot:xlabel=&#39;lon&#39;&gt; . That&#39;s some of features available! Please check out the runpandas docummentation link for the package&#39;s full API. . How to install runpandas . The release version of runpandas (0.1.0) is available on PyPI, the Python Package Index repository as runpandas link. . If you haven&#39;t already installed, start by downloading and installing with pip: . $ pip install runpandas --upgrade . Please note that we currently only support Python 3.6+. You are now ready to start using the runpandas. . Roadmap . We have big plans for runpandas, including not limited to: . Adding suport reading running tracking sessions from social application Strava; | Adding support reading track files giving a directory as parameter; | Better docummentation with user guide and install guidelines; | Support to session of activities | Support to special plots such as routes, average heart zones, personal bests for specific distances. | . You can see the live roadmap of features at our issues repository. . Thanks . It is our first release after two months of planning and coding. We hope that you find runpandas helpful - it is still very young, and result of some of my ideas and needs to perform personal running analysis. So don&#39;t be afraid to get in touch and let us know what features you would like to add next, Feel free to raise an issue if you spot any bugs! .",
            "url": "https://corriporai.github.io/pandasrunner/general/jupyter/releases/2021/01/07/release-v01.html",
            "relUrl": "/general/jupyter/releases/2021/01/07/release-v01.html",
            "date": " • Jan 7, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Welcome to runpandas",
            "content": "What is runpandas ? . Welcome to the runpandas library. The framework was developed by me, Marcel Caraciolo targeted at getting the most from your running data. . Recent technological advances to GPS-enabled tracking devices is transforming the aspects of training and competition in fitness activities such as running, cycling and swimming. Those devices produces detailed tracking data among several sports data available for anyone interested at its analysis. This enables a descriptive analysis associated with the related data, such as performance, impact of volume of training or just reviewing the historical activities. There are several devices or applications for sports tracking offered by manufacturers of the tracking devices, such as Garmin, Polar, and through a wide range of applications for devices such as smartphones and smartwatches, e.g., Strava, Endomondo, and Runtastic Running GPS Tracker. . Limiting to range of data science open-source packages available, there is only a handful of packages specific to sport data and their analysis. Within Python ecosystem, one of the most popular programming languages for data science, there is a gap to fill between the collection of tracking data and the analysis of such data. Pandas is a popular package for data analysis, and several specific domain libraries as built on top of it. At my research at time, I didn’t find many sports data analysis package within the Python + Pandas ecosystem. . As a possible alternative, runpandas package comes as a set of utilities to import sports data from GPS-enabled devices or even track activities applications, and, after careful processing, organises them in data frames which can provide information about the units of measurement (e.g. distance and speed units) as well of any data operations that have been carried out (e.g., personal best records, heart efforts, elevation gain). Runpandas extends the datatypes used by pandas, so it can benefit its core operations for the handling of measurement units and for summarising and visualising tracking data. . . Real motivation behind runpandas . Many runners use Strava, Garmin , Nike plus , Runstatic App (iOS and Android) to track running activities. The APP and its companion website jointly provide many visual charts with analytical metrics to help runners review their running performances to set up new training plans or make adjustments. To a data scientist runner like me, it would be ideal that our data be downloaded and analyzed locally in my own way to have more fun or get different analysis. . Don’t get me wrong, I am huge fan and user of several running apps, but sometimes I get frustrated with the data processing and visualization that major providers offer, or sometimes I want just to play around with my tracking data and plot my running routes using Maps libraries or to calculate my personal best times for specific distances. Runpandas is an ellegible solution for data science runners like me, fans of digging sports data combined with all possibilities of rich analysis matching against weather, temperature, marathons, routes datasets. So, welcome to the world of running analytics, where data science meets the running. . How can I get started ? . . If you read until here, it is probably because you are interested at runpandas or the possibilities of performing your own analysis. I will give you some options: . If you want to check the documentation for more details on using runpandas: Read the Docs | If you already know the library, and want to contribute: Github | You are just a curious or a runner, and wants to see the some examples: | Another introduction to runpandas is my undergoing book Analysing your own running data with Python on Jupyter notebooks: | . . Marcel Caraciolo, Computer Engineer and Bioinformatics Specialist at Genomika Einstein laboratory. Currently responsible for lab systems product management. Interested at data science, productivity techiques and product management. Amateur runner and lego architecture sets lover. @marcelcaraciolo corriporai.github.io/pandasrunner . .",
            "url": "https://corriporai.github.io/pandasrunner/general/2020/08/01/welcome-to-runpandas.html",
            "relUrl": "/general/2020/08/01/welcome-to-runpandas.html",
            "date": " • Aug 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". My name is Marcel Caraciolo, creator of runpandas. When I am not running or coding, I manage the bioinformatics team at the Genomika Einstein, a genetics molecular laboratory, and product manager for some laboratory management systems. Amateur runner, lover of Lego Architecture sets and passioned about productivity and agile techniques. .",
          "url": "https://corriporai.github.io/pandasrunner/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://corriporai.github.io/pandasrunner/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}